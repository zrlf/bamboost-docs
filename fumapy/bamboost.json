{
  "name": "bamboost",
  "path": "bamboost",
  "filepath": "/home/florez/work/code/bamboost/bamboost/__init__.py",
  "description": null,
  "docstring": [],
  "attributes": [
    {
      "name": "__author__",
      "annotation": null,
      "description": null,
      "value": "'florez@ethz.ch'"
    },
    {
      "name": "__copyright__",
      "annotation": null,
      "description": null,
      "value": "''"
    },
    {
      "name": "__license__",
      "annotation": null,
      "description": null,
      "value": "'LGPLv3'"
    },
    {
      "name": "__version__",
      "annotation": "str",
      "description": null,
      "value": "'0.8.1'"
    },
    {
      "name": "BAMBOOST_LOGGER",
      "annotation": null,
      "description": null,
      "value": "logging.getLogger('bamboost')"
    }
  ],
  "modules": {
    "extensions": {
      "name": "extensions",
      "path": "bamboost.extensions",
      "filepath": "/home/florez/work/code/bamboost/bamboost/extensions/__init__.py",
      "description": null,
      "docstring": [],
      "attributes": [
        {
          "name": "extensions",
          "annotation": null,
          "description": null,
          "value": "ExtensionsLazyLoader()"
        }
      ],
      "modules": {
        "slurm": {
          "name": "slurm",
          "path": "bamboost.extensions.slurm",
          "filepath": "/home/florez/work/code/bamboost/bamboost/extensions/slurm.py",
          "description": null,
          "docstring": [],
          "attributes": [
            {
              "name": "__all__",
              "annotation": null,
              "description": null,
              "value": "['install']"
            },
            {
              "name": "NAME_OF_DICT",
              "annotation": null,
              "description": null,
              "value": "'_slurm'"
            }
          ],
          "modules": {},
          "classes": {},
          "functions": {
            "_extend_enter_slurm_info": {
              "name": "_extend_enter_slurm_info",
              "path": "bamboost.extensions.slurm._extend_enter_slurm_info",
              "signature": "(original_enter)",
              "description": null,
              "parameters": [
                {
                  "name": "original_enter",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def _extend_enter_slurm_info(original_enter):\n    @wraps(original_enter)\n    def modified_enter(self: SimulationWriter, *args, **kwargs):\n        slurm_job_id = os.environ.get(\"SLURM_JOB_ID\")\n        self.update_metadata({NAME_OF_DICT: {\"jobId\": slurm_job_id}})\n        return original_enter(self, *args, **kwargs)\n\n    return modified_enter"
            },
            "_extend_exit_slurm_info": {
              "name": "_extend_exit_slurm_info",
              "path": "bamboost.extensions.slurm._extend_exit_slurm_info",
              "signature": "(original_exit)",
              "description": null,
              "parameters": [
                {
                  "name": "original_exit",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def _extend_exit_slurm_info(original_exit):\n    @wraps(original_exit)\n    def modified_exit(self: SimulationWriter, exc_type, exc_value, exc_tb):\n        # Inject the following into the __exit__ method of SimulationWriter\n        slurm_job_id = os.environ.get(\"SLURM_JOB_ID\")\n\n        result = subprocess.run(\n            [\"myjobs\", \"-j\", slurm_job_id], env=os.environ, capture_output=True\n        )\n\n        # Check if the command was successful\n        if result.returncode == 0:\n            # Get the output as a string\n            output_str = result.stdout.decode(\"utf-8\")\n\n            # Create a dictionary to store the key-value pairs\n            slurm_dict = {}\n            for line in output_str.strip().split(\"\\n\"):\n                if \":\" in line:  # Ensure the line contains a key-value pair\n                    key, value = line.split(\":\", 1)  # Split on the first colon\n\n                    # modify key to camelCase\n                    slurm_dict[to_camel_case(key.strip())] = value.strip()\n\n            # _write_slurm_info(self, slurm_dict)\n            self.update_metadata({NAME_OF_DICT: slurm_dict})\n\n        return original_exit(self, exc_type, exc_value, exc_tb)\n\n    return modified_exit"
            },
            "install": {
              "name": "install",
              "path": "bamboost.extensions.slurm.install",
              "signature": "()",
              "description": "Install the slurm extension to the SimulationWriter class. Extends the\n__exit__ method to add slurm metadata.",
              "parameters": [],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def install():\n    \"\"\"Install the slurm extension to the SimulationWriter class. Extends the\n    __exit__ method to add slurm metadata.\n    \"\"\"\n    SimulationWriter.__exit__ = _extend_exit_slurm_info(SimulationWriter.__exit__)\n    SimulationWriter.__enter__ = _extend_enter_slurm_info(SimulationWriter.__enter__)"
            }
          }
        },
        "fenics": {
          "name": "fenics",
          "path": "bamboost.extensions.fenics",
          "filepath": "/home/florez/work/code/bamboost/bamboost/extensions/fenics.py",
          "description": null,
          "docstring": [],
          "attributes": [
            {
              "name": "__all__",
              "annotation": null,
              "description": null,
              "value": "['FenicsWriter']"
            }
          ],
          "modules": {},
          "classes": {
            "FenicsWriter": {
              "name": "FenicsWriter",
              "path": "bamboost.extensions.fenics.FenicsWriter",
              "description": "Helper writer for input from FEniCS directly.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "uid",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Unique identifier for the simulation"
                    }
                  ]
                },
                {
                  "name": "path",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Path to database"
                    }
                  ]
                },
                {
                  "name": "comm",
                  "annotation": "MPI.Comm",
                  "description": [
                    {
                      "kind": "text",
                      "value": "MPI communicator"
                    }
                  ],
                  "value": "MPI.COMM_WORLD"
                },
                {
                  "name": "create_if_not_exists",
                  "annotation": "bool",
                  "description": null,
                  "value": "False"
                }
              ],
              "attributes": [],
              "docstring": [],
              "functions": {
                "__init__": {
                  "name": "__init__",
                  "path": "bamboost.extensions.fenics.FenicsWriter.__init__",
                  "signature": "(self, uid, path, comm = MPI.COMM_WORLD, create_if_not_exists = False)",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "uid",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "path",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "comm",
                      "annotation": "MPI.Comm",
                      "description": null,
                      "value": "MPI.COMM_WORLD"
                    },
                    {
                      "name": "create_if_not_exists",
                      "annotation": "bool",
                      "description": null,
                      "value": "False"
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": null,
                    "description": null
                  },
                  "docstring": [],
                  "source": "def __init__(\n    self,\n    uid: str,\n    path: str,\n    comm: MPI.Comm = MPI.COMM_WORLD,\n    create_if_not_exists: bool = False,\n):\n    super().__init__(uid, path, comm)"
                },
                "add_field": {
                  "name": "add_field",
                  "path": "bamboost.extensions.fenics.FenicsWriter.add_field",
                  "signature": "(self, name, func, time = None, mesh = None, dtype = None, center = 'Node') -> None",
                  "description": "Add a dataset to the file. The data is stored at `data/`.",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "name",
                      "annotation": "str",
                      "description": [
                        {
                          "kind": "text",
                          "value": "Name for the dataset"
                        }
                      ]
                    },
                    {
                      "name": "func",
                      "annotation": "fe.Function",
                      "description": [
                        {
                          "kind": "text",
                          "value": "FEniCS function to store"
                        }
                      ]
                    },
                    {
                      "name": "time",
                      "annotation": "float",
                      "description": [
                        {
                          "kind": "text",
                          "value": "Optional. time"
                        }
                      ],
                      "value": "None"
                    },
                    {
                      "name": "mesh",
                      "annotation": "str",
                      "description": [
                        {
                          "kind": "text",
                          "value": "Optional. Linked mesh for this data"
                        }
                      ],
                      "value": "None"
                    },
                    {
                      "name": "dtype",
                      "annotation": "str",
                      "description": [
                        {
                          "kind": "text",
                          "value": "Optional. Numpy style datatype, see h5py documentation,\ndefaults to the dtype of the vector"
                        }
                      ],
                      "value": "None"
                    },
                    {
                      "name": "center",
                      "annotation": "Literal",
                      "description": [
                        {
                          "kind": "text",
                          "value": "Optional. Center of the data. Can be 'Node' or 'Cell'.\nDefault is 'Node'."
                        }
                      ],
                      "value": "'Node'"
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def add_field(\n    self,\n    name: str,\n    func: fe.Function,\n    time: float = None,\n    mesh: str = None,\n    dtype: str = None,\n    center: Literal[\"Node\", \"Cell\"] = \"Node\",\n) -> None:\n    \"\"\"Add a dataset to the file. The data is stored at `data/`.\n\n    Args:\n        name: Name for the dataset\n        func: FEniCS function to store\n        time: Optional. time\n        mesh: Optional. Linked mesh for this data\n        dtype: Optional. Numpy style datatype, see h5py documentation,\n            defaults to the dtype of the vector\n        center: Optional. Center of the data. Can be 'Node' or 'Cell'.\n            Default is 'Node'.\n    \"\"\"\n    mesh = mesh if mesh is not None else self._default_mesh\n    time = time if time is not None else self.step\n\n    self._dump_fenics_field(\n        f\"data/{name}/{self.step}\",\n        func,\n        dtype=dtype,\n        center=center,\n    )\n    self._comm.barrier()  # attempt to fix bug (see SimulationWriter add_field)\n\n    if self._prank == 0:\n        with self._file(\"a\"):\n            vec = self._file[\"data\"][name][str(self.step)]\n            vec.attrs.update({\"center\": center, \"mesh\": mesh, \"t\": time})\n\n    self._comm.barrier()  # attempt to fix bug (see SimulationWriter add_field)"
                },
                "_dump_fenics_field": {
                  "name": "_dump_fenics_field",
                  "path": "bamboost.extensions.fenics.FenicsWriter._dump_fenics_field",
                  "signature": "(self, location, field, dtype = None, center = 'Node') -> None",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "location",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "field",
                      "annotation": "fe.Function",
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "dtype",
                      "annotation": "str",
                      "description": null,
                      "value": "None"
                    },
                    {
                      "name": "center",
                      "annotation": "Literal",
                      "description": null,
                      "value": "'Node'"
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def _dump_fenics_field(\n    self,\n    location: str,\n    field: fe.Function,\n    dtype: str = None,\n    center: Literal[\"Node\", \"Cell\"] = \"Node\",\n) -> None:\n    # get global dofs ordering and vector\n    if center == \"Node\":\n        data = self._get_global_dofs(field)\n    elif center == \"Cell\":\n        data = self._get_global_dofs_cell_data(field)\n    else:\n        raise ValueError(\"Center must be 'Node' or 'Cell'.\")\n\n    vector = data[\"vector\"]\n    global_map = data[\"global_map\"]\n    global_size = data[\"global_size\"]\n\n    dim = data[\"vector\"].shape[1:] if data[\"vector\"].ndim > 1 else None\n\n    group_name, dataset_name = location.rstrip(\"/\").rsplit(\"/\", 1)\n\n    # Write vector to file\n    with self._file(\"a\", driver=\"mpio\", comm=self._comm) as f:\n        grp = f.require_group(group_name)\n        vec = grp.require_dataset(\n            dataset_name,\n            shape=(global_size, *dim) if dim else (global_size,),\n            dtype=dtype if dtype else vector.dtype,\n        )\n        vec[global_map] = vector"
                },
                "_get_global_dofs": {
                  "name": "_get_global_dofs",
                  "path": "bamboost.extensions.fenics.FenicsWriter._get_global_dofs",
                  "signature": "(self, func) -> bamboost.extensions.fenics.FenicsWriter.FenicsFieldInformation",
                  "description": "Get global dofs for a given function.",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "func",
                      "annotation": "fe.Function",
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "bamboost.extensions.fenics.FenicsWriter.FenicsFieldInformation",
                    "description": "A dict with the local vector, a mapping from the local to the"
                  },
                  "docstring": [],
                  "source": "def _get_global_dofs(self, func: fe.Function) -> FenicsFieldInformation:\n    \"\"\"\n    Get global dofs for a given function.\n\n    Args:\n        - func: Expression/field/function\n\n    Returns:\n        A dict with the local vector, a mapping from the local to the\n        global vertices (both sorted by index because h5py complains if\n        slicing is not continuously increasing), and the number of global\n        vertices.\n    \"\"\"\n    assert hasattr(\n        func, \"function_space\"\n    ), \"Input is likely an indexed coefficient. Project to it's own function space first.\"\n\n    # Project to CG1 if necessary\n    if func.ufl_element().degree() != 1:\n        func = fe.project(\n            func, fe.FunctionSpace(func.function_space().mesh(), \"CG\", 1)\n        )\n\n    mesh = func.function_space().mesh()\n    global_size = mesh.num_entities_global(0)\n    shape = (-1, *func.ufl_shape) if func.ufl_shape else (-1,)\n    val_per_vertex = np.prod(shape[1:]).astype(np.int32) if func.ufl_shape else 1\n\n    dofmap = func.function_space().dofmap()\n    d2v = fe.dof_to_vertex_map(func.function_space())\n    d2v = (\n        d2v[np.arange(0, len(d2v), val_per_vertex, dtype=np.int32)]\n        // val_per_vertex\n    )\n\n    loc0, loc1 = (i // val_per_vertex for i in dofmap.ownership_range())\n    global_vertex_numbers = mesh.topology().global_indices(0)\n    global_vertices = global_vertex_numbers[d2v[: loc1 - loc0]]\n    sort_indices = np.argsort(global_vertices)\n\n    local_vector = (\n        func.vector().get_local().reshape(shape)[: loc1 - loc0][sort_indices]\n    )\n\n    return {\n        \"vector\": local_vector,\n        \"global_map\": global_vertices[sort_indices],\n        \"global_size\": global_size,\n    }"
                },
                "_get_global_dofs_cell_data": {
                  "name": "_get_global_dofs_cell_data",
                  "path": "bamboost.extensions.fenics.FenicsWriter._get_global_dofs_cell_data",
                  "signature": "(self, func) -> bamboost.extensions.fenics.FenicsWriter.FenicsFieldInformation",
                  "description": "Get global dofs for a given function.",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "func",
                      "annotation": "fe.Function",
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "bamboost.extensions.fenics.FenicsWriter.FenicsFieldInformation",
                    "description": "A dict with the local vector, a mapping from the local to the"
                  },
                  "docstring": [],
                  "source": "def _get_global_dofs_cell_data(self, func: fe.Function) -> FenicsFieldInformation:\n    \"\"\"\n    Get global dofs for a given function.\n\n    Args:\n        - func: Expression/field/function\n\n    Returns:\n        A dict with the local vector, a mapping from the local to the\n        global vertices (both sorted by index because h5py complains if\n        slicing is not continuously increasing), and the number of global\n        vertices.\n    \"\"\"\n    V = func.function_space()\n    val_per_vertex = (\n        np.prod(func.ufl_shape).astype(np.int32) if func.ufl_shape else 1\n    )\n\n    mesh = V.mesh()\n    dofmap = V.dofmap()\n\n    local_to_global_indices = dofmap.tabulate_local_to_global_dofs()\n    local_to_global_indices = (\n        local_to_global_indices[\n            np.arange(\n                0, len(local_to_global_indices), val_per_vertex, dtype=np.int32\n            )\n        ]\n        // val_per_vertex\n    )\n    shape = (-1, *func.ufl_shape) if func.ufl_shape else (-1,)\n    local_vector = func.vector().get_local().reshape(shape)\n\n    return {\n        \"vector\": local_vector,\n        \"global_map\": local_to_global_indices,\n        \"global_size\": self._comm.allreduce(mesh.num_cells(), op=MPI.SUM),\n    }"
                },
                "add_mesh": {
                  "name": "add_mesh",
                  "path": "bamboost.extensions.fenics.FenicsWriter.add_mesh",
                  "signature": "(self, mesh, mesh_name = None) -> None",
                  "description": "Add the mesh to file using fe.HDF5File. I can't figure out how to\nextract the local mesh data in correct order when running in parallel.",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "mesh",
                      "annotation": "fe.Mesh",
                      "description": [
                        {
                          "kind": "text",
                          "value": "FEniCS mesh object"
                        }
                      ]
                    },
                    {
                      "name": "mesh_name",
                      "annotation": "str",
                      "description": [
                        {
                          "kind": "text",
                          "value": "name for mesh (default = `mesh`)"
                        }
                      ],
                      "value": "None"
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def add_mesh(self, mesh: fe.Mesh, mesh_name: str = None) -> None:\n    \"\"\"\n    Add the mesh to file using fe.HDF5File. I can't figure out how to\n    extract the local mesh data in correct order when running in parallel.\n\n    Args:\n        mesh: FEniCS mesh object\n        mesh_name: name for mesh (default = `mesh`)\n    \"\"\"\n    mesh_name = mesh_name if mesh_name is not None else self._default_mesh\n    mesh_location = f\"{self._mesh_location}/{mesh_name}/\"\n\n    assert not self._file.file_object, \"File is open -> Quitting\"\n\n    @contextmanager\n    def temporary_close_file():\n        was_open = False\n        if self._file.file_object:\n            self._file.file_object.close()\n            was_open = True\n        try:\n            yield\n        finally:\n            if was_open:\n                self._file.file_object = open_h5file(\n                    self._file.file_name,\n                    self._file.mode,\n                    self._file.driver,\n                    self._file.comm,\n                )\n\n    with temporary_close_file():\n        with fe.HDF5File(self._comm, self.h5file, \"a\") as f:\n            f.write(mesh, mesh_location)"
                }
              },
              "source": "class FenicsWriter(SimulationWriter):\n    \"\"\"\n    Helper writer for input from FEniCS directly.\n\n    Args:\n        uid: Unique identifier for the simulation\n        path: Path to database\n        comm: MPI communicator\n    \"\"\"\n\n    def __init__(\n        self,\n        uid: str,\n        path: str,\n        comm: MPI.Comm = MPI.COMM_WORLD,\n        create_if_not_exists: bool = False,\n    ):\n        super().__init__(uid, path, comm)\n\n    def add_field(\n        self,\n        name: str,\n        func: fe.Function,\n        time: float = None,\n        mesh: str = None,\n        dtype: str = None,\n        center: Literal[\"Node\", \"Cell\"] = \"Node\",\n    ) -> None:\n        \"\"\"Add a dataset to the file. The data is stored at `data/`.\n\n        Args:\n            name: Name for the dataset\n            func: FEniCS function to store\n            time: Optional. time\n            mesh: Optional. Linked mesh for this data\n            dtype: Optional. Numpy style datatype, see h5py documentation,\n                defaults to the dtype of the vector\n            center: Optional. Center of the data. Can be 'Node' or 'Cell'.\n                Default is 'Node'.\n        \"\"\"\n        mesh = mesh if mesh is not None else self._default_mesh\n        time = time if time is not None else self.step\n\n        self._dump_fenics_field(\n            f\"data/{name}/{self.step}\",\n            func,\n            dtype=dtype,\n            center=center,\n        )\n        self._comm.barrier()  # attempt to fix bug (see SimulationWriter add_field)\n\n        if self._prank == 0:\n            with self._file(\"a\"):\n                vec = self._file[\"data\"][name][str(self.step)]\n                vec.attrs.update({\"center\": center, \"mesh\": mesh, \"t\": time})\n\n        self._comm.barrier()  # attempt to fix bug (see SimulationWriter add_field)\n\n    def _dump_fenics_field(\n        self,\n        location: str,\n        field: fe.Function,\n        dtype: str = None,\n        center: Literal[\"Node\", \"Cell\"] = \"Node\",\n    ) -> None:\n        # get global dofs ordering and vector\n        if center == \"Node\":\n            data = self._get_global_dofs(field)\n        elif center == \"Cell\":\n            data = self._get_global_dofs_cell_data(field)\n        else:\n            raise ValueError(\"Center must be 'Node' or 'Cell'.\")\n\n        vector = data[\"vector\"]\n        global_map = data[\"global_map\"]\n        global_size = data[\"global_size\"]\n\n        dim = data[\"vector\"].shape[1:] if data[\"vector\"].ndim > 1 else None\n\n        group_name, dataset_name = location.rstrip(\"/\").rsplit(\"/\", 1)\n\n        # Write vector to file\n        with self._file(\"a\", driver=\"mpio\", comm=self._comm) as f:\n            grp = f.require_group(group_name)\n            vec = grp.require_dataset(\n                dataset_name,\n                shape=(global_size, *dim) if dim else (global_size,),\n                dtype=dtype if dtype else vector.dtype,\n            )\n            vec[global_map] = vector\n\n    class FenicsFieldInformation(TypedDict):\n        vector: np.ndarray\n        global_map: np.ndarray\n        global_size: int\n\n    def _get_global_dofs(self, func: fe.Function) -> FenicsFieldInformation:\n        \"\"\"\n        Get global dofs for a given function.\n\n        Args:\n            - func: Expression/field/function\n\n        Returns:\n            A dict with the local vector, a mapping from the local to the\n            global vertices (both sorted by index because h5py complains if\n            slicing is not continuously increasing), and the number of global\n            vertices.\n        \"\"\"\n        assert hasattr(\n            func, \"function_space\"\n        ), \"Input is likely an indexed coefficient. Project to it's own function space first.\"\n\n        # Project to CG1 if necessary\n        if func.ufl_element().degree() != 1:\n            func = fe.project(\n                func, fe.FunctionSpace(func.function_space().mesh(), \"CG\", 1)\n            )\n\n        mesh = func.function_space().mesh()\n        global_size = mesh.num_entities_global(0)\n        shape = (-1, *func.ufl_shape) if func.ufl_shape else (-1,)\n        val_per_vertex = np.prod(shape[1:]).astype(np.int32) if func.ufl_shape else 1\n\n        dofmap = func.function_space().dofmap()\n        d2v = fe.dof_to_vertex_map(func.function_space())\n        d2v = (\n            d2v[np.arange(0, len(d2v), val_per_vertex, dtype=np.int32)]\n            // val_per_vertex\n        )\n\n        loc0, loc1 = (i // val_per_vertex for i in dofmap.ownership_range())\n        global_vertex_numbers = mesh.topology().global_indices(0)\n        global_vertices = global_vertex_numbers[d2v[: loc1 - loc0]]\n        sort_indices = np.argsort(global_vertices)\n\n        local_vector = (\n            func.vector().get_local().reshape(shape)[: loc1 - loc0][sort_indices]\n        )\n\n        return {\n            \"vector\": local_vector,\n            \"global_map\": global_vertices[sort_indices],\n            \"global_size\": global_size,\n        }\n\n    def _get_global_dofs_cell_data(self, func: fe.Function) -> FenicsFieldInformation:\n        \"\"\"\n        Get global dofs for a given function.\n\n        Args:\n            - func: Expression/field/function\n\n        Returns:\n            A dict with the local vector, a mapping from the local to the\n            global vertices (both sorted by index because h5py complains if\n            slicing is not continuously increasing), and the number of global\n            vertices.\n        \"\"\"\n        V = func.function_space()\n        val_per_vertex = (\n            np.prod(func.ufl_shape).astype(np.int32) if func.ufl_shape else 1\n        )\n\n        mesh = V.mesh()\n        dofmap = V.dofmap()\n\n        local_to_global_indices = dofmap.tabulate_local_to_global_dofs()\n        local_to_global_indices = (\n            local_to_global_indices[\n                np.arange(\n                    0, len(local_to_global_indices), val_per_vertex, dtype=np.int32\n                )\n            ]\n            // val_per_vertex\n        )\n        shape = (-1, *func.ufl_shape) if func.ufl_shape else (-1,)\n        local_vector = func.vector().get_local().reshape(shape)\n\n        return {\n            \"vector\": local_vector,\n            \"global_map\": local_to_global_indices,\n            \"global_size\": self._comm.allreduce(mesh.num_cells(), op=MPI.SUM),\n        }\n\n    def add_mesh(self, mesh: fe.Mesh, mesh_name: str = None) -> None:\n        \"\"\"\n        Add the mesh to file using fe.HDF5File. I can't figure out how to\n        extract the local mesh data in correct order when running in parallel.\n\n        Args:\n            mesh: FEniCS mesh object\n            mesh_name: name for mesh (default = `mesh`)\n        \"\"\"\n        mesh_name = mesh_name if mesh_name is not None else self._default_mesh\n        mesh_location = f\"{self._mesh_location}/{mesh_name}/\"\n\n        assert not self._file.file_object, \"File is open -> Quitting\"\n\n        @contextmanager\n        def temporary_close_file():\n            was_open = False\n            if self._file.file_object:\n                self._file.file_object.close()\n                was_open = True\n            try:\n                yield\n            finally:\n                if was_open:\n                    self._file.file_object = open_h5file(\n                        self._file.file_name,\n                        self._file.mode,\n                        self._file.driver,\n                        self._file.comm,\n                    )\n\n        with temporary_close_file():\n            with fe.HDF5File(self._comm, self.h5file, \"a\") as f:\n                f.write(mesh, mesh_location)",
              "inherited_members": {
                "bamboost.simulation.Simulation": [
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation._mesh_location"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation._default_mesh"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.uid"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.path_database"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.database_id"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.path"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.h5file"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.xdmffile"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation._comm"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation._psize"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation._prank"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation._ranks"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation._file"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.meshes"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.data"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.globals"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.userdata"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.links"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.fromUID"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.__getitem__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation._repr_html_"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation._push_update_to_sqlite"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.parameters"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.metadata"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.files"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.show_files"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.open_in_file_explorer"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.open_in_paraview"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.get_full_uid"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.change_status"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.update_metadata"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.update_parameters"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.create_xdmf_file"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.create_run_script"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.create_batch_script"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.submit"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.change_note"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.open"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.mesh"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.get_mesh"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.data_info"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.git"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.get_data_interpolator"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.show_h5tree"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.enter_path"
                  }
                ],
                "bamboost.simulation_writer.SimulationWriter": [
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation_writer.SimulationWriter.step"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation_writer.SimulationWriter.__enter__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation_writer.SimulationWriter.__exit__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation_writer.SimulationWriter.initialize"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation_writer.SimulationWriter.add_metadata"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation_writer.SimulationWriter.add_parameters"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation_writer.SimulationWriter._dump_array"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation_writer.SimulationWriter.add_fields"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation_writer.SimulationWriter.add_global_field"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation_writer.SimulationWriter._dump_global_data"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation_writer.SimulationWriter.add_global_fields"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation_writer.SimulationWriter.finish_step"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation_writer.SimulationWriter.finish_sim"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation_writer.SimulationWriter.register_git_attributes"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation_writer.SimulationWriter.copy_executable"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation_writer.SimulationWriter.copy_file"
                  }
                ]
              }
            }
          },
          "functions": {}
        },
        "remote_manager": {
          "name": "remote_manager",
          "path": "bamboost.extensions.remote_manager",
          "filepath": "/home/florez/work/code/bamboost/bamboost/extensions/remote_manager.py",
          "description": null,
          "docstring": [],
          "attributes": [
            {
              "name": "__all__",
              "annotation": null,
              "description": null,
              "value": "['Remote', 'RemoteManager', 'RemoteSimulation']"
            },
            {
              "name": "log",
              "annotation": null,
              "description": null,
              "value": "BAMBOOST_LOGGER.getChild(__name__.split('.')[-1])"
            },
            {
              "name": "HOME",
              "annotation": null,
              "description": null,
              "value": "os.path.expanduser('~')"
            },
            {
              "name": "CACHE_DIR",
              "annotation": null,
              "description": null,
              "value": "os.path.join(HOME, '.cache', 'bamboost')"
            },
            {
              "name": "REMOTE_INDEX",
              "annotation": null,
              "description": null,
              "value": "'~/.local/share/bamboost/bamboost.db'"
            }
          ],
          "modules": {},
          "classes": {
            "Remote": {
              "name": "Remote",
              "path": "bamboost.extensions.remote_manager.Remote",
              "description": "Access bamboost database of a remote server. The index is fetched using\nrsync over ssh. The `remote_name` can be a hostname or an IP address. Make\nsure that ssh keys are set and working, as there is no user authentication.\nThe `skip_update` flag can be set to avoid fetching the index from the\nremote server.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "remote_name",
                  "annotation": "str",
                  "description": null,
                  "value": null
                },
                {
                  "name": "skip_update",
                  "annotation": "bool",
                  "description": null,
                  "value": "False"
                },
                {
                  "name": "home_path",
                  "annotation": "str",
                  "description": null,
                  "value": "None"
                }
              ],
              "attributes": [
                {
                  "name": "remote_name",
                  "annotation": null,
                  "description": null,
                  "value": "remote_name"
                },
                {
                  "name": "local_path",
                  "annotation": null,
                  "description": null,
                  "value": "os.path.join(CACHE_DIR, self.remote_name)"
                },
                {
                  "name": "file",
                  "annotation": null,
                  "description": null,
                  "value": "f'{self.local_path}/bamboost.db'"
                }
              ],
              "docstring": [
                {
                  "kind": "admonition",
                  "value": {
                    "annotation": "example",
                    "description": ">>> remote = Remote(\"euler\")\n>>> remote.read_table()\nreturns a pandas DataFrame of the remote index.\n>>> remote[\"<id>\"]\nreturns a RemoteManager object for the given id."
                  },
                  "title": "Example"
                }
              ],
              "functions": {
                "__new__": {
                  "name": "__new__",
                  "path": "bamboost.extensions.remote_manager.Remote.__new__",
                  "signature": "(cls, *args, **kwargs)",
                  "description": "Override the __new__ method to avoid the singleton pattern of IndexAPI.",
                  "parameters": [
                    {
                      "name": "cls",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "args",
                      "annotation": null,
                      "description": null,
                      "value": "()"
                    },
                    {
                      "name": "kwargs",
                      "annotation": null,
                      "description": null,
                      "value": "{}"
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": null,
                    "description": null
                  },
                  "docstring": [],
                  "source": "def __new__(cls, *args, **kwargs):\n    \"\"\"Override the __new__ method to avoid the singleton pattern of IndexAPI.\"\"\"\n    return object.__new__(cls)"
                },
                "__init__": {
                  "name": "__init__",
                  "path": "bamboost.extensions.remote_manager.Remote.__init__",
                  "signature": "(self, remote_name, skip_update = False, *, home_path = None) -> None",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "remote_name",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "skip_update",
                      "annotation": "bool",
                      "description": null,
                      "value": "False"
                    },
                    {
                      "name": "home_path",
                      "annotation": "str",
                      "description": null,
                      "value": "None"
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def __init__(\n    self, remote_name: str, skip_update: bool = False, *, home_path: str = None\n) -> None:\n    self.remote_name = remote_name\n    self.local_path = os.path.join(CACHE_DIR, self.remote_name)\n    os.makedirs(self.local_path, exist_ok=True)\n    self.file = f\"{self.local_path}/bamboost.db\"\n\n    if not skip_update:\n        process = self.fetch_index()\n        process.wait()\n\n    # Initialize the SQLiteHandler\n    SQLiteHandler.__init__(self, self.file)"
                },
                "list": {
                  "name": "list",
                  "path": "bamboost.extensions.remote_manager.Remote.list",
                  "signature": "(cls) -> bamboost.extensions.remote_manager.Remote.list",
                  "description": "List all remote servers.",
                  "parameters": [
                    {
                      "name": "cls",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "bamboost.extensions.remote_manager.Remote.list",
                    "description": null
                  },
                  "docstring": [],
                  "source": "@classmethod\ndef list(cls) -> list:\n    \"\"\"List all remote servers.\"\"\"\n    return [\n        name\n        for name in os.listdir(CACHE_DIR)\n        if os.path.isdir(os.path.join(CACHE_DIR, name))\n    ]"
                },
                "_ipython_key_completions_": {
                  "name": "_ipython_key_completions_",
                  "path": "bamboost.extensions.remote_manager.Remote._ipython_key_completions_",
                  "signature": "(self) -> bamboost.extensions.remote_manager.Remote.list",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "bamboost.extensions.remote_manager.Remote.list",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def _ipython_key_completions_(self) -> list[str]:\n    ids = self.read_table()[[\"id\", \"path\"]].values\n    completion_keys = [\n        f'{key} - {\"...\"+val[-25:] if len(val)>=25 else val}' for key, val in ids\n    ]\n    return completion_keys"
                },
                "__getitem__": {
                  "name": "__getitem__",
                  "path": "bamboost.extensions.remote_manager.Remote.__getitem__",
                  "signature": "(self, id) -> bamboost.extensions.remote_manager.RemoteManager",
                  "description": "Return a `RemoteManager` for the given id.",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "id",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "bamboost.extensions.remote_manager.RemoteManager",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def __getitem__(self, id: str) -> RemoteManager:\n    \"\"\"Return a `RemoteManager` for the given id.\"\"\"\n    id = id.split(\" - \")[0]\n    return RemoteManager(id, remote=self)"
                },
                "fetch_index": {
                  "name": "fetch_index",
                  "path": "bamboost.extensions.remote_manager.Remote.fetch_index",
                  "signature": "(self) -> subprocess.Popen",
                  "description": "Fetch the index from the remote server.",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "subprocess.Popen",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def fetch_index(self) -> subprocess.Popen:\n    \"\"\"Fetch the index from the remote server.\"\"\"\n    return subprocess.Popen(\n        [\"rsync\", \"-av\", f\"{self.remote_name}:{REMOTE_INDEX}\", self.file],\n        stdout=subprocess.PIPE,\n        stderr=subprocess.STDOUT,\n        text=True,\n    )"
                },
                "get_manager": {
                  "name": "get_manager",
                  "path": "bamboost.extensions.remote_manager.Remote.get_manager",
                  "signature": "(self, id, skip_update = False) -> bamboost.extensions.remote_manager.RemoteManager",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "id",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "skip_update",
                      "annotation": "bool",
                      "description": null,
                      "value": "False"
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "bamboost.extensions.remote_manager.RemoteManager",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def get_manager(self, id: str, skip_update: bool = False) -> RemoteManager:\n    return RemoteManager(id, remote=self, skip_update=skip_update)"
                },
                "get_path": {
                  "name": "get_path",
                  "path": "bamboost.extensions.remote_manager.Remote.get_path",
                  "signature": "(self, id) -> str",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "id",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "str",
                    "description": null
                  },
                  "docstring": [],
                  "source": "@with_connection\ndef get_path(self, id: str) -> str:\n    self._cursor.execute(\"SELECT path FROM dbindex WHERE id=?\", (id,))\n    fetch = self._cursor.fetchone()\n    if fetch is None:\n        raise KeyError(f\"No database found with id: {id}\")\n    else:\n        return fetch[0]"
                },
                "insert_local_path": {
                  "name": "insert_local_path",
                  "path": "bamboost.extensions.remote_manager.Remote.insert_local_path",
                  "signature": "(self, id, path) -> None",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "id",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "path",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "@with_connection\ndef insert_local_path(self, id: str, path: str) -> None:\n    try:\n        self._cursor.execute(\n            \"UPDATE dbindex SET local_path=? WHERE id=?\", (path, id)\n        )\n    except sqlite3.OperationalError:\n        self._cursor.execute(\n            \"ALTER TABLE dbindex ADD COLUMN local_path TEXT DEFAULT NULL\"\n        )\n        self._cursor.execute(\n            \"UPDATE dbindex SET local_path=? WHERE id=?\", (path, id)\n        )"
                }
              },
              "source": "class Remote(IndexAPI, SQLiteHandler):\n    \"\"\"Access bamboost database of a remote server. The index is fetched using\n    rsync over ssh. The `remote_name` can be a hostname or an IP address. Make\n    sure that ssh keys are set and working, as there is no user authentication.\n    The `skip_update` flag can be set to avoid fetching the index from the\n    remote server.\n\n    Args:\n        - remote_name (str): The hostname or IP address of the remote server.\n        - skip_update (bool): Flag to avoid fetching the index from the remote\n          server. Default is False.\n\n    Example:\n        >>> remote = Remote(\"euler\")\n        >>> remote.read_table()\n        returns a pandas DataFrame of the remote index.\n        >>> remote[\"<id>\"]\n        returns a RemoteManager object for the given id.\n    \"\"\"\n\n    def __new__(cls, *args, **kwargs):\n        \"\"\"Override the __new__ method to avoid the singleton pattern of IndexAPI.\"\"\"\n        return object.__new__(cls)\n\n    def __init__(\n        self, remote_name: str, skip_update: bool = False, *, home_path: str = None\n    ) -> None:\n        self.remote_name = remote_name\n        self.local_path = os.path.join(CACHE_DIR, self.remote_name)\n        os.makedirs(self.local_path, exist_ok=True)\n        self.file = f\"{self.local_path}/bamboost.db\"\n\n        if not skip_update:\n            process = self.fetch_index()\n            process.wait()\n\n        # Initialize the SQLiteHandler\n        SQLiteHandler.__init__(self, self.file)\n\n    @classmethod\n    def list(cls) -> list:\n        \"\"\"List all remote servers.\"\"\"\n        return [\n            name\n            for name in os.listdir(CACHE_DIR)\n            if os.path.isdir(os.path.join(CACHE_DIR, name))\n        ]\n\n    def _ipython_key_completions_(self) -> list[str]:\n        ids = self.read_table()[[\"id\", \"path\"]].values\n        completion_keys = [\n            f'{key} - {\"...\"+val[-25:] if len(val)>=25 else val}' for key, val in ids\n        ]\n        return completion_keys\n\n    def __getitem__(self, id: str) -> RemoteManager:\n        \"\"\"Return a `RemoteManager` for the given id.\"\"\"\n        id = id.split(\" - \")[0]\n        return RemoteManager(id, remote=self)\n\n    def fetch_index(self) -> subprocess.Popen:\n        \"\"\"Fetch the index from the remote server.\"\"\"\n        return subprocess.Popen(\n            [\"rsync\", \"-av\", f\"{self.remote_name}:{REMOTE_INDEX}\", self.file],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n            text=True,\n        )\n\n    def get_manager(self, id: str, skip_update: bool = False) -> RemoteManager:\n        return RemoteManager(id, remote=self, skip_update=skip_update)\n\n    @with_connection\n    def get_path(self, id: str) -> str:\n        self._cursor.execute(\"SELECT path FROM dbindex WHERE id=?\", (id,))\n        fetch = self._cursor.fetchone()\n        if fetch is None:\n            raise KeyError(f\"No database found with id: {id}\")\n        else:\n            return fetch[0]\n\n    @with_connection\n    def insert_local_path(self, id: str, path: str) -> None:\n        try:\n            self._cursor.execute(\n                \"UPDATE dbindex SET local_path=? WHERE id=?\", (path, id)\n            )\n        except sqlite3.OperationalError:\n            self._cursor.execute(\n                \"ALTER TABLE dbindex ADD COLUMN local_path TEXT DEFAULT NULL\"\n            )\n            self._cursor.execute(\n                \"UPDATE dbindex SET local_path=? WHERE id=?\", (path, id)\n            )",
              "inherited_members": {
                "bamboost._sqlite_database.SQLiteHandler": [
                  {
                    "kind": "attribute",
                    "path": "bamboost._sqlite_database.SQLiteHandler._conn"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost._sqlite_database.SQLiteHandler._cursor"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost._sqlite_database.SQLiteHandler._is_open"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost._sqlite_database.SQLiteHandler._lock_stack"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost._sqlite_database.SQLiteHandler.connect"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost._sqlite_database.SQLiteHandler.close"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost._sqlite_database.SQLiteHandler.commit"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost._sqlite_database.SQLiteHandler.open"
                  }
                ],
                "bamboost.index.IndexAPI": [
                  {
                    "kind": "attribute",
                    "path": "bamboost.index.IndexAPI._instances"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.index.IndexAPI._initialized"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.index.IndexAPI.ThreadSafe"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.index.IndexAPI.__repr__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.index.IndexAPI._repr_html_"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.index.IndexAPI.create_index_table"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.index.IndexAPI.get_database_table"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.index.IndexAPI.read_table"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.index.IndexAPI.fetch"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.index.IndexAPI.insert_path"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.index.IndexAPI.get_id"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.index.IndexAPI.scan_known_paths"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.index.IndexAPI.commit_once"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.index.IndexAPI.clean"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.index.IndexAPI.drop_path"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.index.IndexAPI.check_path"
                  }
                ]
              }
            },
            "RemoteDatabaseTable": {
              "name": "RemoteDatabaseTable",
              "path": "bamboost.extensions.remote_manager.RemoteDatabaseTable",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "id",
                  "annotation": "str",
                  "description": null,
                  "value": null
                },
                {
                  "name": "_index",
                  "annotation": "IndexAPI",
                  "description": null,
                  "value": "None"
                }
              ],
              "attributes": [],
              "docstring": [],
              "functions": {
                "sync": {
                  "name": "sync",
                  "path": "bamboost.extensions.remote_manager.RemoteDatabaseTable.sync",
                  "signature": "(self) -> None",
                  "description": "Don't sync a remote database.",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def sync(self) -> None:\n    \"\"\"Don't sync a remote database.\"\"\"\n    return None"
                }
              },
              "source": "class RemoteDatabaseTable(DatabaseTable):\n    def sync(self) -> None:\n        \"\"\"Don't sync a remote database.\"\"\"\n        return None",
              "inherited_members": {
                "bamboost.index.DatabaseTable": [
                  {
                    "kind": "attribute",
                    "path": "bamboost.index.DatabaseTable._instances"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.index.DatabaseTable.__new__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.index.DatabaseTable.__init__"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.index.DatabaseTable.id"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.index.DatabaseTable._entries"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.index.DatabaseTable._initialized"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.index.DatabaseTable._index"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.index.DatabaseTable.path"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.index.DatabaseTable.tablename_db"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.index.DatabaseTable.tablename_update_times"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.index.DatabaseTable.__getattr__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.index.DatabaseTable.read_table"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.index.DatabaseTable.read_entry"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.index.DatabaseTable.read_column"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.index.DatabaseTable.drop_table"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.index.DatabaseTable.create_database_table"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.index.DatabaseTable.update_entry"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.index.DatabaseTable.entry"
                  }
                ]
              }
            },
            "RemoteManager": {
              "name": "RemoteManager",
              "path": "bamboost.extensions.remote_manager.RemoteManager",
              "description": "Manager class with remote functionality. Constructor takes an existing ID\nof a database on a remote server. The ssh connection must be set up to work\nwithout explicit user authentication. Data is lazily transferred using\nrsync.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "id",
                  "annotation": "str",
                  "description": null,
                  "value": null
                },
                {
                  "name": "remote",
                  "annotation": "Remote",
                  "description": null,
                  "value": null
                },
                {
                  "name": "comm",
                  "annotation": "MPI.Comm",
                  "description": null,
                  "value": "MPI.COMM_WORLD"
                }
              ],
              "attributes": [
                {
                  "name": "UID",
                  "annotation": null,
                  "description": null,
                  "value": "id"
                },
                {
                  "name": "remote",
                  "annotation": null,
                  "description": null,
                  "value": "remote"
                },
                {
                  "name": "comm",
                  "annotation": null,
                  "description": null,
                  "value": "comm"
                },
                {
                  "name": "path",
                  "annotation": null,
                  "description": null,
                  "value": "os.path.join(self.remote.local_path, self.UID)"
                },
                {
                  "name": "remote_path_db",
                  "annotation": null,
                  "description": null,
                  "value": "self._index.get_path(self.UID)"
                },
                {
                  "name": "_index",
                  "annotation": "IndexAPI",
                  "description": null,
                  "value": null
                },
                {
                  "name": "_table",
                  "annotation": "RemoteDatabaseTable",
                  "description": null,
                  "value": null
                }
              ],
              "docstring": [],
              "functions": {
                "__init__": {
                  "name": "__init__",
                  "path": "bamboost.extensions.remote_manager.RemoteManager.__init__",
                  "signature": "(self, id, remote, comm = MPI.COMM_WORLD) -> None",
                  "description": "params\nskip_update: if True, does not lookup the new database on the remote:",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "id",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "remote",
                      "annotation": "Remote",
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "comm",
                      "annotation": "MPI.Comm",
                      "description": null,
                      "value": "MPI.COMM_WORLD"
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def __init__(\n    self,\n    id: str,\n    remote: Remote,\n    comm: MPI.Comm = MPI.COMM_WORLD,\n) -> None:\n    \"\"\"\n    params\n    skip_update: if True, does not lookup the new database on the remote:\n    \"\"\"\n    self.UID = id\n    self.remote = remote\n    self.comm = comm\n    self.path = os.path.join(self.remote.local_path, self.UID)\n    log.info(f\"Creating cache directory at {self.path}\")\n    os.makedirs(self.path, exist_ok=True)\n\n    self.remote_path_db = self._index.get_path(self.UID)\n\n    # check if path exists\n    if not os.path.isdir(self.path):\n        os.makedirs(self.path)\n\n    # Write the database ID file if it does not exist\n    if not os.path.exists(f\"{self.path}/.BAMBOOST-{self.UID}\"):\n        with open(f\"{self.path}/.BAMBOOST-{self.UID}\", \"w\") as f:\n            f.write(self.UID)\n\n    self.UID = id\n    self._index.insert_local_path(self.UID, self.path)\n\n    # Update the SQL table for the database\n    with self._index.open():\n        self._table.create_database_table()"
                },
                "_repr_html_": {
                  "name": "_repr_html_",
                  "path": "bamboost.extensions.remote_manager.RemoteManager._repr_html_",
                  "signature": "(self) -> str",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "str",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def _repr_html_(self) -> str:\n    html_string = pkgutil.get_data(__name__, \"../html/manager.html\").decode()\n    icon = pkgutil.get_data(__name__, \"../html/icon.txt\").decode()\n    return (\n        html_string.replace(\"$ICON\", icon)\n        .replace(\"$db_path\", self.path)\n        .replace(\"$db_uid\", \"euler-\" + self.UID)\n        .replace(\"$db_size\", str(len(self)))\n    )"
                },
                "_get_uids": {
                  "name": "_get_uids",
                  "path": "bamboost.extensions.remote_manager.RemoteManager._get_uids",
                  "signature": "(self) -> list",
                  "description": "Override the simulation list to fetch from databasetable.",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "list",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def _get_uids(self) -> list[str]:\n    \"\"\"Override the simulation list to fetch from databasetable.\"\"\"\n    uids_in_tuple = self._index.fetch(f\"SELECT id FROM db_{self.UID}\")\n    return [uid for (uid,) in uids_in_tuple]"
                },
                "get_view": {
                  "name": "get_view",
                  "path": "bamboost.extensions.remote_manager.RemoteManager.get_view",
                  "signature": "(self, include_linked_sims = False) -> pandas.DataFrame",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "include_linked_sims",
                      "annotation": "bool",
                      "description": null,
                      "value": "False"
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "pandas.DataFrame",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def get_view(self, include_linked_sims: bool = False) -> pd.DataFrame:\n    df = super().get_view(include_linked_sims)\n    df.insert(1, \"cached\", False)\n    for id in os.listdir(self.path):\n        if id in df[\"id\"].values:\n            df.loc[df[\"id\"] == id, \"cached\"] = True\n\n    opts = config.get(\"options\", {})\n    if \"sort_table_key\" in opts:\n        df.sort_values(\n            opts.get(\"sort_table_key\", \"id\"),\n            ascending=opts.get(\"sort_table_order\", \"asc\") == \"asc\",\n            inplace=True,\n        )\n    return df"
                },
                "sim": {
                  "name": "sim",
                  "path": "bamboost.extensions.remote_manager.RemoteManager.sim",
                  "signature": "(self, uid, return_writer = False)",
                  "description": "Return simulation object.",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "uid",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "return_writer",
                      "annotation": "bool",
                      "description": null,
                      "value": "False"
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": null,
                    "description": null
                  },
                  "docstring": [
                    {
                      "kind": "text",
                      "value": "This method checks if the data for the given uid is already in the\nlocal cache. If not, it transfers the data from a remote location using\nrsync. The method then calls the superclass method to perform further\noperations on the transferred data."
                    }
                  ],
                  "source": "def sim(self, uid, return_writer: bool = False):\n    \"\"\"Return simulation object.\n\n    Args:\n        - uid (str): the unique id of the sim to be transferred.\n        - return_writer (bool): Flag to indicate whether to return a writer\n          object. Default is False.\n\n    This method checks if the data for the given uid is already in the\n    local cache. If not, it transfers the data from a remote location using\n    rsync. The method then calls the superclass method to perform further\n    operations on the transferred data.\n    \"\"\"\n    # Check if data is already in cache\n    if os.path.exists(f\"{self.path}/{uid}\"):\n        log.info(f\"Data for {uid} already in cache\")\n        return RemoteSimulation(uid, self)\n\n    # Transfer data using rsync\n    log.info(f\"Data not in cache. Transferring data for {uid} from {self.remote}\")\n    self.rsync(uid)\n\n    return RemoteSimulation(uid, self)"
                },
                "_rsync": {
                  "name": "_rsync",
                  "path": "bamboost.extensions.remote_manager.RemoteManager._rsync",
                  "signature": "(self, uid = None) -> subprocess.Popen",
                  "description": "Transfer data using rsync. This method is called by the `rsync`.\nIt returns the subprocess.Popen object.",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "uid",
                      "annotation": "str | None",
                      "description": [
                        {
                          "kind": "text",
                          "value": "The unique id of the simulation to be transferred. If None,\nall simulations are synced."
                        }
                      ],
                      "value": "None"
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "subprocess.Popen",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def _rsync(self, uid: str | None = None) -> subprocess.Popen:\n    \"\"\"Transfer data using rsync. This method is called by the `rsync`.\n    It returns the subprocess.Popen object.\n\n    Args:\n        uid: The unique id of the simulation to be transferred. If None,\n            all simulations are synced.\n    \"\"\"\n    if uid is not None:\n        log.info(f\"Start syncing data for {uid} with {self.path}\")\n        return subprocess.Popen(\n            [\n                \"rsync\",\n                \"-ravh\",\n                f\"{self.remote.remote_name}:{self.remote_path_db}/{uid}\",\n                f\"{self.path}\",\n            ],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n            text=True,\n        )\n\n    # else, sync entire database directory\n    log.info(f\"Start sync database with {self.path}\")\n    return subprocess.Popen(\n        [\n            \"rsync\",\n            \"-ravh\",\n            f\"{self.remote.remote_name}:{self.remote_path_db}/*\",\n            f\"{self.path}\",\n        ],\n        stdout=subprocess.PIPE,\n        stderr=subprocess.STDOUT,\n        text=True,\n    )"
                },
                "rsync": {
                  "name": "rsync",
                  "path": "bamboost.extensions.remote_manager.RemoteManager.rsync",
                  "signature": "(self, uid = None) -> bamboost.extensions.remote_manager.RemoteManager",
                  "description": "Transfer data using rsync. Wait for the process to finish and return\nself.",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "uid",
                      "annotation": "str | None",
                      "description": [
                        {
                          "kind": "text",
                          "value": "The unique id of the simulation to be transferred. If None,\nall simulations are synced."
                        }
                      ],
                      "value": "None"
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "bamboost.extensions.remote_manager.RemoteManager",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def rsync(self, uid: str | None = None) -> RemoteManager:\n    \"\"\"Transfer data using rsync. Wait for the process to finish and return\n    self.\n\n    Args:\n        uid: The unique id of the simulation to be transferred. If None,\n            all simulations are synced.\n    \"\"\"\n    process = self._rsync(uid)\n    for line in iter(process.stdout.readline, ''):\n        print(line, end='')\n    process.wait()\n    return self"
                }
              },
              "source": "class RemoteManager(Manager):\n    \"\"\"\n    Manager class with remote functionality. Constructor takes an existing ID\n    of a database on a remote server. The ssh connection must be set up to work\n    without explicit user authentication. Data is lazily transferred using\n    rsync.\n    \"\"\"\n\n    # INFO: The initialization of this class takes around 8 seconds because the\n    # home directory of the remote server needs to be fetched, read database\n    # index, and get remote database csv file with db.df in it (see below).\n    def __init__(\n        self,\n        id: str,\n        remote: Remote,\n        comm: MPI.Comm = MPI.COMM_WORLD,\n    ) -> None:\n        \"\"\"\n        params\n        skip_update: if True, does not lookup the new database on the remote:\n        \"\"\"\n        self.UID = id\n        self.remote = remote\n        self.comm = comm\n        self.path = os.path.join(self.remote.local_path, self.UID)\n        log.info(f\"Creating cache directory at {self.path}\")\n        os.makedirs(self.path, exist_ok=True)\n\n        self.remote_path_db = self._index.get_path(self.UID)\n\n        # check if path exists\n        if not os.path.isdir(self.path):\n            os.makedirs(self.path)\n\n        # Write the database ID file if it does not exist\n        if not os.path.exists(f\"{self.path}/.BAMBOOST-{self.UID}\"):\n            with open(f\"{self.path}/.BAMBOOST-{self.UID}\", \"w\") as f:\n                f.write(self.UID)\n\n        self.UID = id\n        self._index.insert_local_path(self.UID, self.path)\n\n        # Update the SQL table for the database\n        with self._index.open():\n            self._table.create_database_table()\n            # self._table.sync()\n\n    def _repr_html_(self) -> str:\n        html_string = pkgutil.get_data(__name__, \"../html/manager.html\").decode()\n        icon = pkgutil.get_data(__name__, \"../html/icon.txt\").decode()\n        return (\n            html_string.replace(\"$ICON\", icon)\n            .replace(\"$db_path\", self.path)\n            .replace(\"$db_uid\", \"euler-\" + self.UID)\n            .replace(\"$db_size\", str(len(self)))\n        )\n\n    def _get_uids(self) -> list[str]:\n        \"\"\"Override the simulation list to fetch from databasetable.\"\"\"\n        uids_in_tuple = self._index.fetch(f\"SELECT id FROM db_{self.UID}\")\n        return [uid for (uid,) in uids_in_tuple]\n\n    @property\n    def _index(self) -> IndexAPI:\n        return self.remote\n\n    @property\n    def _table(self) -> RemoteDatabaseTable:\n        return RemoteDatabaseTable(self.UID, _index=self._index)\n\n    def get_view(self, include_linked_sims: bool = False) -> pd.DataFrame:\n        df = super().get_view(include_linked_sims)\n        df.insert(1, \"cached\", False)\n        for id in os.listdir(self.path):\n            if id in df[\"id\"].values:\n                df.loc[df[\"id\"] == id, \"cached\"] = True\n\n        opts = config.get(\"options\", {})\n        if \"sort_table_key\" in opts:\n            df.sort_values(\n                opts.get(\"sort_table_key\", \"id\"),\n                ascending=opts.get(\"sort_table_order\", \"asc\") == \"asc\",\n                inplace=True,\n            )\n        return df\n\n    def sim(self, uid, return_writer: bool = False):\n        \"\"\"Return simulation object.\n\n        Args:\n            - uid (str): the unique id of the sim to be transferred.\n            - return_writer (bool): Flag to indicate whether to return a writer\n              object. Default is False.\n\n        This method checks if the data for the given uid is already in the\n        local cache. If not, it transfers the data from a remote location using\n        rsync. The method then calls the superclass method to perform further\n        operations on the transferred data.\n        \"\"\"\n        # Check if data is already in cache\n        if os.path.exists(f\"{self.path}/{uid}\"):\n            log.info(f\"Data for {uid} already in cache\")\n            return RemoteSimulation(uid, self)\n\n        # Transfer data using rsync\n        log.info(f\"Data not in cache. Transferring data for {uid} from {self.remote}\")\n        self.rsync(uid)\n\n        return RemoteSimulation(uid, self)\n\n    def _rsync(self, uid: str | None = None) -> subprocess.Popen:\n        \"\"\"Transfer data using rsync. This method is called by the `rsync`.\n        It returns the subprocess.Popen object.\n\n        Args:\n            uid: The unique id of the simulation to be transferred. If None,\n                all simulations are synced.\n        \"\"\"\n        if uid is not None:\n            log.info(f\"Start syncing data for {uid} with {self.path}\")\n            return subprocess.Popen(\n                [\n                    \"rsync\",\n                    \"-ravh\",\n                    f\"{self.remote.remote_name}:{self.remote_path_db}/{uid}\",\n                    f\"{self.path}\",\n                ],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.STDOUT,\n                text=True,\n            )\n\n        # else, sync entire database directory\n        log.info(f\"Start sync database with {self.path}\")\n        return subprocess.Popen(\n            [\n                \"rsync\",\n                \"-ravh\",\n                f\"{self.remote.remote_name}:{self.remote_path_db}/*\",\n                f\"{self.path}\",\n            ],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n            text=True,\n        )\n\n    def rsync(self, uid: str | None = None) -> RemoteManager:\n        \"\"\"Transfer data using rsync. Wait for the process to finish and return\n        self.\n\n        Args:\n            uid: The unique id of the simulation to be transferred. If None,\n                all simulations are synced.\n        \"\"\"\n        process = self._rsync(uid)\n        for line in iter(process.stdout.readline, ''):\n            print(line, end='')\n        process.wait()\n        return self",
              "inherited_members": {
                "bamboost.manager.Manager": [
                  {
                    "kind": "attribute",
                    "path": "bamboost.manager.Manager.FIX_DF"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.manager.Manager.fromUID"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.manager.Manager.fromName"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.manager.Manager.__getitem__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.manager.Manager.__len__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.manager.Manager.__iter__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.manager.Manager._ipython_key_completions_"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.manager.Manager._retrieve_uid"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.manager.Manager._make_new"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.manager.Manager.all_uids"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.manager.Manager.df"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.manager.Manager._get_parameters_for_uid"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.manager.Manager.get_view_from_hdf_files"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.manager.Manager.data_info"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.manager.Manager.sims"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.manager.Manager.create_simulation"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.manager.Manager.remove"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.manager.Manager.find"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.manager.Manager._list_duplicates"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.manager.Manager._check_duplicate"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.manager.Manager._generate_subuid"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.manager.Manager.global_fields_in_all"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.manager.Manager.get_parameters"
                  }
                ]
              }
            },
            "RemoteSimulation": {
              "name": "RemoteSimulation",
              "path": "bamboost.extensions.remote_manager.RemoteSimulation",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "uid",
                  "annotation": "str",
                  "description": null,
                  "value": null
                },
                {
                  "name": "manager",
                  "annotation": "RemoteManager",
                  "description": null,
                  "value": null
                }
              ],
              "attributes": [
                {
                  "name": "manager",
                  "annotation": null,
                  "description": null,
                  "value": "manager"
                }
              ],
              "docstring": [],
              "functions": {
                "__init__": {
                  "name": "__init__",
                  "path": "bamboost.extensions.remote_manager.RemoteSimulation.__init__",
                  "signature": "(self, uid, manager) -> None",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "uid",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "manager",
                      "annotation": "RemoteManager",
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def __init__(self, uid: str, manager: RemoteManager) -> None:\n    super().__init__(uid, manager.path, _db_id=manager.UID)\n    self.manager = manager"
                },
                "sync": {
                  "name": "sync",
                  "path": "bamboost.extensions.remote_manager.RemoteSimulation.sync",
                  "signature": "(self) -> bamboost.extensions.remote_manager.RemoteSimulation",
                  "description": "Sync the simulation data with the remote server.",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "bamboost.extensions.remote_manager.RemoteSimulation",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def sync(self) -> RemoteSimulation:\n    \"\"\"Sync the simulation data with the remote server.\"\"\"\n    self.manager.rsync(self.uid)\n    return self"
                },
                "get_full_uid": {
                  "name": "get_full_uid",
                  "path": "bamboost.extensions.remote_manager.RemoteSimulation.get_full_uid",
                  "signature": "(self) -> str",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "str",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def get_full_uid(self) -> str:\n    return f\"ssh://{self.manager.remote.remote_name}/{self.manager.UID}:{self.uid}\""
                }
              },
              "source": "class RemoteSimulation(Simulation):\n    def __init__(self, uid: str, manager: RemoteManager) -> None:\n        super().__init__(uid, manager.path, _db_id=manager.UID)\n        self.manager = manager\n\n    def sync(self) -> RemoteSimulation:\n        \"\"\"Sync the simulation data with the remote server.\"\"\"\n        self.manager.rsync(self.uid)\n        return self\n\n    def get_full_uid(self) -> str:\n        return f\"ssh://{self.manager.remote.remote_name}/{self.manager.UID}:{self.uid}\"",
              "inherited_members": {
                "bamboost.simulation.Simulation": [
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation._mesh_location"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation._default_mesh"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.uid"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.path_database"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.database_id"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.path"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.h5file"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.xdmffile"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation._comm"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation._psize"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation._prank"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation._ranks"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation._file"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.meshes"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.data"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.globals"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.userdata"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.links"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.fromUID"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.__getitem__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation._repr_html_"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation._push_update_to_sqlite"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.parameters"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.metadata"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.files"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.show_files"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.open_in_file_explorer"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.open_in_paraview"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.change_status"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.update_metadata"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.update_parameters"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.create_xdmf_file"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.create_run_script"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.create_batch_script"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.submit"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.change_note"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.open"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.mesh"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.get_mesh"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.data_info"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.simulation.Simulation.git"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.get_data_interpolator"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.show_h5tree"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.simulation.Simulation.enter_path"
                  }
                ]
              }
            }
          },
          "functions": {
            "_extend_manager_from_uid_getitem": {
              "name": "_extend_manager_from_uid_getitem",
              "path": "bamboost.extensions.remote_manager._extend_manager_from_uid_getitem",
              "signature": "(original_getitem)",
              "description": "Extend the __getitem__ method of ManagerFromUID to handle remote keys.\nIn the following format: ssh://<remote_name>/<id>.",
              "parameters": [
                {
                  "name": "original_getitem",
                  "annotation": "Callable",
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def _extend_manager_from_uid_getitem(original_getitem: Callable):\n    \"\"\"Extend the __getitem__ method of ManagerFromUID to handle remote keys.\n    In the following format: ssh://<remote_name>/<id>.\n    \"\"\"\n\n    @wraps(original_getitem)\n    def modified_getitem(self: ManagerFromUID, key: str):\n        # If key starts with ssh://, it is a remote key\n        # Format: ssh://<remote_name>/<id>\n        if key.startswith(\"ssh://\"):\n            remote_name = key.split(\"/\")[2]\n            key = key.split(\"/\")[3]\n            try:\n                remote = Remote(remote_name, skip_update=True)\n                return remote[key]\n            except KeyError:\n                remote = Remote(remote_name, skip_update=False)\n                return remote[key]\n\n        return original_getitem(self, key)\n\n    return modified_getitem"
            },
            "_extend_simulation_from_uid": {
              "name": "_extend_simulation_from_uid",
              "path": "bamboost.extensions.remote_manager._extend_simulation_from_uid",
              "signature": "(original_from_uid)",
              "description": "Extend the fromUID method of Simulation to handle remote keys.\nIn the following format: ssh://<remote_name>/<id>:<uid>.",
              "parameters": [
                {
                  "name": "original_from_uid",
                  "annotation": "Callable",
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def _extend_simulation_from_uid(original_from_uid: Callable):\n    \"\"\"Extend the fromUID method of Simulation to handle remote keys.\n    In the following format: ssh://<remote_name>/<id>:<uid>.\n    \"\"\"\n\n    @wraps(original_from_uid)\n    def modified_from_uid(cls: Simulation, key: str):\n        # If key starts with ssh://, it is a remote key\n        # Format: ssh://<remote_name>/<db_id>:<sim_id>\n        if key.startswith(\"ssh://\"):\n            remote_name = key.split(\"/\")[2]\n            full_id = key.split(\"/\")[3]\n            db_id, sim_id = full_id.split(\":\")\n            remote = Remote(remote_name, skip_update=True)\n            return remote[db_id].sim(sim_id)\n\n        return original_from_uid(key)\n\n    return modified_from_uid"
            }
          }
        },
        "use_locking": {
          "name": "use_locking",
          "path": "bamboost.extensions.use_locking",
          "filepath": "/home/florez/work/code/bamboost/bamboost/extensions/use_locking.py",
          "description": "This module provides a custom rather primitive file locking mechanism for\nHDF5 files.\n\nThis module provides a function `use_locking` that installs the mechanism by\nMonkey-patching the `FileHandler` class. To use this mechanism, call the\n`use_locking` function at the start of your script, before creating any\n`bamboost.common.file_handler.FileHandler` instances.",
          "docstring": [
            {
              "kind": "admonition",
              "value": {
                "annotation": "example",
                "description": ">>> from bamboost.extensions.use_locking import use_locking\n>>> use_locking(\"shared\")"
              },
              "title": "Example"
            }
          ],
          "attributes": [],
          "modules": {},
          "classes": {},
          "functions": {
            "get_lock_and_open_function": {
              "name": "get_lock_and_open_function",
              "path": "bamboost.extensions.use_locking.get_lock_and_open_function",
              "signature": "(lock_type) -> collections.abc.Callable",
              "description": "Returns a function that locks and opens an HDF5 file with the specified\nlock type.\n\nThe returned function acquires a lock on the lock file and opens the HDF5\nfile, returning both the opened HDF5 file object and the lock file object.\n\nThe returned function takes the following parameters:\n\n| Argument  | Description                                                                 |\n|-----------|-----------------------------------------------------------------------------|\n| file      | The path to the HDF5 file to open.                                          |\n| lock_file | The path to the lock file.                                                  |\n| mode      | The mode to open the file in (e.g., 'r', 'w', 'a').                         |\n| driver    | The HDF5 driver to use (e.g., 'mpio' for MPI-IO).                           |\n| comm      | The MPI communicator (only used with 'mpio' driver).                        |",
              "parameters": [
                {
                  "name": "lock_type",
                  "annotation": "Literal",
                  "description": [
                    {
                      "kind": "text",
                      "value": "The type of lock to use."
                    }
                  ]
                }
              ],
              "returns": {
                "name": "Callable",
                "annotation": "collections.abc.Callable",
                "description": "A function that locks and opens an HDF5 file."
              },
              "docstring": [],
              "source": "def get_lock_and_open_function(\n    lock_type: Literal[\"shared\", \"exclusive\"],\n) -> Callable[..., Tuple[h5py.File, BufferedReader]]:\n    \"\"\"Returns a function that locks and opens an HDF5 file with the specified\n    lock type.\n\n    The returned function acquires a lock on the lock file and opens the HDF5\n    file, returning both the opened HDF5 file object and the lock file object.\n\n    The returned function takes the following parameters:\n\n    | Argument  | Description                                                                 |\n    |-----------|-----------------------------------------------------------------------------|\n    | file      | The path to the HDF5 file to open.                                          |\n    | lock_file | The path to the lock file.                                                  |\n    | mode      | The mode to open the file in (e.g., 'r', 'w', 'a').                         |\n    | driver    | The HDF5 driver to use (e.g., 'mpio' for MPI-IO).                           |\n    | comm      | The MPI communicator (only used with 'mpio' driver).                        |\n\n    Args:\n        lock_type (Literal[\"shared\", \"exclusive\"]): The type of lock to use.\n\n    Returns:\n        Callable: A function that locks and opens an HDF5 file.\n    \"\"\"\n    lock_type_int = {\"shared\": fcntl.LOCK_SH, \"exclusive\": fcntl.LOCK_EX}[lock_type]\n\n    def lock_and_open(\n        file: str, lock_file: str, mode: str, driver: str, comm: Any\n    ) -> Tuple[h5py.File, BufferedReader]:\n        lock_file_object = open(lock_file, \"rb\")\n        # acquire a lock\n        fcntl.flock(lock_file_object, lock_type_int)\n        # open the file\n        h5_file = open_h5file(file, mode, driver, comm)\n        return h5_file, lock_file_object\n\n    return lock_and_open"
            },
            "close_and_unlock": {
              "name": "close_and_unlock",
              "path": "bamboost.extensions.use_locking.close_and_unlock",
              "signature": "(h5_file, lock_file) -> None",
              "description": "Close an HDF5 file and release the associated file lock.\n\nThis function performs the following operations:\n1. Closes the given HDF5 file.\n2. Releases the lock on the lock file.\n3. Closes the lock file.",
              "parameters": [
                {
                  "name": "h5_file",
                  "annotation": "h5py.File",
                  "description": [
                    {
                      "kind": "text",
                      "value": "The HDF5 file object to be closed."
                    }
                  ]
                },
                {
                  "name": "lock_file",
                  "annotation": "BufferedReader",
                  "description": [
                    {
                      "kind": "text",
                      "value": "The lock file object to be unlocked and closed."
                    }
                  ]
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": "None"
              },
              "docstring": [],
              "source": "def close_and_unlock(h5_file: h5py.File, lock_file: BufferedReader) -> None:\n    \"\"\"Close an HDF5 file and release the associated file lock.\n\n    This function performs the following operations:\n    1. Closes the given HDF5 file.\n    2. Releases the lock on the lock file.\n    3. Closes the lock file.\n\n    Args:\n        h5_file: The HDF5 file object to be closed.\n        lock_file: The lock file object to be unlocked and closed.\n\n    Returns:\n        None\n    \"\"\"\n    h5_file.close()\n    fcntl.flock(lock_file, fcntl.LOCK_UN)\n    lock_file.close()"
            },
            "get_open_method": {
              "name": "get_open_method",
              "path": "bamboost.extensions.use_locking.get_open_method",
              "signature": "(lock_type) -> collections.abc.Callable",
              "description": null,
              "parameters": [
                {
                  "name": "lock_type",
                  "annotation": "Literal",
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "collections.abc.Callable",
                "description": null
              },
              "docstring": [],
              "source": "def get_open_method(\n    lock_type: Literal[\"shared\", \"exclusive\"],\n) -> Callable[..., h5py.File]:\n    open_function = get_lock_and_open_function(lock_type)\n\n    @wraps(FileHandler.open)\n    def _modified_open(self: FileHandler, mode: str = \"r\", driver=None, comm=None):\n        \"\"\"Create a primitive lock file for the file.\n\n        Will replace `file_handler.FileHandler.open` method.\n        \"\"\"\n        if self._lock <= 0:\n            # lock_file_access(self.file_name, comm)\n\n            log.debug(f\"[{id(self)}] Open {self.file_name}\")\n            # self.file_object = open_h5file(self.file_name, mode, driver, comm)\n            self.file_object, self._lock_file = open_function(  # type: ignore\n                self.file_name, self._lock_file_name, mode, driver, comm\n            )\n\n        if FILE_MODE_HIRARCHY[self.file_object.mode] < FILE_MODE_HIRARCHY[mode]:\n            close_and_unlock(self.file_object, self._lock_file)\n            self.file_object, self._lock_file = open_function(  # type: ignore\n                self.file_name, self._lock_file_name, mode, driver, comm\n            )\n\n        log.debug(f\"[{id(self)}] Lock stack {self._lock}\")\n        self._lock += 1\n        return self.file_object\n\n    return _modified_open"
            },
            "_modified_close": {
              "name": "_modified_close",
              "path": "bamboost.extensions.use_locking._modified_close",
              "signature": "(self)",
              "description": "Create a primitive lock for the file.\n\nWill replace `file_handler.FileHandler.close` method.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": "FileHandler",
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "@wraps(FileHandler.close)\ndef _modified_close(self: FileHandler):\n    \"\"\"Create a primitive lock for the file.\n\n    Will replace `file_handler.FileHandler.close` method.\n    \"\"\"\n    self._lock -= 1\n    if self._lock == 0:\n        log.debug(f\"[{id(self)}] Close {self.file_name}\")\n        # self.file_object.close()\n        close_and_unlock(self.file_object, self._lock_file)\n\n    log.debug(f\"[{id(self)}] Lock stack {self._lock}\")"
            },
            "_extend_init": {
              "name": "_extend_init",
              "path": "bamboost.extensions.use_locking._extend_init",
              "signature": "(original_init)",
              "description": null,
              "parameters": [
                {
                  "name": "original_init",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def _extend_init(original_init):\n    @wraps(FileHandler.__init__)\n    def _modified_init(self: FileHandler, *args, **kwargs):\n        original_init(self, *args, **kwargs)\n\n        self._lock_file_name = f\"{self.file_name}.lock\"  # type: ignore\n\n        if not os.path.exists(self._lock_file_name):\n            with open(self._lock_file_name, \"w\") as f:\n                f.write(\"LOCK FILE\")\n\n    return _modified_init"
            },
            "use_locking": {
              "name": "use_locking",
              "path": "bamboost.extensions.use_locking.use_locking",
              "signature": "(lock_type) -> None",
              "description": "Installs a primitive locking mechanism for FileHandler operations.\n\nThis function modifies the FileHandler class to include file locking\ncapabilities, ensuring thread-safe access to files. It wraps the\n`__init__`, `open`, and `close` methods of FileHandler with locking mechanisms.",
              "parameters": [
                {
                  "name": "lock_type",
                  "annotation": "Literal",
                  "description": [
                    {
                      "kind": "text",
                      "value": "The type of lock to use.\n- \"shared\" allows multiple processes to open the file simultaneously.\n- \"exclusive\" allows only one reader or writer at a time."
                    }
                  ]
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [
                {
                  "kind": "admonition",
                  "value": {
                    "annotation": "usage",
                    "description": "Call this function before using FileHandler to enable locking:\nuse_locking(\"shared\")  # or use_locking(\"exclusive\")"
                  },
                  "title": "Usage"
                },
                {
                  "kind": "admonition",
                  "value": {
                    "annotation": "note",
                    "description": "This function should be called only once, preferably at the start\nof your program, before any FileHandler instances are created."
                  },
                  "title": "Note"
                },
                {
                  "kind": "admonition",
                  "value": {
                    "annotation": "note",
                    "description": "You should only need this functionality if you are using HDF5 <= 1.10.6.\nThe newer versions of HDF5 (>= 1.10.7) have built-in file locking."
                  },
                  "title": "Note"
                }
              ],
              "source": "def use_locking(lock_type: Literal[\"shared\", \"exclusive\"]) -> None:\n    \"\"\"Installs a primitive locking mechanism for FileHandler operations.\n\n    This function modifies the FileHandler class to include file locking\n    capabilities, ensuring thread-safe access to files. It wraps the\n    `__init__`, `open`, and `close` methods of FileHandler with locking mechanisms.\n\n    Usage:\n        Call this function before using FileHandler to enable locking:\n        use_locking(\"shared\")  # or use_locking(\"exclusive\")\n\n    Note:\n        This function should be called only once, preferably at the start\n        of your program, before any FileHandler instances are created.\n\n    Note:\n        You should only need this functionality if you are using HDF5 <= 1.10.6.\n        The newer versions of HDF5 (>= 1.10.7) have built-in file locking.\n\n    Args:\n        lock_type (Literal[\"shared\", \"exclusive\"]): The type of lock to use.\n            - \"shared\" allows multiple processes to open the file simultaneously.\n            - \"exclusive\" allows only one reader or writer at a time.\n    \"\"\"\n    if not hasattr(FileHandler.__init__, \"__wrapped__\"):\n        FileHandler.__init__ = _extend_init(FileHandler.__init__)\n\n    if not hasattr(FileHandler.open, \"__wrapped__\"):\n        FileHandler.open = get_open_method(lock_type)\n\n    if not hasattr(FileHandler.close, \"__wrapped__\"):\n        FileHandler.close = _modified_close\n\n    log.info(\"Primitive locking installed\")"
            }
          }
        }
      },
      "classes": {
        "ExtensionsLazyLoader": {
          "name": "ExtensionsLazyLoader",
          "path": "bamboost.extensions.ExtensionsLazyLoader",
          "description": null,
          "parameters": [],
          "attributes": [
            {
              "name": "FenicsWriter",
              "annotation": null,
              "description": null,
              "value": null
            },
            {
              "name": "Remote",
              "annotation": null,
              "description": null,
              "value": null
            },
            {
              "name": "RemoteManager",
              "annotation": null,
              "description": null,
              "value": null
            },
            {
              "name": "install_slurm",
              "annotation": null,
              "description": null,
              "value": null
            }
          ],
          "docstring": [],
          "functions": {},
          "source": "class ExtensionsLazyLoader:\n    # This pattern is used to provide a single point/namespace to access all\n    # the extensions without importing them directly.\n    # \n    # TODO: this is the best way I could come up with, please suggest a better\n    # approach if you have one.\n\n    @property\n    def FenicsWriter(self):\n        from .fenics import FenicsWriter\n        return FenicsWriter\n\n    @property\n    def Remote(self):\n        from .remote_manager import Remote\n        return Remote\n\n    @property\n    def RemoteManager(self):\n        from .remote_manager import RemoteManager\n        return RemoteManager\n\n    @property\n    def install_slurm(self):\n        from .slurm import install\n        return install",
          "inherited_members": {}
        }
      },
      "functions": {}
    },
    "_config": {
      "name": "_config",
      "path": "bamboost._config",
      "filepath": "/home/florez/work/code/bamboost/bamboost/_config.py",
      "description": "The module includes functions to copy an example config file to the user's\nconfig directory and load the config file from the directory. If the config\nfile does not exist, a copy of the example config file will be created.",
      "docstring": [
        {
          "kind": "functions",
          "value": [
            {
              "name": "- _copy_config_file",
              "annotation": "- _copy_config_file()",
              "description": "Copies the example config file to the user's config\ndirectory."
            },
            {
              "name": "- _load_config_file",
              "annotation": "- _load_config_file()",
              "description": "Loads the config file from the user's config\ndirectory."
            }
          ]
        }
      ],
      "attributes": [
        {
          "name": "__all__",
          "annotation": null,
          "description": null,
          "value": "['paths', 'config']"
        },
        {
          "name": "_home_dir",
          "annotation": null,
          "description": null,
          "value": "os.path.expanduser('~')"
        },
        {
          "name": "paths",
          "annotation": null,
          "description": null,
          "value": "{'HOME': os.path.expanduser('~'), 'CONFIG_DIR': os.path.join(_home_dir, '.config', 'bamboost'), 'LOCAL_DIR': os.path.join(_home_dir, '.local', 'share', 'bamboost'), 'CONFIG_FILE': os.path.join(_home_dir, '.config', 'bamboost', 'config.toml'), 'DATABASE_FILE': os.path.join(_home_dir, '.local', 'share', 'bamboost', 'bamboost.db')}"
        },
        {
          "name": "config",
          "annotation": null,
          "description": null,
          "value": "_load_config_file()"
        }
      ],
      "modules": {},
      "classes": {},
      "functions": {
        "_copy_config_file": {
          "name": "_copy_config_file",
          "path": "bamboost._config._copy_config_file",
          "signature": "(file)",
          "description": "Copy the example config file to the user's config directory.",
          "parameters": [
            {
              "name": "file",
              "annotation": "str",
              "description": null,
              "value": null
            }
          ],
          "returns": {
            "name": "",
            "annotation": null,
            "description": null
          },
          "docstring": [
            {
              "kind": "raises",
              "value": [
                {
                  "annotation": "-FileExistsError",
                  "description": "If the config file already exists in the destination\ndirectory."
                }
              ]
            }
          ],
          "source": "def _copy_config_file(file: str):\n    \"\"\"Copy the example config file to the user's config directory.\n\n    Raises:\n        - FileExistsError: If the config file already exists in the destination\n          directory.\"\"\"\n    # If file exists, raise an error\n    if os.path.exists(file):\n        raise FileExistsError(\"Config file already exists\")\n\n    # source_file = \"_example_config.toml\"\n    source_file: bytes = pkgutil.get_data(\"bamboost\", \"_example_config.toml\")\n\n    # Copy the source file to the destination\n    with open(file, \"wb\") as f:\n        f.write(source_file)"
        },
        "_load_config_file": {
          "name": "_load_config_file",
          "path": "bamboost._config._load_config_file",
          "signature": "(file = None)",
          "description": "Load the config file from the user's config directory.\n\nIf the config file does not exist, a copy of the example config file will\nbe created.",
          "parameters": [
            {
              "name": "file",
              "annotation": "str",
              "description": null,
              "value": "None"
            }
          ],
          "returns": {
            "name": "",
            "annotation": null,
            "description": "- dict: The contents of the config file as a dictionary."
          },
          "docstring": [],
          "source": "def _load_config_file(file: str = None):\n    \"\"\"Load the config file from the user's config directory.\n\n    If the config file does not exist, a copy of the example config file will\n    be created.\n\n    Returns:\n        - dict: The contents of the config file as a dictionary.\n    \"\"\"\n    # Load the config file\n    if file is None:\n        file = paths[\"CONFIG_FILE\"]\n    try:\n        with open(file, \"rb\") as f:\n            return tomli.load(f)\n    except FileNotFoundError:\n        _copy_config_file(file)\n        return _load_config_file(file)"
        }
      }
    },
    "simulation_writer": {
      "name": "simulation_writer",
      "path": "bamboost.simulation_writer",
      "filepath": "/home/florez/work/code/bamboost/bamboost/simulation_writer.py",
      "description": null,
      "docstring": [],
      "attributes": [
        {
          "name": "__all__",
          "annotation": null,
          "description": null,
          "value": "['SimulationWriter']"
        },
        {
          "name": "log",
          "annotation": null,
          "description": null,
          "value": "BAMBOOST_LOGGER.getChild(__name__.split('.')[-1])"
        }
      ],
      "modules": {},
      "classes": {
        "SimulationWriter": {
          "name": "SimulationWriter",
          "path": "bamboost.simulation_writer.SimulationWriter",
          "description": "The SimulationWriter is the writer object for a single simulation. It inherits\nall reading methods from :class:`Simulation`.\n\nThis class can be used as a context manager. When entering the context, the status\nof the simulation is changed to \"Started\". When an exception is raised inside the\ncontext, the status is changed to \"Failed [Exception]\".",
          "parameters": [
            {
              "name": "self",
              "annotation": null,
              "description": null,
              "value": null
            },
            {
              "name": "uid",
              "annotation": "str",
              "description": [
                {
                  "kind": "text",
                  "value": "The identifier of the simulation"
                }
              ]
            },
            {
              "name": "path",
              "annotation": "str",
              "description": [
                {
                  "kind": "text",
                  "value": "The (parent) database path"
                }
              ]
            },
            {
              "name": "comm",
              "annotation": "MPI.Comm",
              "description": [
                {
                  "kind": "text",
                  "value": "An MPI communicator (Default: `MPI.COMM_WORLD`)"
                }
              ],
              "value": "MPI.COMM_WORLD"
            },
            {
              "name": "create_if_not_exists",
              "annotation": "bool",
              "description": null,
              "value": "True"
            }
          ],
          "attributes": [
            {
              "name": "step",
              "annotation": "int",
              "description": null,
              "value": "0"
            }
          ],
          "docstring": [],
          "functions": {
            "__init__": {
              "name": "__init__",
              "path": "bamboost.simulation_writer.SimulationWriter.__init__",
              "signature": "(self, uid, path, comm = MPI.COMM_WORLD, create_if_not_exists = True)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "uid",
                  "annotation": "str",
                  "description": null,
                  "value": null
                },
                {
                  "name": "path",
                  "annotation": "str",
                  "description": null,
                  "value": null
                },
                {
                  "name": "comm",
                  "annotation": "MPI.Comm",
                  "description": null,
                  "value": "MPI.COMM_WORLD"
                },
                {
                  "name": "create_if_not_exists",
                  "annotation": "bool",
                  "description": null,
                  "value": "True"
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def __init__(\n    self,\n    uid: str,\n    path: str,\n    comm: MPI.Comm = MPI.COMM_WORLD,\n    create_if_not_exists: bool = True,\n):\n    super().__init__(uid, path, comm, create_if_not_exists)\n    self.step: int = 0"
            },
            "__enter__": {
              "name": "__enter__",
              "path": "bamboost.simulation_writer.SimulationWriter.__enter__",
              "signature": "(self)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def __enter__(self):\n    self.change_status(\"Started\")  # change status to running (process 0 only)\n    self._comm.barrier()  # wait for change status to be written\n    return self"
            },
            "__exit__": {
              "name": "__exit__",
              "path": "bamboost.simulation_writer.SimulationWriter.__exit__",
              "signature": "(self, exc_type, exc_val, exc_tb)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "exc_type",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "exc_val",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "exc_tb",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def __exit__(self, exc_type, exc_val, exc_tb):\n    if exc_type:\n        self.change_status(f\"Failed [{exc_type.__name__}]\")\n        log.error(f\"Simulation failed with {exc_type.__name__}: {exc_val}\")\n        log.error(exc_tb)\n        raise RuntimeError(f\"Simulation failed [Process {self._prank}]\")\n    self._comm.barrier()"
            },
            "initialize": {
              "name": "initialize",
              "path": "bamboost.simulation_writer.SimulationWriter.initialize",
              "signature": "(self) -> bamboost.simulation_writer.SimulationWriter",
              "description": "Create a new file for this simlation.\nThis deletes an existing h5 file of the simulation and creates an empty new one",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "bamboost.simulation_writer.SimulationWriter",
                "description": null
              },
              "docstring": [],
              "source": "def initialize(self) -> SimulationWriter:\n    \"\"\"Create a new file for this simlation.\n    This deletes an existing h5 file of the simulation and creates an empty new one\n    \"\"\"\n    self.step = 0\n    self.add_metadata()\n    self.change_status(\"Initiated\")\n\n    return self"
            },
            "add_metadata": {
              "name": "add_metadata",
              "path": "bamboost.simulation_writer.SimulationWriter.add_metadata",
              "signature": "(self) -> None",
              "description": "Add metadata to h5 file.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def add_metadata(self) -> None:\n    \"\"\"Add metadata to h5 file.\"\"\"\n    nb_proc = self._comm.Get_size()\n    if self._prank == 0:\n        with self._file(\"a\"):\n            data = {\n                \"time_stamp\": str(datetime.datetime.now().replace(microsecond=0)),\n                \"id\": self.uid,\n                \"processors\": nb_proc,\n                \"notes\": self._file.attrs.get(\"notes\", \"\"),\n            }\n            self._file.attrs.update(data)\n        self._push_update_to_sqlite(data)"
            },
            "add_parameters": {
              "name": "add_parameters",
              "path": "bamboost.simulation_writer.SimulationWriter.add_parameters",
              "signature": "(self, parameters) -> None",
              "description": "Add parameters to simulation.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "parameters",
                  "annotation": "dict",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Dictionary with parameters."
                    }
                  ]
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def add_parameters(self, parameters: dict) -> None:\n    \"\"\"Add parameters to simulation.\n\n    Args:\n        parameters: Dictionary with parameters.\n    \"\"\"\n    if self._prank == 0:\n        with self._file(\"a\"):\n            # flatten parameters\n            parameters = flatten_dict(parameters)\n\n            if \"parameters\" in self._file.keys():\n                del self._file[\"parameters\"]\n            grp = self._file.create_group(\"/parameters\")\n            for key, val in parameters.items():\n                if isinstance(val, np.ndarray):\n                    grp.create_dataset(key, data=val)\n                elif val is not None:\n                    grp.attrs[key] = val\n        self._push_update_to_sqlite(parameters)"
            },
            "add_mesh": {
              "name": "add_mesh",
              "path": "bamboost.simulation_writer.SimulationWriter.add_mesh",
              "signature": "(self, coordinates, connectivity, mesh_name = None) -> None",
              "description": "Add the mesh to file. Currently only 2d meshes.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "coordinates",
                  "annotation": "np.ndarray",
                  "description": null,
                  "value": null
                },
                {
                  "name": "connectivity",
                  "annotation": "np.ndarray",
                  "description": null,
                  "value": null
                },
                {
                  "name": "mesh_name",
                  "annotation": "str",
                  "description": null,
                  "value": "None"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [
                {
                  "kind": "admonition",
                  "value": {
                    "annotation": "note",
                    "description": "If you are working with FEniCS, you can use the\n`bamboost.extensions.fenics.FenicsWriter` writer. With it you can\nwrite the FEniCS mesh directly."
                  },
                  "title": "Note"
                },
                {
                  "kind": "text",
                  "value": "Args:\n    coordinates: Coordinates as array (nb_nodes, dim)\n    connectivity: Connectivity matrix (nb_cells, nb nodes per cell)\n    mesh_name: name for mesh (default = `mesh`)"
                }
              ],
              "source": "def add_mesh(\n    self, coordinates: np.ndarray, connectivity: np.ndarray, mesh_name: str = None\n) -> None:\n    \"\"\"Add the mesh to file. Currently only 2d meshes.\n\n    Note:\n        If you are working with FEniCS, you can use the\n        `bamboost.extensions.fenics.FenicsWriter` writer. With it you can\n        write the FEniCS mesh directly.\n    Args:\n        coordinates: Coordinates as array (nb_nodes, dim)\n        connectivity: Connectivity matrix (nb_cells, nb nodes per cell)\n        mesh_name: name for mesh (default = `mesh`)\n    \"\"\"\n    if mesh_name is None:\n        mesh_name = self._default_mesh\n    # self._mesh_location = 'Mesh/0/mesh/'\n    mesh_location = f\"{self._mesh_location}/{mesh_name}/\"\n\n    nb_nodes_local = coordinates.shape[0]\n    nb_cells_local = connectivity.shape[0]\n\n    # gather total mesh\n    nb_nodes_p = np.array(self._comm.allgather(nb_nodes_local))\n    nb_cells_p = np.array(self._comm.allgather(nb_cells_local))\n    nb_nodes, nb_cells = np.sum(nb_nodes_p), np.sum(nb_cells_p)\n\n    # shape of datasets\n    coord_shape = (\n        (nb_nodes, coordinates.shape[1]) if coordinates.ndim > 1 else (nb_nodes,)\n    )\n    conn_shape = (\n        (nb_cells, connectivity.shape[1]) if connectivity.ndim > 1 else (nb_cells,)\n    )\n\n    # global indices nodes\n    idx_start = np.sum(nb_nodes_p[self._ranks < self._prank])\n    idx_end = idx_start + nb_nodes_local\n\n    # global indices cells\n    idx_start_cells = np.sum(nb_cells_p[self._ranks < self._prank])\n    idx_end_cells = idx_start_cells + nb_cells_local\n    connectivity = connectivity + idx_start\n\n    with self._file(\"a\", driver=\"mpio\", comm=self._comm) as f:\n        if mesh_location in self._file.file_object:\n            del self._file.file_object[mesh_location]\n        grp = f.require_group(mesh_location)\n        coord = grp.require_dataset(\n            \"coordinates\", shape=coord_shape, dtype=coordinates.dtype\n        )\n        conn = grp.require_dataset(\n            \"topology\", shape=conn_shape, dtype=connectivity.dtype\n        )\n\n        coord[idx_start:idx_end] = coordinates\n        conn[idx_start_cells:idx_end_cells] = connectivity"
            },
            "add_field": {
              "name": "add_field",
              "path": "bamboost.simulation_writer.SimulationWriter.add_field",
              "signature": "(self, name, vector, time = None, mesh = None, dtype = None, center = 'Node') -> None",
              "description": "Add a dataset to the file. The data is stored at `data/`.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "name",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Name for the dataset"
                    }
                  ]
                },
                {
                  "name": "vector",
                  "annotation": "np.array",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Dataset"
                    }
                  ]
                },
                {
                  "name": "time",
                  "annotation": "float",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Optional. time"
                    }
                  ],
                  "value": "None"
                },
                {
                  "name": "mesh",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Optional. Linked mesh for this data"
                    }
                  ],
                  "value": "None"
                },
                {
                  "name": "dtype",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Optional. Numpy style datatype, see h5py documentation,\ndefaults to the dtype of the vector."
                    }
                  ],
                  "value": "None"
                },
                {
                  "name": "center",
                  "annotation": "Literal",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Optional. Center of the data. Can be 'Node' or 'Cell'.\nDefault is 'Node'."
                    }
                  ],
                  "value": "'Node'"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def add_field(\n    self,\n    name: str,\n    vector: np.array,\n    time: float = None,\n    mesh: str = None,\n    dtype: str = None,\n    center: Literal[\"Node\", \"Cell\"] = \"Node\",\n) -> None:\n    \"\"\"Add a dataset to the file. The data is stored at `data/`.\n\n    Args:\n        name: Name for the dataset\n        vector: Dataset\n        time: Optional. time\n        mesh: Optional. Linked mesh for this data\n        dtype: Optional. Numpy style datatype, see h5py documentation,\n            defaults to the dtype of the vector.\n        center: Optional. Center of the data. Can be 'Node' or 'Cell'.\n            Default is 'Node'.\n    \"\"\"\n    if mesh is None:\n        mesh = self._default_mesh\n\n    if time is None:\n        time = self.step\n\n    self._dump_array(f\"data/{name}/{self.step}\", vector, dtype=dtype)\n    self._comm.barrier()  # attempt to fix bug (see SimulationWriter add_field)\n\n    if self._prank == 0:\n        with self._file(\"a\"):\n            # Sometimes this fails with (if simultaneously trying to read the file)\n            # KeyError: 'Unable to synchronously open object (addr overflow, addr = 247903512, size = 328, eoa = 247903240)'\n            # KeyError: 'Unable to synchronously open object (len not positive after adjustment for EOA)'\n            # I don't know exactly what is going on.\n            # It could be that some process is still writing and then it's opened again and the dataset doesn't exist properly\n            # OR the other processes try to open the file already for the next time while this one is waiting\n            vec = self._file[\"data\"][name][str(self.step)]\n            vec.attrs.update({\"center\": center, \"mesh\": mesh, \"t\": time})\n\n    self._comm.barrier()  # attempt to fix bug (see SimulationWriter add_field)"
            },
            "_dump_array": {
              "name": "_dump_array",
              "path": "bamboost.simulation_writer.SimulationWriter._dump_array",
              "signature": "(self, location, arr, dtype = None) -> None",
              "description": "Dump an array to the file. Correctly patch together multi-rank arrays.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "location",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Location in the file"
                    }
                  ]
                },
                {
                  "name": "arr",
                  "annotation": "np.ndarray",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Array to dump"
                    }
                  ]
                },
                {
                  "name": "dtype",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Optional. Numpy style datatype, see h5py documentation,\ndefaults to the dtype of the vector."
                    }
                  ],
                  "value": "None"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def _dump_array(self, location: str, arr: np.ndarray, dtype: str = None) -> None:\n    \"\"\"Dump an array to the file. Correctly patch together multi-rank arrays.\n\n    Args:\n        location: Location in the file\n        arr: Array to dump\n        dtype: Optional. Numpy style datatype, see h5py documentation,\n            defaults to the dtype of the vector.\n    \"\"\"\n    dim = arr.shape[1:] if arr.ndim > 1 else None\n    length_local = arr.shape[0]\n    length_p = np.array(self._comm.allgather(length_local))\n    length = np.sum(length_p)\n\n    # split location into group and dataset\n    group_name, dataset_name = location.rstrip(\"/\").rsplit(\"/\", 1)\n\n    # global indices\n    idx_start = np.sum(length_p[self._ranks < self._prank])\n    idx_end = idx_start + length_local\n\n    # open file\n    with self._file(\"a\", driver=\"mpio\", comm=self._comm) as f:\n        grp = f.require_group(group_name)\n        vec = grp.require_dataset(\n            dataset_name,\n            shape=(length, *dim) if dim else (length,),\n            dtype=dtype if dtype else arr.dtype,\n        )\n        vec[idx_start:idx_end] = arr"
            },
            "add_fields": {
              "name": "add_fields",
              "path": "bamboost.simulation_writer.SimulationWriter.add_fields",
              "signature": "(self, fields, time = None, mesh = None) -> None",
              "description": "Add multiple fields at once.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "fields",
                  "annotation": "Dict",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Dictionary with fields. The value can be a tuple with the\ndata and a string \"Node\" or \"Cell\"."
                    }
                  ]
                },
                {
                  "name": "time",
                  "annotation": "float",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Optional. time"
                    }
                  ],
                  "value": "None"
                },
                {
                  "name": "mesh",
                  "annotation": "str",
                  "description": null,
                  "value": "None"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def add_fields(\n    self,\n    fields: Dict[str, np.ndarray | Tuple[np.ndarray, str]],\n    time: float = None,\n    mesh: str = None,\n) -> None:\n    \"\"\"Add multiple fields at once.\n\n    Args:\n        fields: Dictionary with fields. The value can be a tuple with the\n            data and a string \"Node\" or \"Cell\".\n        time: Optional. time\n    \"\"\"\n    for key, value in fields.items():\n        if isinstance(value, tuple):\n            vector, center = value\n        else:\n            vector, center = value, \"Node\"\n        self.add_field(key, vector, time, mesh, center=center)"
            },
            "add_global_field": {
              "name": "add_global_field",
              "path": "bamboost.simulation_writer.SimulationWriter.add_global_field",
              "signature": "(self, name, value, dtype = None) -> None",
              "description": "Add a gobal field. These are stored at `globals/` as an array in a\nsingle dataset.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "name",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Name for the data"
                    }
                  ]
                },
                {
                  "name": "value",
                  "annotation": "Any",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Data. Can be a numpy array or a single value."
                    }
                  ]
                },
                {
                  "name": "dtype",
                  "annotation": "str",
                  "description": null,
                  "value": "None"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def add_global_field(self, name: str, value: Any, dtype: str = None) -> None:\n    \"\"\"Add a gobal field. These are stored at `globals/` as an array in a\n    single dataset.\n\n    Args:\n        name: Name for the data\n        value: Data. Can be a numpy array or a single value.\n    \"\"\"\n    self._dump_global_data(f\"globals/{name}\", value, self.step, dtype=dtype)"
            },
            "_dump_global_data": {
              "name": "_dump_global_data",
              "path": "bamboost.simulation_writer.SimulationWriter._dump_global_data",
              "signature": "(self, location, value, step, dtype = None) -> None",
              "description": "Dump a global value / array to the file at location `location`.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "location",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Location in the file"
                    }
                  ]
                },
                {
                  "name": "value",
                  "annotation": "Any",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Data to dump"
                    }
                  ]
                },
                {
                  "name": "step",
                  "annotation": "int",
                  "description": null,
                  "value": null
                },
                {
                  "name": "dtype",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Optional. Numpy style datatype, see h5py documentation,\ndefaults to the dtype of the vector."
                    }
                  ],
                  "value": "None"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def _dump_global_data(\n    self, location: str, value: Any, step: int, dtype: str = None\n) -> None:\n    \"\"\"Dump a global value / array to the file at location `location`.\n\n    Args:\n        location: Location in the file\n        value: Data to dump\n        dtype: Optional. Numpy style datatype, see h5py documentation,\n            defaults to the dtype of the vector.\n    \"\"\"\n    # split location into group and dataset\n    group_name, dataset_name = location.rstrip(\"/\").rsplit(\"/\", 1)\n\n    if isinstance(value, np.ndarray):\n        shape = (step + 1, *value.shape)\n    else:\n        shape = (step + 1,)\n\n    if self._prank == 0:\n        with self._file(\"a\") as f:\n            grp = f.require_group(group_name)\n            if dataset_name not in grp.keys():\n                vec = grp.create_dataset(\n                    dataset_name,\n                    shape=shape,\n                    dtype=dtype if dtype else np.array(value).dtype,\n                    chunks=True,\n                    maxshape=(None, *shape[1:]) if len(shape) > 1 else (None,),\n                    fillvalue=np.nan,\n                )\n                vec[-1] = value\n            else:\n                vec = grp[dataset_name]\n                vec.resize(shape)\n                vec[-1] = value"
            },
            "add_global_fields": {
              "name": "add_global_fields",
              "path": "bamboost.simulation_writer.SimulationWriter.add_global_fields",
              "signature": "(self, fields) -> None",
              "description": "Add multiple global fields at once.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "fields",
                  "annotation": "Dict",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Dictionary with fields"
                    }
                  ]
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def add_global_fields(self, fields: Dict[str, Any]) -> None:\n    \"\"\"Add multiple global fields at once.\n\n    Args:\n        fields: Dictionary with fields\n    \"\"\"\n    for name, value in fields.items():\n        self.add_global_field(name, value)"
            },
            "finish_step": {
              "name": "finish_step",
              "path": "bamboost.simulation_writer.SimulationWriter.finish_step",
              "signature": "(self) -> None",
              "description": "Finish step. Adds 1 to the step counter.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def finish_step(self) -> None:\n    \"\"\"Finish step. Adds 1 to the step counter.\"\"\"\n    self.step += 1"
            },
            "finish_sim": {
              "name": "finish_sim",
              "path": "bamboost.simulation_writer.SimulationWriter.finish_sim",
              "signature": "(self, status = 'Finished') -> None",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "status",
                  "annotation": "str",
                  "description": null,
                  "value": "'Finished'"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def finish_sim(self, status: str = \"Finished\") -> None:\n    if self._prank == 0:\n        self.change_status(status)"
            },
            "register_git_attributes": {
              "name": "register_git_attributes",
              "path": "bamboost.simulation_writer.SimulationWriter.register_git_attributes",
              "signature": "(self, repo_path = './') -> None",
              "description": "Register git information for given repo.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "repo_path",
                  "annotation": "`str`",
                  "description": [
                    {
                      "kind": "text",
                      "value": "path to git repository"
                    }
                  ],
                  "value": "'./'"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def register_git_attributes(self, repo_path: str = \"./\") -> None:\n    \"\"\"Register git information for given repo.\n\n    Args:\n        repo_path (`str`): path to git repository\n    \"\"\"\n    if self._prank == 0:\n        repo_path = os.path.abspath(repo_path)\n        # store current working directory\n        cwd = os.getcwd()\n\n        # switch directory to git repo\n        os.chdir(repo_path)\n        git_string = GitStateGetter().create_git_string()\n\n        # switch working directory back\n        os.chdir(cwd)\n\n        with self._file(\"a\") as f:\n            grp = f.require_group(\"git\")\n            repo_name = os.path.split(repo_path)[1]\n            log.info(f\"Adding repo {repo_name}\")\n            if repo_name in grp.keys():\n                del grp[repo_name]\n            grp.create_dataset(repo_name, data=git_string)"
            },
            "copy_executable": {
              "name": "copy_executable",
              "path": "bamboost.simulation_writer.SimulationWriter.copy_executable",
              "signature": "(self, script_path) -> None",
              "description": "WILL BE REMOVED. USE COPY_FILE.\nCopy an executable to directory for reproducability.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "script_path",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "path to script"
                    }
                  ]
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def copy_executable(self, script_path: str) -> None:\n    \"\"\"WILL BE REMOVED. USE COPY_FILE.\n    Copy an executable to directory for reproducability.\n\n    Args:\n        script_path: path to script\n    \"\"\"\n    shutil.copy(script_path, self.path)\n    self.executable = os.path.split(script_path)[1]"
            },
            "copy_file": {
              "name": "copy_file",
              "path": "bamboost.simulation_writer.SimulationWriter.copy_file",
              "signature": "(self, source, destination = '') -> None",
              "description": "Copy a file to the datafolder.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "source",
                  "annotation": "Union",
                  "description": [
                    {
                      "kind": "text",
                      "value": "path to file, or list of files"
                    }
                  ]
                },
                {
                  "name": "destination",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "destination (will create intermediatory directories)"
                    }
                  ],
                  "value": "''"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def copy_file(self, source: Union[str, list], destination: str = \"\") -> None:\n    \"\"\"Copy a file to the datafolder.\n\n    Args:\n        source: path to file, or list of files\n        destination: destination (will create intermediatory directories)\n    \"\"\"\n    if self._prank != 0:\n        return\n\n    if isinstance(source, list):\n        for item in source:\n            self.copy_file(item, destination)\n        return\n\n    destination = os.path.join(self.path, destination)\n\n    if os.path.isdir(source):\n        shutil.copytree(\n            source,\n            os.path.join(destination, os.path.basename(source)),\n            dirs_exist_ok=True,\n        )\n    elif os.path.isfile(source):\n        os.makedirs(destination, exist_ok=True)\n        shutil.copy(source, destination)\n    else:\n        raise FileNotFoundError"
            }
          },
          "source": "class SimulationWriter(Simulation):\n    \"\"\"The SimulationWriter is the writer object for a single simulation. It inherits\n    all reading methods from :class:`Simulation`.\n\n    This class can be used as a context manager. When entering the context, the status\n    of the simulation is changed to \"Started\". When an exception is raised inside the\n    context, the status is changed to \"Failed [Exception]\".\n\n    Args:\n        uid: The identifier of the simulation\n        path: The (parent) database path\n        comm: An MPI communicator (Default: `MPI.COMM_WORLD`)\n    \"\"\"\n\n    def __init__(\n        self,\n        uid: str,\n        path: str,\n        comm: MPI.Comm = MPI.COMM_WORLD,\n        create_if_not_exists: bool = True,\n    ):\n        super().__init__(uid, path, comm, create_if_not_exists)\n        self.step: int = 0\n\n    def __enter__(self):\n        self.change_status(\"Started\")  # change status to running (process 0 only)\n        self._comm.barrier()  # wait for change status to be written\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        if exc_type:\n            self.change_status(f\"Failed [{exc_type.__name__}]\")\n            log.error(f\"Simulation failed with {exc_type.__name__}: {exc_val}\")\n            log.error(exc_tb)\n            raise RuntimeError(f\"Simulation failed [Process {self._prank}]\")\n        self._comm.barrier()\n\n    def initialize(self) -> SimulationWriter:\n        \"\"\"Create a new file for this simlation.\n        This deletes an existing h5 file of the simulation and creates an empty new one\n        \"\"\"\n        self.step = 0\n        self.add_metadata()\n        self.change_status(\"Initiated\")\n\n        return self\n\n    def add_metadata(self) -> None:\n        \"\"\"Add metadata to h5 file.\"\"\"\n        nb_proc = self._comm.Get_size()\n        if self._prank == 0:\n            with self._file(\"a\"):\n                data = {\n                    \"time_stamp\": str(datetime.datetime.now().replace(microsecond=0)),\n                    \"id\": self.uid,\n                    \"processors\": nb_proc,\n                    \"notes\": self._file.attrs.get(\"notes\", \"\"),\n                }\n                self._file.attrs.update(data)\n            self._push_update_to_sqlite(data)\n\n    def add_parameters(self, parameters: dict) -> None:\n        \"\"\"Add parameters to simulation.\n\n        Args:\n            parameters: Dictionary with parameters.\n        \"\"\"\n        if self._prank == 0:\n            with self._file(\"a\"):\n                # flatten parameters\n                parameters = flatten_dict(parameters)\n\n                if \"parameters\" in self._file.keys():\n                    del self._file[\"parameters\"]\n                grp = self._file.create_group(\"/parameters\")\n                for key, val in parameters.items():\n                    if isinstance(val, np.ndarray):\n                        grp.create_dataset(key, data=val)\n                    elif val is not None:\n                        grp.attrs[key] = val\n            self._push_update_to_sqlite(parameters)\n\n    def add_mesh(\n        self, coordinates: np.ndarray, connectivity: np.ndarray, mesh_name: str = None\n    ) -> None:\n        \"\"\"Add the mesh to file. Currently only 2d meshes.\n\n        Note:\n            If you are working with FEniCS, you can use the\n            `bamboost.extensions.fenics.FenicsWriter` writer. With it you can\n            write the FEniCS mesh directly.\n        Args:\n            coordinates: Coordinates as array (nb_nodes, dim)\n            connectivity: Connectivity matrix (nb_cells, nb nodes per cell)\n            mesh_name: name for mesh (default = `mesh`)\n        \"\"\"\n        if mesh_name is None:\n            mesh_name = self._default_mesh\n        # self._mesh_location = 'Mesh/0/mesh/'\n        mesh_location = f\"{self._mesh_location}/{mesh_name}/\"\n\n        nb_nodes_local = coordinates.shape[0]\n        nb_cells_local = connectivity.shape[0]\n\n        # gather total mesh\n        nb_nodes_p = np.array(self._comm.allgather(nb_nodes_local))\n        nb_cells_p = np.array(self._comm.allgather(nb_cells_local))\n        nb_nodes, nb_cells = np.sum(nb_nodes_p), np.sum(nb_cells_p)\n\n        # shape of datasets\n        coord_shape = (\n            (nb_nodes, coordinates.shape[1]) if coordinates.ndim > 1 else (nb_nodes,)\n        )\n        conn_shape = (\n            (nb_cells, connectivity.shape[1]) if connectivity.ndim > 1 else (nb_cells,)\n        )\n\n        # global indices nodes\n        idx_start = np.sum(nb_nodes_p[self._ranks < self._prank])\n        idx_end = idx_start + nb_nodes_local\n\n        # global indices cells\n        idx_start_cells = np.sum(nb_cells_p[self._ranks < self._prank])\n        idx_end_cells = idx_start_cells + nb_cells_local\n        connectivity = connectivity + idx_start\n\n        with self._file(\"a\", driver=\"mpio\", comm=self._comm) as f:\n            if mesh_location in self._file.file_object:\n                del self._file.file_object[mesh_location]\n            grp = f.require_group(mesh_location)\n            coord = grp.require_dataset(\n                \"coordinates\", shape=coord_shape, dtype=coordinates.dtype\n            )\n            conn = grp.require_dataset(\n                \"topology\", shape=conn_shape, dtype=connectivity.dtype\n            )\n\n            coord[idx_start:idx_end] = coordinates\n            conn[idx_start_cells:idx_end_cells] = connectivity\n\n    def add_field(\n        self,\n        name: str,\n        vector: np.array,\n        time: float = None,\n        mesh: str = None,\n        dtype: str = None,\n        center: Literal[\"Node\", \"Cell\"] = \"Node\",\n    ) -> None:\n        \"\"\"Add a dataset to the file. The data is stored at `data/`.\n\n        Args:\n            name: Name for the dataset\n            vector: Dataset\n            time: Optional. time\n            mesh: Optional. Linked mesh for this data\n            dtype: Optional. Numpy style datatype, see h5py documentation,\n                defaults to the dtype of the vector.\n            center: Optional. Center of the data. Can be 'Node' or 'Cell'.\n                Default is 'Node'.\n        \"\"\"\n        if mesh is None:\n            mesh = self._default_mesh\n\n        if time is None:\n            time = self.step\n\n        self._dump_array(f\"data/{name}/{self.step}\", vector, dtype=dtype)\n        self._comm.barrier()  # attempt to fix bug (see SimulationWriter add_field)\n\n        if self._prank == 0:\n            with self._file(\"a\"):\n                # Sometimes this fails with (if simultaneously trying to read the file)\n                # KeyError: 'Unable to synchronously open object (addr overflow, addr = 247903512, size = 328, eoa = 247903240)'\n                # KeyError: 'Unable to synchronously open object (len not positive after adjustment for EOA)'\n                # I don't know exactly what is going on.\n                # It could be that some process is still writing and then it's opened again and the dataset doesn't exist properly\n                # OR the other processes try to open the file already for the next time while this one is waiting\n                vec = self._file[\"data\"][name][str(self.step)]\n                vec.attrs.update({\"center\": center, \"mesh\": mesh, \"t\": time})\n\n        self._comm.barrier()  # attempt to fix bug (see SimulationWriter add_field)\n\n    def _dump_array(self, location: str, arr: np.ndarray, dtype: str = None) -> None:\n        \"\"\"Dump an array to the file. Correctly patch together multi-rank arrays.\n\n        Args:\n            location: Location in the file\n            arr: Array to dump\n            dtype: Optional. Numpy style datatype, see h5py documentation,\n                defaults to the dtype of the vector.\n        \"\"\"\n        dim = arr.shape[1:] if arr.ndim > 1 else None\n        length_local = arr.shape[0]\n        length_p = np.array(self._comm.allgather(length_local))\n        length = np.sum(length_p)\n\n        # split location into group and dataset\n        group_name, dataset_name = location.rstrip(\"/\").rsplit(\"/\", 1)\n\n        # global indices\n        idx_start = np.sum(length_p[self._ranks < self._prank])\n        idx_end = idx_start + length_local\n\n        # open file\n        with self._file(\"a\", driver=\"mpio\", comm=self._comm) as f:\n            grp = f.require_group(group_name)\n            vec = grp.require_dataset(\n                dataset_name,\n                shape=(length, *dim) if dim else (length,),\n                dtype=dtype if dtype else arr.dtype,\n            )\n            vec[idx_start:idx_end] = arr\n\n    def add_fields(\n        self,\n        fields: Dict[str, np.ndarray | Tuple[np.ndarray, str]],\n        time: float = None,\n        mesh: str = None,\n    ) -> None:\n        \"\"\"Add multiple fields at once.\n\n        Args:\n            fields: Dictionary with fields. The value can be a tuple with the\n                data and a string \"Node\" or \"Cell\".\n            time: Optional. time\n        \"\"\"\n        for key, value in fields.items():\n            if isinstance(value, tuple):\n                vector, center = value\n            else:\n                vector, center = value, \"Node\"\n            self.add_field(key, vector, time, mesh, center=center)\n\n    def add_global_field(self, name: str, value: Any, dtype: str = None) -> None:\n        \"\"\"Add a gobal field. These are stored at `globals/` as an array in a\n        single dataset.\n\n        Args:\n            name: Name for the data\n            value: Data. Can be a numpy array or a single value.\n        \"\"\"\n        self._dump_global_data(f\"globals/{name}\", value, self.step, dtype=dtype)\n\n    def _dump_global_data(\n        self, location: str, value: Any, step: int, dtype: str = None\n    ) -> None:\n        \"\"\"Dump a global value / array to the file at location `location`.\n\n        Args:\n            location: Location in the file\n            value: Data to dump\n            dtype: Optional. Numpy style datatype, see h5py documentation,\n                defaults to the dtype of the vector.\n        \"\"\"\n        # split location into group and dataset\n        group_name, dataset_name = location.rstrip(\"/\").rsplit(\"/\", 1)\n\n        if isinstance(value, np.ndarray):\n            shape = (step + 1, *value.shape)\n        else:\n            shape = (step + 1,)\n\n        if self._prank == 0:\n            with self._file(\"a\") as f:\n                grp = f.require_group(group_name)\n                if dataset_name not in grp.keys():\n                    vec = grp.create_dataset(\n                        dataset_name,\n                        shape=shape,\n                        dtype=dtype if dtype else np.array(value).dtype,\n                        chunks=True,\n                        maxshape=(None, *shape[1:]) if len(shape) > 1 else (None,),\n                        fillvalue=np.nan,\n                    )\n                    vec[-1] = value\n                else:\n                    vec = grp[dataset_name]\n                    vec.resize(shape)\n                    vec[-1] = value\n\n    def add_global_fields(self, fields: Dict[str, Any]) -> None:\n        \"\"\"Add multiple global fields at once.\n\n        Args:\n            fields: Dictionary with fields\n        \"\"\"\n        for name, value in fields.items():\n            self.add_global_field(name, value)\n\n    def finish_step(self) -> None:\n        \"\"\"Finish step. Adds 1 to the step counter.\"\"\"\n        self.step += 1\n\n    def finish_sim(self, status: str = \"Finished\") -> None:\n        if self._prank == 0:\n            self.change_status(status)\n\n    def register_git_attributes(self, repo_path: str = \"./\") -> None:\n        \"\"\"Register git information for given repo.\n\n        Args:\n            repo_path (`str`): path to git repository\n        \"\"\"\n        if self._prank == 0:\n            repo_path = os.path.abspath(repo_path)\n            # store current working directory\n            cwd = os.getcwd()\n\n            # switch directory to git repo\n            os.chdir(repo_path)\n            git_string = GitStateGetter().create_git_string()\n\n            # switch working directory back\n            os.chdir(cwd)\n\n            with self._file(\"a\") as f:\n                grp = f.require_group(\"git\")\n                repo_name = os.path.split(repo_path)[1]\n                log.info(f\"Adding repo {repo_name}\")\n                if repo_name in grp.keys():\n                    del grp[repo_name]\n                grp.create_dataset(repo_name, data=git_string)\n\n    def copy_executable(self, script_path: str) -> None:\n        \"\"\"WILL BE REMOVED. USE COPY_FILE.\n        Copy an executable to directory for reproducability.\n\n        Args:\n            script_path: path to script\n        \"\"\"\n        shutil.copy(script_path, self.path)\n        self.executable = os.path.split(script_path)[1]\n\n    def copy_file(self, source: Union[str, list], destination: str = \"\") -> None:\n        \"\"\"Copy a file to the datafolder.\n\n        Args:\n            source: path to file, or list of files\n            destination: destination (will create intermediatory directories)\n        \"\"\"\n        if self._prank != 0:\n            return\n\n        if isinstance(source, list):\n            for item in source:\n                self.copy_file(item, destination)\n            return\n\n        destination = os.path.join(self.path, destination)\n\n        if os.path.isdir(source):\n            shutil.copytree(\n                source,\n                os.path.join(destination, os.path.basename(source)),\n                dirs_exist_ok=True,\n            )\n        elif os.path.isfile(source):\n            os.makedirs(destination, exist_ok=True)\n            shutil.copy(source, destination)\n        else:\n            raise FileNotFoundError",
          "inherited_members": {
            "bamboost.simulation.Simulation": [
              {
                "kind": "attribute",
                "path": "bamboost.simulation.Simulation._mesh_location"
              },
              {
                "kind": "attribute",
                "path": "bamboost.simulation.Simulation._default_mesh"
              },
              {
                "kind": "attribute",
                "path": "bamboost.simulation.Simulation.uid"
              },
              {
                "kind": "attribute",
                "path": "bamboost.simulation.Simulation.path_database"
              },
              {
                "kind": "attribute",
                "path": "bamboost.simulation.Simulation.database_id"
              },
              {
                "kind": "attribute",
                "path": "bamboost.simulation.Simulation.path"
              },
              {
                "kind": "attribute",
                "path": "bamboost.simulation.Simulation.h5file"
              },
              {
                "kind": "attribute",
                "path": "bamboost.simulation.Simulation.xdmffile"
              },
              {
                "kind": "attribute",
                "path": "bamboost.simulation.Simulation._comm"
              },
              {
                "kind": "attribute",
                "path": "bamboost.simulation.Simulation._psize"
              },
              {
                "kind": "attribute",
                "path": "bamboost.simulation.Simulation._prank"
              },
              {
                "kind": "attribute",
                "path": "bamboost.simulation.Simulation._ranks"
              },
              {
                "kind": "attribute",
                "path": "bamboost.simulation.Simulation._file"
              },
              {
                "kind": "attribute",
                "path": "bamboost.simulation.Simulation.meshes"
              },
              {
                "kind": "attribute",
                "path": "bamboost.simulation.Simulation.data"
              },
              {
                "kind": "attribute",
                "path": "bamboost.simulation.Simulation.globals"
              },
              {
                "kind": "attribute",
                "path": "bamboost.simulation.Simulation.userdata"
              },
              {
                "kind": "attribute",
                "path": "bamboost.simulation.Simulation.links"
              },
              {
                "kind": "function",
                "path": "bamboost.simulation.Simulation.fromUID"
              },
              {
                "kind": "function",
                "path": "bamboost.simulation.Simulation.__getitem__"
              },
              {
                "kind": "function",
                "path": "bamboost.simulation.Simulation._repr_html_"
              },
              {
                "kind": "function",
                "path": "bamboost.simulation.Simulation._push_update_to_sqlite"
              },
              {
                "kind": "attribute",
                "path": "bamboost.simulation.Simulation.parameters"
              },
              {
                "kind": "attribute",
                "path": "bamboost.simulation.Simulation.metadata"
              },
              {
                "kind": "function",
                "path": "bamboost.simulation.Simulation.files"
              },
              {
                "kind": "function",
                "path": "bamboost.simulation.Simulation.show_files"
              },
              {
                "kind": "function",
                "path": "bamboost.simulation.Simulation.open_in_file_explorer"
              },
              {
                "kind": "function",
                "path": "bamboost.simulation.Simulation.open_in_paraview"
              },
              {
                "kind": "function",
                "path": "bamboost.simulation.Simulation.get_full_uid"
              },
              {
                "kind": "function",
                "path": "bamboost.simulation.Simulation.change_status"
              },
              {
                "kind": "function",
                "path": "bamboost.simulation.Simulation.update_metadata"
              },
              {
                "kind": "function",
                "path": "bamboost.simulation.Simulation.update_parameters"
              },
              {
                "kind": "function",
                "path": "bamboost.simulation.Simulation.create_xdmf_file"
              },
              {
                "kind": "function",
                "path": "bamboost.simulation.Simulation.create_run_script"
              },
              {
                "kind": "function",
                "path": "bamboost.simulation.Simulation.create_batch_script"
              },
              {
                "kind": "function",
                "path": "bamboost.simulation.Simulation.submit"
              },
              {
                "kind": "function",
                "path": "bamboost.simulation.Simulation.change_note"
              },
              {
                "kind": "function",
                "path": "bamboost.simulation.Simulation.open"
              },
              {
                "kind": "attribute",
                "path": "bamboost.simulation.Simulation.mesh"
              },
              {
                "kind": "function",
                "path": "bamboost.simulation.Simulation.get_mesh"
              },
              {
                "kind": "attribute",
                "path": "bamboost.simulation.Simulation.data_info"
              },
              {
                "kind": "attribute",
                "path": "bamboost.simulation.Simulation.git"
              },
              {
                "kind": "function",
                "path": "bamboost.simulation.Simulation.get_data_interpolator"
              },
              {
                "kind": "function",
                "path": "bamboost.simulation.Simulation.show_h5tree"
              },
              {
                "kind": "function",
                "path": "bamboost.simulation.Simulation.enter_path"
              }
            ]
          }
        }
      },
      "functions": {}
    },
    "xdmf": {
      "name": "xdmf",
      "path": "bamboost.xdmf",
      "filepath": "/home/florez/work/code/bamboost/bamboost/xdmf.py",
      "description": null,
      "docstring": [],
      "attributes": [
        {
          "name": "__all__",
          "annotation": null,
          "description": null,
          "value": "['XDMFWriter']"
        },
        {
          "name": "numpy_to_xdmf_dtype",
          "annotation": null,
          "description": null,
          "value": "{'int8': ('Int', '1'), 'int16': ('Int', '2'), 'int32': ('Int', '4'), 'int64': ('Int', '8'), 'uint8': ('UInt', '1'), 'uint16': ('UInt', '2'), 'uint32': ('UInt', '4'), 'uint64': ('UInt', '8'), 'float32': ('Float', '4'), 'float64': ('Float', '8')}"
        }
      ],
      "modules": {},
      "classes": {
        "XDMFWriter": {
          "name": "XDMFWriter",
          "path": "bamboost.xdmf.XDMFWriter",
          "description": "Write xdmf file for a subset of the stored data in the H5 file.",
          "parameters": [
            {
              "name": "self",
              "annotation": null,
              "description": null,
              "value": null
            },
            {
              "name": "filename",
              "annotation": "str",
              "description": [
                {
                  "kind": "text",
                  "value": "xdmf file path"
                }
              ]
            },
            {
              "name": "_file",
              "annotation": "FileHandler",
              "description": null,
              "value": null
            }
          ],
          "attributes": [
            {
              "name": "filename",
              "annotation": null,
              "description": null,
              "value": "filename"
            },
            {
              "name": "_file",
              "annotation": null,
              "description": null,
              "value": "_file"
            },
            {
              "name": "h5file",
              "annotation": null,
              "description": null,
              "value": "os.path.basename(_file.file_name)"
            },
            {
              "name": "xdmf_file",
              "annotation": null,
              "description": null,
              "value": "ET.Element('Xdmf', Version='3.0')"
            },
            {
              "name": "domain",
              "annotation": null,
              "description": null,
              "value": "ET.SubElement(self.xdmf_file, 'Domain')"
            },
            {
              "name": "mesh_name",
              "annotation": null,
              "description": null,
              "value": "'mesh'"
            }
          ],
          "docstring": [],
          "functions": {
            "__init__": {
              "name": "__init__",
              "path": "bamboost.xdmf.XDMFWriter.__init__",
              "signature": "(self, filename, _file)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "filename",
                  "annotation": "str",
                  "description": null,
                  "value": null
                },
                {
                  "name": "_file",
                  "annotation": "FileHandler",
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def __init__(self, filename: str, _file: FileHandler):\n    self.filename = filename\n    self._file = _file\n    self.h5file = os.path.basename(_file.file_name)\n    self.xdmf_file = ET.Element(\"Xdmf\", Version=\"3.0\")\n    self.domain = ET.SubElement(self.xdmf_file, \"Domain\")\n    ET.register_namespace(\"xi\", \"https://www.w3.org/2001/XInclude/\")\n    self.mesh_name = \"mesh\""
            },
            "write_file": {
              "name": "write_file",
              "path": "bamboost.xdmf.XDMFWriter.write_file",
              "signature": "(self)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def write_file(self):\n    tree = ET.ElementTree(self.xdmf_file)\n    self._pretty_print(tree.getroot())\n    tree.write(self.filename)"
            },
            "_pretty_print": {
              "name": "_pretty_print",
              "path": "bamboost.xdmf.XDMFWriter._pretty_print",
              "signature": "(self, elem, level = 0)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "elem",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "level",
                  "annotation": null,
                  "description": null,
                  "value": "0"
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def _pretty_print(self, elem, level=0):\n    indent = \"  \"  # 4 spaces\n    if len(elem):\n        if not elem.text or not elem.text.strip():\n            elem.text = \"\\n\" + indent * (level + 1)\n        if not elem.tail or not elem.tail.strip():\n            elem.tail = \"\\n\" + indent * level\n        for elem in elem:\n            self._pretty_print(elem, level + 1)\n        if not elem.tail or not elem.tail.strip():\n            elem.tail = \"\\n\" + indent * level\n    else:\n        if level and (not elem.tail or not elem.tail.strip()):\n            elem.tail = \"\\n\" + indent * level"
            },
            "write_points_cells": {
              "name": "write_points_cells",
              "path": "bamboost.xdmf.XDMFWriter.write_points_cells",
              "signature": "(self, points_location, cells_location)",
              "description": "Write the mesh to the xdmf file.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "points_location",
                  "annotation": "str",
                  "description": null,
                  "value": null
                },
                {
                  "name": "cells_location",
                  "annotation": "str",
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def write_points_cells(self, points_location: str, cells_location: str):\n    \"\"\"Write the mesh to the xdmf file.\n\n    Args:\n        points (str): String to geometry/nodes in h5 file\n        cells (str): String to topology/cells in h5 file\n    \"\"\"\n    grid = ET.SubElement(\n        self.domain, \"Grid\", Name=self.mesh_name, GridType=\"Uniform\"\n    )\n    self._points(grid, points_location)\n    self._cells(grid, cells_location)"
            },
            "_points": {
              "name": "_points",
              "path": "bamboost.xdmf.XDMFWriter._points",
              "signature": "(self, grid, points_location)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "grid",
                  "annotation": "ET.Element",
                  "description": null,
                  "value": null
                },
                {
                  "name": "points_location",
                  "annotation": "str",
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def _points(self, grid: ET.Element, points_location: str):\n    geometry_type = \"XY\"\n\n    with self._file(\"r\") as _f:\n        f = _f.file_object\n        points = f[points_location]\n        geo = ET.SubElement(grid, \"Geometry\", GeometryType=geometry_type)\n        dt, prec = numpy_to_xdmf_dtype[points.dtype.name]\n        dim = \"{} {}\".format(*points.shape)\n        data_item = ET.SubElement(\n            geo,\n            \"DataItem\",\n            DataType=dt,\n            Dimensions=dim,\n            Format=\"HDF\",\n            Precision=prec,\n        )\n        data_item.text = f\"{self.h5file}:/{points_location}\""
            },
            "_cells": {
              "name": "_cells",
              "path": "bamboost.xdmf.XDMFWriter._cells",
              "signature": "(self, grid, cells_location)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "grid",
                  "annotation": "ET.Element",
                  "description": null,
                  "value": null
                },
                {
                  "name": "cells_location",
                  "annotation": "str",
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def _cells(self, grid: ET.Element, cells_location: str):\n    with self._file(\"r\") as _f:\n        f = _f.file_object\n        cells = f[cells_location]\n        nb_cells = cells.shape[0]\n        topo = ET.SubElement(\n            grid,\n            \"Topology\",\n            TopologyType=\"Triangle\",\n            NumberOfElements=str(nb_cells),\n        )\n        dim = \"{} {}\".format(*cells.shape)\n        dt, prec = numpy_to_xdmf_dtype[cells.dtype.name]\n        data_item = ET.SubElement(\n            topo,\n            \"DataItem\",\n            DataType=dt,\n            Dimensions=dim,\n            Format=\"HDF\",\n            Precision=prec,\n        )\n        data_item.text = f\"{self.h5file}:/{cells_location}\""
            },
            "add_timeseries": {
              "name": "add_timeseries",
              "path": "bamboost.xdmf.XDMFWriter.add_timeseries",
              "signature": "(self, steps, fields)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "steps",
                  "annotation": "int",
                  "description": null,
                  "value": null
                },
                {
                  "name": "fields",
                  "annotation": "list",
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def add_timeseries(self, steps: int, fields: list):\n    collection = ET.SubElement(\n        self.domain,\n        \"Grid\",\n        Name=\"TimeSeries\",\n        GridType=\"Collection\",\n        CollectionType=\"Temporal\",\n    )\n\n    for i in range(steps):\n        self.write_step(collection, fields, i)"
            },
            "write_step": {
              "name": "write_step",
              "path": "bamboost.xdmf.XDMFWriter.write_step",
              "signature": "(self, collection, fields, step)",
              "description": "Write the data array for time t.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "collection",
                  "annotation": "ET.Element",
                  "description": null,
                  "value": null
                },
                {
                  "name": "fields",
                  "annotation": "list",
                  "description": null,
                  "value": null
                },
                {
                  "name": "step",
                  "annotation": "int",
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def write_step(self, collection: ET.Element, fields: list, step: int):\n    \"\"\"Write the data array for time t.\n\n    Args:\n        t (float): time\n        data_location (str): String to data in h5 file\n        name (str): Name for the field in the Xdmf file\n    \"\"\"\n    with self._file(\"r\") as _f:\n        f = _f.file_object\n        grid = ET.SubElement(collection, \"Grid\")\n        ptr = f'xpointer(//Grid[@Name=\"{self.mesh_name}\"]/*[self::Topology or self::Geometry])'\n\n        ET.SubElement(\n            grid, \"{http://www.w3.org/2003/XInclude}include\", xpointer=ptr\n        )\n\n        t = f[f\"data/{fields[0]}/{step}\"].attrs.get(\"t\", step)\n        ET.SubElement(grid, \"Time\", Value=str(t))\n\n        for name in fields:\n            self.write_attribute(grid, name, name, step)"
            },
            "write_attribute": {
              "name": "write_attribute",
              "path": "bamboost.xdmf.XDMFWriter.write_attribute",
              "signature": "(self, grid, field_name, name, step) -> None",
              "description": "Write an attribute/field.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "grid",
                  "annotation": "ET.Element",
                  "description": null,
                  "value": null
                },
                {
                  "name": "field_name",
                  "annotation": "str",
                  "description": null,
                  "value": null
                },
                {
                  "name": "name",
                  "annotation": "str",
                  "description": null,
                  "value": null
                },
                {
                  "name": "step",
                  "annotation": "int",
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def write_attribute(\n    self, grid: ET.Element, field_name: str, name: str, step: int\n) -> None:\n    \"\"\"Write an attribute/field.\"\"\"\n    with self._file(\"r\") as _f:\n        f = _f.file_object\n        data = f[f\"data/{field_name}/{step}\"]\n\n        if data.ndim == 1 or data.shape[1] <= 1:\n            att_type = \"Scalar\"\n        elif data.ndim == 2:\n            att_type = \"Vector\"\n        elif data.ndim == 3 and len(set(data.shape[1:])) == 1:\n            # Square shape -> Tensor\n            att_type = \"Tensor\"\n        else:\n            att_type = \"Matrix\"\n\n        # Cell or Node data\n        center = data.attrs.get(\"center\", \"Node\")\n\n        att = ET.SubElement(\n            grid,\n            \"Attribute\",\n            Name=name,\n            AttributeType=att_type,\n            Center=center,\n        )\n\n        dt, prec = numpy_to_xdmf_dtype[data.dtype.name]\n        dim = \" \".join([str(i) for i in data.shape])\n\n        data_item = ET.SubElement(\n            att,\n            \"DataItem\",\n            DataType=dt,\n            Dimensions=dim,\n            Format=\"HDF\",\n            Precision=prec,\n        )\n        data_item.text = f\"{self.h5file}:/data/{field_name}/{step}\""
            }
          },
          "source": "class XDMFWriter:\n    \"\"\"Write xdmf file for a subset of the stored data in the H5 file.\n\n    Args:\n        filename (str): xdmf file path\n        h5file (str): h5 file path\"\"\"\n\n    def __init__(self, filename: str, _file: FileHandler):\n        self.filename = filename\n        self._file = _file\n        self.h5file = os.path.basename(_file.file_name)\n        self.xdmf_file = ET.Element(\"Xdmf\", Version=\"3.0\")\n        self.domain = ET.SubElement(self.xdmf_file, \"Domain\")\n        ET.register_namespace(\"xi\", \"https://www.w3.org/2001/XInclude/\")\n        self.mesh_name = \"mesh\"\n\n    def write_file(self):\n        tree = ET.ElementTree(self.xdmf_file)\n        self._pretty_print(tree.getroot())\n        tree.write(self.filename)\n\n    def _pretty_print(self, elem, level=0):\n        indent = \"  \"  # 4 spaces\n        if len(elem):\n            if not elem.text or not elem.text.strip():\n                elem.text = \"\\n\" + indent * (level + 1)\n            if not elem.tail or not elem.tail.strip():\n                elem.tail = \"\\n\" + indent * level\n            for elem in elem:\n                self._pretty_print(elem, level + 1)\n            if not elem.tail or not elem.tail.strip():\n                elem.tail = \"\\n\" + indent * level\n        else:\n            if level and (not elem.tail or not elem.tail.strip()):\n                elem.tail = \"\\n\" + indent * level\n\n    def write_points_cells(self, points_location: str, cells_location: str):\n        \"\"\"Write the mesh to the xdmf file.\n\n        Args:\n            points (str): String to geometry/nodes in h5 file\n            cells (str): String to topology/cells in h5 file\n        \"\"\"\n        grid = ET.SubElement(\n            self.domain, \"Grid\", Name=self.mesh_name, GridType=\"Uniform\"\n        )\n        self._points(grid, points_location)\n        self._cells(grid, cells_location)\n\n    def _points(self, grid: ET.Element, points_location: str):\n        geometry_type = \"XY\"\n\n        with self._file(\"r\") as _f:\n            f = _f.file_object\n            points = f[points_location]\n            geo = ET.SubElement(grid, \"Geometry\", GeometryType=geometry_type)\n            dt, prec = numpy_to_xdmf_dtype[points.dtype.name]\n            dim = \"{} {}\".format(*points.shape)\n            data_item = ET.SubElement(\n                geo,\n                \"DataItem\",\n                DataType=dt,\n                Dimensions=dim,\n                Format=\"HDF\",\n                Precision=prec,\n            )\n            data_item.text = f\"{self.h5file}:/{points_location}\"\n\n    def _cells(self, grid: ET.Element, cells_location: str):\n        with self._file(\"r\") as _f:\n            f = _f.file_object\n            cells = f[cells_location]\n            nb_cells = cells.shape[0]\n            topo = ET.SubElement(\n                grid,\n                \"Topology\",\n                TopologyType=\"Triangle\",\n                NumberOfElements=str(nb_cells),\n            )\n            dim = \"{} {}\".format(*cells.shape)\n            dt, prec = numpy_to_xdmf_dtype[cells.dtype.name]\n            data_item = ET.SubElement(\n                topo,\n                \"DataItem\",\n                DataType=dt,\n                Dimensions=dim,\n                Format=\"HDF\",\n                Precision=prec,\n            )\n            data_item.text = f\"{self.h5file}:/{cells_location}\"\n\n    def add_timeseries(self, steps: int, fields: list):\n        collection = ET.SubElement(\n            self.domain,\n            \"Grid\",\n            Name=\"TimeSeries\",\n            GridType=\"Collection\",\n            CollectionType=\"Temporal\",\n        )\n\n        for i in range(steps):\n            self.write_step(collection, fields, i)\n\n    def write_step(self, collection: ET.Element, fields: list, step: int):\n        \"\"\"Write the data array for time t.\n\n        Args:\n            t (float): time\n            data_location (str): String to data in h5 file\n            name (str): Name for the field in the Xdmf file\n        \"\"\"\n        with self._file(\"r\") as _f:\n            f = _f.file_object\n            grid = ET.SubElement(collection, \"Grid\")\n            ptr = f'xpointer(//Grid[@Name=\"{self.mesh_name}\"]/*[self::Topology or self::Geometry])'\n\n            ET.SubElement(\n                grid, \"{http://www.w3.org/2003/XInclude}include\", xpointer=ptr\n            )\n\n            t = f[f\"data/{fields[0]}/{step}\"].attrs.get(\"t\", step)\n            ET.SubElement(grid, \"Time\", Value=str(t))\n\n            for name in fields:\n                self.write_attribute(grid, name, name, step)\n\n    def write_attribute(\n        self, grid: ET.Element, field_name: str, name: str, step: int\n    ) -> None:\n        \"\"\"Write an attribute/field.\"\"\"\n        with self._file(\"r\") as _f:\n            f = _f.file_object\n            data = f[f\"data/{field_name}/{step}\"]\n\n            if data.ndim == 1 or data.shape[1] <= 1:\n                att_type = \"Scalar\"\n            elif data.ndim == 2:\n                att_type = \"Vector\"\n            elif data.ndim == 3 and len(set(data.shape[1:])) == 1:\n                # Square shape -> Tensor\n                att_type = \"Tensor\"\n            else:\n                att_type = \"Matrix\"\n\n            # Cell or Node data\n            center = data.attrs.get(\"center\", \"Node\")\n\n            att = ET.SubElement(\n                grid,\n                \"Attribute\",\n                Name=name,\n                AttributeType=att_type,\n                Center=center,\n            )\n\n            dt, prec = numpy_to_xdmf_dtype[data.dtype.name]\n            dim = \" \".join([str(i) for i in data.shape])\n\n            data_item = ET.SubElement(\n                att,\n                \"DataItem\",\n                DataType=dt,\n                Dimensions=dim,\n                Format=\"HDF\",\n                Precision=prec,\n            )\n            data_item.text = f\"{self.h5file}:/data/{field_name}/{step}\"",
          "inherited_members": {}
        }
      },
      "functions": {}
    },
    "_sqlite_database": {
      "name": "_sqlite_database",
      "path": "bamboost._sqlite_database",
      "filepath": "/home/florez/work/code/bamboost/bamboost/_sqlite_database.py",
      "description": "This module provides a class to handle sqlite databases.",
      "docstring": [],
      "attributes": [
        {
          "name": "__all__",
          "annotation": null,
          "description": null,
          "value": "['SQLiteHandler']"
        },
        {
          "name": "log",
          "annotation": null,
          "description": null,
          "value": "BAMBOOST_LOGGER.getChild(__name__.split('.')[-1])"
        },
        {
          "name": "_type_to_sql_column_type",
          "annotation": null,
          "description": null,
          "value": "{np.ndarray: 'ARRAY', np.datetime64: 'DATETIME', int: 'INTEGER', float: 'REAL', str: 'TEXT', bool: 'BOOL'}"
        }
      ],
      "modules": {},
      "classes": {
        "SQLiteHandler": {
          "name": "SQLiteHandler",
          "path": "bamboost._sqlite_database.SQLiteHandler",
          "description": "Class to handle sqlite databases.",
          "parameters": [
            {
              "name": "self",
              "annotation": null,
              "description": null,
              "value": null
            },
            {
              "name": "file",
              "annotation": "str",
              "description": null,
              "value": null
            },
            {
              "name": "_comm",
              "annotation": null,
              "description": null,
              "value": "MPI.COMM_WORLD"
            },
            {
              "name": "convert_arrays",
              "annotation": "bool",
              "description": null,
              "value": "True"
            }
          ],
          "attributes": [
            {
              "name": "file",
              "annotation": null,
              "description": null,
              "value": "file"
            },
            {
              "name": "_conn",
              "annotation": null,
              "description": null,
              "value": "None"
            },
            {
              "name": "_cursor",
              "annotation": null,
              "description": null,
              "value": "None"
            },
            {
              "name": "_is_open",
              "annotation": null,
              "description": null,
              "value": "False"
            },
            {
              "name": "_lock_stack",
              "annotation": "int",
              "description": null,
              "value": null
            }
          ],
          "docstring": [],
          "functions": {
            "__init__": {
              "name": "__init__",
              "path": "bamboost._sqlite_database.SQLiteHandler.__init__",
              "signature": "(self, file, _comm = MPI.COMM_WORLD, convert_arrays = True) -> None",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "file",
                  "annotation": "str",
                  "description": null,
                  "value": null
                },
                {
                  "name": "_comm",
                  "annotation": null,
                  "description": null,
                  "value": "MPI.COMM_WORLD"
                },
                {
                  "name": "convert_arrays",
                  "annotation": "bool",
                  "description": null,
                  "value": "True"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def __init__(\n    self, file: str, _comm=MPI.COMM_WORLD, convert_arrays: bool = True\n) -> None:\n    if _comm.rank != 0:\n        return\n    # self._comm = _comm\n    self.file = file\n    self._conn = None\n    self._cursor = None\n    self._is_open = False\n    self._lock_stack = 0\n\n    _register_sqlite_adapters()\n    _register_sqlite_converters(convert_arrays=convert_arrays)"
            },
            "connect": {
              "name": "connect",
              "path": "bamboost._sqlite_database.SQLiteHandler.connect",
              "signature": "(self) -> typing_extensions.Self",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "typing_extensions.Self",
                "description": null
              },
              "docstring": [],
              "source": "def connect(self) -> Self:\n    self._lock_stack += 1\n    if not self._is_open:\n        log.debug(f\"Connecting to {self.file}\")\n        self._conn = sqlite3.connect(\n            self.file, detect_types=sqlite3.PARSE_DECLTYPES\n        )\n        self._cursor = self._conn.cursor()\n        self._is_open = True\n    return self"
            },
            "close": {
              "name": "close",
              "path": "bamboost._sqlite_database.SQLiteHandler.close",
              "signature": "(self, *, force = False, ensure_commit = False) -> typing_extensions.Self",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "force",
                  "annotation": "bool",
                  "description": null,
                  "value": "False"
                },
                {
                  "name": "ensure_commit",
                  "annotation": "bool",
                  "description": null,
                  "value": "False"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "typing_extensions.Self",
                "description": null
              },
              "docstring": [],
              "source": "def close(self, *, force: bool = False, ensure_commit: bool = False) -> Self:\n    if force:\n        self._lock_stack = 0\n    else:\n        self._lock_stack -= 1\n\n    if self._lock_stack <= 0 and self._is_open:\n        log.debug(f\"Closing connection to {self.file}\")\n        self._conn.commit()\n        self._conn.close()\n        self._is_open = False\n        return self\n\n    if ensure_commit:\n        self._conn.commit()\n\n    return self"
            },
            "commit": {
              "name": "commit",
              "path": "bamboost._sqlite_database.SQLiteHandler.commit",
              "signature": "(self) -> None",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def commit(self) -> None:\n    self._conn.commit()\n    return self"
            },
            "open": {
              "name": "open",
              "path": "bamboost._sqlite_database.SQLiteHandler.open",
              "signature": "(self, *, force_close = False, ensure_commit = False) -> typing.Generator",
              "description": "The open method is used as a context manager.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "force_close",
                  "annotation": "bool",
                  "description": null,
                  "value": "False"
                },
                {
                  "name": "ensure_commit",
                  "annotation": "bool",
                  "description": null,
                  "value": "False"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "typing.Generator",
                "description": null
              },
              "docstring": [
                {
                  "kind": "admonition",
                  "value": {
                    "annotation": "example",
                    "description": ">>> with index.open() as table:\n>>>     table._cursor.execute(\"SELECT * FROM database\")"
                  },
                  "title": "Example"
                }
              ],
              "source": "@contextmanager\ndef open(\n    self,\n    *,\n    force_close: bool = False,\n    ensure_commit: bool = False,\n) -> Generator[Self]:\n    \"\"\"The open method is used as a context manager.\n\n    Args:\n        - ensure_commit (bool, optional): Ensure that the connection is\n          committed. Defaults to False.\n\n    Example:\n        >>> with index.open() as table:\n        >>>     table._cursor.execute(\"SELECT * FROM database\")\n    \"\"\"\n    self.connect()\n    try:\n        yield self\n    finally:\n        self.close(ensure_commit=ensure_commit, force=force_close)"
            }
          },
          "source": "class SQLiteHandler:\n    \"\"\"Class to handle sqlite databases.\"\"\"\n\n    def __init__(\n        self, file: str, _comm=MPI.COMM_WORLD, convert_arrays: bool = True\n    ) -> None:\n        if _comm.rank != 0:\n            return\n        # self._comm = _comm\n        self.file = file\n        self._conn = None\n        self._cursor = None\n        self._is_open = False\n        self._lock_stack = 0\n\n        _register_sqlite_adapters()\n        _register_sqlite_converters(convert_arrays=convert_arrays)\n\n    @property\n    def _lock_stack(self) -> int:\n        return self.__lock_stack\n\n    @_lock_stack.setter\n    def _lock_stack(self, value: int) -> None:\n        self.__lock_stack = value if value >= 0 else 0\n\n    def connect(self) -> Self:\n        self._lock_stack += 1\n        if not self._is_open:\n            log.debug(f\"Connecting to {self.file}\")\n            self._conn = sqlite3.connect(\n                self.file, detect_types=sqlite3.PARSE_DECLTYPES\n            )\n            self._cursor = self._conn.cursor()\n            self._is_open = True\n        return self\n\n    def close(self, *, force: bool = False, ensure_commit: bool = False) -> Self:\n        if force:\n            self._lock_stack = 0\n        else:\n            self._lock_stack -= 1\n\n        if self._lock_stack <= 0 and self._is_open:\n            log.debug(f\"Closing connection to {self.file}\")\n            self._conn.commit()\n            self._conn.close()\n            self._is_open = False\n            return self\n\n        if ensure_commit:\n            self._conn.commit()\n\n        return self\n\n    def commit(self) -> None:\n        self._conn.commit()\n        return self\n\n    @contextmanager\n    def open(\n        self,\n        *,\n        force_close: bool = False,\n        ensure_commit: bool = False,\n    ) -> Generator[Self]:\n        \"\"\"The open method is used as a context manager.\n\n        Args:\n            - ensure_commit (bool, optional): Ensure that the connection is\n              committed. Defaults to False.\n\n        Example:\n            >>> with index.open() as table:\n            >>>     table._cursor.execute(\"SELECT * FROM database\")\n        \"\"\"\n        self.connect()\n        try:\n            yield self\n        finally:\n            self.close(ensure_commit=ensure_commit, force=force_close)",
          "inherited_members": {}
        }
      },
      "functions": {
        "get_sqlite_column_type": {
          "name": "get_sqlite_column_type",
          "path": "bamboost._sqlite_database.get_sqlite_column_type",
          "signature": "(val)",
          "description": null,
          "parameters": [
            {
              "name": "val",
              "annotation": null,
              "description": null,
              "value": null
            }
          ],
          "returns": {
            "name": "",
            "annotation": null,
            "description": null
          },
          "docstring": [],
          "source": "def get_sqlite_column_type(val):\n    dtype = type(val)\n    if isinstance(val, np.generic):\n        dtype = type(val.item())\n    if dtype in _type_to_sql_column_type:\n        return _type_to_sql_column_type[dtype]\n\n    if isinstance(val, Iterable):\n        return \"JSON\"\n    if isinstance(val, dict):\n        return \"JSON\"\n    if isinstance(val, np.ndarray):\n        return \"ARRAY\""
        },
        "_register_sqlite_adapters": {
          "name": "_register_sqlite_adapters",
          "path": "bamboost._sqlite_database._register_sqlite_adapters",
          "signature": "()",
          "description": null,
          "parameters": [],
          "returns": {
            "name": "",
            "annotation": null,
            "description": null
          },
          "docstring": [],
          "source": "def _register_sqlite_adapters():\n    # Converts np.array & Iterable to JSON when inserting\n    sqlite3.register_adapter(np.ndarray, lambda arr: json.dumps(arr.tolist()))\n    sqlite3.register_adapter(list, lambda val: json.dumps(val))\n    sqlite3.register_adapter(dict, lambda val: json.dumps(val))\n    sqlite3.register_adapter(tuple, lambda val: json.dumps(val))\n    sqlite3.register_adapter(set, lambda val: json.dumps(val))\n\n    # Numpy generic types\n    def adapt_numpy_number(val):\n        return val.item()\n\n    sqlite3.register_adapter(np.int_, adapt_numpy_number)\n    sqlite3.register_adapter(np.float64, adapt_numpy_number)\n    sqlite3.register_adapter(np.datetime64, adapt_numpy_number)\n    sqlite3.register_adapter(np.bool_, bool)"
        },
        "_register_sqlite_converters": {
          "name": "_register_sqlite_converters",
          "path": "bamboost._sqlite_database._register_sqlite_converters",
          "signature": "(convert_arrays = True)",
          "description": null,
          "parameters": [
            {
              "name": "convert_arrays",
              "annotation": "bool",
              "description": null,
              "value": "True"
            }
          ],
          "returns": {
            "name": "",
            "annotation": null,
            "description": null
          },
          "docstring": [],
          "source": "def _register_sqlite_converters(convert_arrays: bool = True):\n    # Converts JSON to np.array & Iterable when selecting\n    if convert_arrays:\n        sqlite3.register_converter(\"ARRAY\", lambda text: np.array(json.loads(text)))\n    else:\n        sqlite3.register_converter(\"ARRAY\", lambda text: json.loads(text))\n    sqlite3.register_converter(\"JSON\", lambda text: json.loads(text))\n\n    def convert_bool(val):\n        # from now on, all bools should be stored as integers\n        try:\n            return bool(int(val))\n        # for a while, booleans were stored as bytes\n        # this exception handles the conversion of these bytes to bool for old databases\n        except ValueError:\n            return bool(int.from_bytes(val, \"big\"))\n\n    sqlite3.register_converter(\"BOOL\", convert_bool)"
        },
        "with_connection": {
          "name": "with_connection",
          "path": "bamboost._sqlite_database.with_connection",
          "signature": "(func)",
          "description": "Decorator to ensure that the cursor is available. If the cursor is not\navailable, the connection is opened and closed after the function is\nexecuted.",
          "parameters": [
            {
              "name": "func",
              "annotation": null,
              "description": null,
              "value": null
            }
          ],
          "returns": {
            "name": "",
            "annotation": null,
            "description": null
          },
          "docstring": [],
          "source": "def with_connection(func):\n    \"\"\"Decorator to ensure that the cursor is available. If the cursor is not\n    available, the connection is opened and closed after the function is\n    executed.\"\"\"\n\n    @wraps(func)\n    def wrapper(self: SQLiteHandler, *args, **kwargs):\n        cursor: sqlite3.Cursor = self._cursor\n        # check if cursor is available\n        if not self._is_open or cursor is None:\n            with self.open():\n                return func(self, *args, **kwargs)\n        return func(self, *args, **kwargs)\n\n    return wrapper"
        }
      }
    },
    "simulation": {
      "name": "simulation",
      "path": "bamboost.simulation",
      "filepath": "/home/florez/work/code/bamboost/bamboost/simulation.py",
      "description": null,
      "docstring": [],
      "attributes": [
        {
          "name": "__all__",
          "annotation": null,
          "description": null,
          "value": "['Simulation', 'Links']"
        },
        {
          "name": "log",
          "annotation": null,
          "description": null,
          "value": "BAMBOOST_LOGGER.getChild(__name__.split('.')[-1])"
        }
      ],
      "modules": {},
      "classes": {
        "Links": {
          "name": "Links",
          "path": "bamboost.simulation.Links",
          "description": "Link group. Used to create and access links.\n\nI don't know how to distribute this to its own file in the accessors\ndirectory, due to circular imports.",
          "parameters": [
            {
              "name": "self",
              "annotation": null,
              "description": null,
              "value": null
            },
            {
              "name": "file_handler",
              "annotation": "FileHandler",
              "description": null,
              "value": null
            }
          ],
          "attributes": [],
          "docstring": [],
          "functions": {
            "__init__": {
              "name": "__init__",
              "path": "bamboost.simulation.Links.__init__",
              "signature": "(self, file_handler) -> None",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "file_handler",
                  "annotation": "FileHandler",
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def __init__(self, file_handler: FileHandler) -> None:\n    super().__init__(file_handler, path_to_data=\"links\")"
            },
            "_ipython_key_completions_": {
              "name": "_ipython_key_completions_",
              "path": "bamboost.simulation.Links._ipython_key_completions_",
              "signature": "(self)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def _ipython_key_completions_(self):\n    return tuple(self.all_links().keys())"
            },
            "__getitem__": {
              "name": "__getitem__",
              "path": "bamboost.simulation.Links.__getitem__",
              "signature": "(self, key) -> bamboost.simulation.Simulation",
              "description": "Returns the linked simulation object.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "key",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "bamboost.simulation.Simulation",
                "description": null
              },
              "docstring": [],
              "source": "@with_file_open(\"r\", driver=\"mpio\")\ndef __getitem__(self, key) -> Simulation:\n    \"\"\"Returns the linked simulation object.\"\"\"\n    return Simulation.fromUID(self.obj.attrs[key])"
            },
            "__setitem__": {
              "name": "__setitem__",
              "path": "bamboost.simulation.Links.__setitem__",
              "signature": "(self, key, newvalue)",
              "description": "Creates the link.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "key",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "newvalue",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def __setitem__(self, key, newvalue):\n    \"\"\"Creates the link.\"\"\"\n    return self.update_attrs({key: newvalue})"
            },
            "__delitem__": {
              "name": "__delitem__",
              "path": "bamboost.simulation.Links.__delitem__",
              "signature": "(self, key)",
              "description": "Delete a link.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "key",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def __delitem__(self, key):\n    \"\"\"Delete a link.\"\"\"\n    with self._file(\"a\"):\n        del self.obj.attrs[key]"
            },
            "__repr__": {
              "name": "__repr__",
              "path": "bamboost.simulation.Links.__repr__",
              "signature": "(self) -> str",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "str",
                "description": null
              },
              "docstring": [],
              "source": "@with_file_open(\"r\")\ndef __repr__(self) -> str:\n    return repr(\n        pd.DataFrame.from_dict(self.all_links(), orient=\"index\", columns=[\"UID\"])\n    )"
            },
            "_repr_html_": {
              "name": "_repr_html_",
              "path": "bamboost.simulation.Links._repr_html_",
              "signature": "(self) -> str",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "str",
                "description": null
              },
              "docstring": [],
              "source": "@with_file_open(\"r\")\ndef _repr_html_(self) -> str:\n    return pd.DataFrame.from_dict(\n        self.all_links(), orient=\"index\", columns=[\"UID\"]\n    )._repr_html_()"
            },
            "all_links": {
              "name": "all_links",
              "path": "bamboost.simulation.Links.all_links",
              "signature": "(self) -> dict",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "dict",
                "description": null
              },
              "docstring": [],
              "source": "@with_file_open(\"r\")\ndef all_links(self) -> dict:\n    return dict(self.obj.attrs)"
            }
          },
          "source": "class Links(hdf_pointer.MutableGroup):\n    \"\"\"Link group. Used to create and access links.\n\n    I don't know how to distribute this to its own file in the accessors\n    directory, due to circular imports.\n    \"\"\"\n\n    def __init__(self, file_handler: FileHandler) -> None:\n        super().__init__(file_handler, path_to_data=\"links\")\n\n    def _ipython_key_completions_(self):\n        return tuple(self.all_links().keys())\n\n    @with_file_open(\"r\", driver=\"mpio\")\n    def __getitem__(self, key) -> Simulation:\n        \"\"\"Returns the linked simulation object.\"\"\"\n        return Simulation.fromUID(self.obj.attrs[key])\n\n    def __setitem__(self, key, newvalue):\n        \"\"\"Creates the link.\"\"\"\n        return self.update_attrs({key: newvalue})\n\n    def __delitem__(self, key):\n        \"\"\"Delete a link.\"\"\"\n        with self._file(\"a\"):\n            del self.obj.attrs[key]\n\n    @with_file_open(\"r\")\n    def __repr__(self) -> str:\n        return repr(\n            pd.DataFrame.from_dict(self.all_links(), orient=\"index\", columns=[\"UID\"])\n        )\n\n    @with_file_open(\"r\")\n    def _repr_html_(self) -> str:\n        return pd.DataFrame.from_dict(\n            self.all_links(), orient=\"index\", columns=[\"UID\"]\n        )._repr_html_()\n\n    @with_file_open(\"r\")\n    def all_links(self) -> dict:\n        return dict(self.obj.attrs)",
          "inherited_members": {
            "bamboost.common.hdf_pointer.BasePointer": [
              {
                "kind": "function",
                "path": "bamboost.common.hdf_pointer.BasePointer.new_pointer"
              },
              {
                "kind": "attribute",
                "path": "bamboost.common.hdf_pointer.BasePointer._file"
              },
              {
                "kind": "attribute",
                "path": "bamboost.common.hdf_pointer.BasePointer.path_to_data"
              },
              {
                "kind": "attribute",
                "path": "bamboost.common.hdf_pointer.BasePointer.obj"
              },
              {
                "kind": "function",
                "path": "bamboost.common.hdf_pointer.BasePointer.__str__"
              },
              {
                "kind": "function",
                "path": "bamboost.common.hdf_pointer.BasePointer.__getattr__"
              },
              {
                "kind": "attribute",
                "path": "bamboost.common.hdf_pointer.BasePointer.attrs"
              }
            ],
            "bamboost.common.hdf_pointer.Group": [
              {
                "kind": "function",
                "path": "bamboost.common.hdf_pointer.Group.__iter__"
              },
              {
                "kind": "function",
                "path": "bamboost.common.hdf_pointer.Group.keys"
              },
              {
                "kind": "function",
                "path": "bamboost.common.hdf_pointer.Group.groups"
              },
              {
                "kind": "function",
                "path": "bamboost.common.hdf_pointer.Group.datasets"
              },
              {
                "kind": "function",
                "path": "bamboost.common.hdf_pointer.Group.extract_attrs"
              }
            ],
            "bamboost.common.hdf_pointer.MutableGroup": [
              {
                "kind": "function",
                "path": "bamboost.common.hdf_pointer.MutableGroup.update_attrs"
              },
              {
                "kind": "function",
                "path": "bamboost.common.hdf_pointer.MutableGroup.add_dataset"
              },
              {
                "kind": "function",
                "path": "bamboost.common.hdf_pointer.MutableGroup.require_group"
              }
            ]
          }
        },
        "Simulation": {
          "name": "Simulation",
          "path": "bamboost.simulation.Simulation",
          "description": "A single dataset/simulation. Used to write to it, read from it or append.",
          "parameters": [
            {
              "name": "self",
              "annotation": null,
              "description": null,
              "value": null
            },
            {
              "name": "uid",
              "annotation": "str",
              "description": [
                {
                  "kind": "text",
                  "value": "unique identifier"
                }
              ]
            },
            {
              "name": "path",
              "annotation": "str",
              "description": [
                {
                  "kind": "text",
                  "value": "path to parent/database folder"
                }
              ]
            },
            {
              "name": "comm",
              "annotation": "MPI.Comm",
              "description": [
                {
                  "kind": "text",
                  "value": "MPI communicator (default=MPI.COMM_WORLD)"
                }
              ],
              "value": "MPI.COMM_WORLD"
            },
            {
              "name": "create_if_not_exists",
              "annotation": "bool",
              "description": null,
              "value": "False"
            },
            {
              "name": "_db_id",
              "annotation": "str",
              "description": null,
              "value": "None"
            }
          ],
          "attributes": [
            {
              "name": "_mesh_location",
              "annotation": null,
              "description": null,
              "value": "'Mesh/0'"
            },
            {
              "name": "_default_mesh",
              "annotation": null,
              "description": null,
              "value": "'mesh'"
            },
            {
              "name": "uid",
              "annotation": "str",
              "description": null,
              "value": "uid"
            },
            {
              "name": "path_database",
              "annotation": "str",
              "description": null,
              "value": "os.path.abspath(path)"
            },
            {
              "name": "database_id",
              "annotation": null,
              "description": null,
              "value": "_db_id or index.get_uid_from_path(self.path_database)"
            },
            {
              "name": "path",
              "annotation": "str",
              "description": null,
              "value": "os.path.abspath(os.path.join(path, uid))"
            },
            {
              "name": "h5file",
              "annotation": "str",
              "description": null,
              "value": "os.path.join(self.path, f'{self.uid}.h5')"
            },
            {
              "name": "xdmffile",
              "annotation": "str",
              "description": null,
              "value": "os.path.join(self.path, f'{self.uid}.xdmf')"
            },
            {
              "name": "_comm",
              "annotation": null,
              "description": null,
              "value": "comm"
            },
            {
              "name": "_psize",
              "annotation": null,
              "description": null,
              "value": "self._comm.size"
            },
            {
              "name": "_prank",
              "annotation": null,
              "description": null,
              "value": "self._comm.rank"
            },
            {
              "name": "_ranks",
              "annotation": null,
              "description": null,
              "value": "np.array([i for i in range(self._psize)])"
            },
            {
              "name": "_file",
              "annotation": null,
              "description": null,
              "value": "FileHandler(self.h5file)"
            },
            {
              "name": "meshes",
              "annotation": "MeshGroup",
              "description": null,
              "value": "MeshGroup(self._file)"
            },
            {
              "name": "data",
              "annotation": "DataGroup",
              "description": null,
              "value": "DataGroup(self._file, self.meshes)"
            },
            {
              "name": "globals",
              "annotation": "GlobalGroup",
              "description": null,
              "value": "GlobalGroup(self._file, '/globals')"
            },
            {
              "name": "userdata",
              "annotation": "hdf_pointer.MutableGroup",
              "description": null,
              "value": "hdf_pointer.MutableGroup(self._file, '/userdata')"
            },
            {
              "name": "links",
              "annotation": "Links",
              "description": null,
              "value": "Links(self._file)"
            },
            {
              "name": "parameters",
              "annotation": "Dict",
              "description": null,
              "value": null
            },
            {
              "name": "metadata",
              "annotation": "dict",
              "description": null,
              "value": null
            },
            {
              "name": "mesh",
              "annotation": "Mesh",
              "description": null,
              "value": null
            },
            {
              "name": "data_info",
              "annotation": "pd.DataFrame",
              "description": null,
              "value": null
            },
            {
              "name": "git",
              "annotation": "dict",
              "description": null,
              "value": null
            }
          ],
          "docstring": [],
          "functions": {
            "__init__": {
              "name": "__init__",
              "path": "bamboost.simulation.Simulation.__init__",
              "signature": "(self, uid, path, comm = MPI.COMM_WORLD, create_if_not_exists = False, *, _db_id = None)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "uid",
                  "annotation": "str",
                  "description": null,
                  "value": null
                },
                {
                  "name": "path",
                  "annotation": "str",
                  "description": null,
                  "value": null
                },
                {
                  "name": "comm",
                  "annotation": "MPI.Comm",
                  "description": null,
                  "value": "MPI.COMM_WORLD"
                },
                {
                  "name": "create_if_not_exists",
                  "annotation": "bool",
                  "description": null,
                  "value": "False"
                },
                {
                  "name": "_db_id",
                  "annotation": "str",
                  "description": null,
                  "value": "None"
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def __init__(\n    self,\n    uid: str,\n    path: str,\n    comm: MPI.Comm = MPI.COMM_WORLD,\n    create_if_not_exists: bool = False,\n    *,\n    _db_id: str = None,\n):\n    self.uid: str = uid\n    path = comm.bcast(path, root=0)\n    self.path_database: str = os.path.abspath(path)\n    self.database_id = _db_id or index.get_uid_from_path(self.path_database)\n    self.path: str = os.path.abspath(os.path.join(path, uid))\n    self.h5file: str = os.path.join(self.path, f\"{self.uid}.h5\")\n    self.xdmffile: str = os.path.join(self.path, f\"{self.uid}.xdmf\")\n\n    if not os.path.exists(self.h5file) and not create_if_not_exists:\n        raise FileNotFoundError(\n            f\"Simulation {self.uid} does not exist in {self.path}.\"\n        )\n\n    os.makedirs(self.path, exist_ok=True)\n\n    # MPI information\n    self._comm = comm\n    self._psize = self._comm.size\n    self._prank = self._comm.rank\n    self._ranks = np.array([i for i in range(self._psize)])\n\n    self._file = FileHandler(self.h5file)\n\n    # Initialize groups to meshes, data and userdata. Create groups.\n    self.meshes: MeshGroup = MeshGroup(self._file)\n    self.data: DataGroup = DataGroup(self._file, self.meshes)\n    self.globals: GlobalGroup = GlobalGroup(self._file, \"/globals\")\n    self.userdata: hdf_pointer.MutableGroup = hdf_pointer.MutableGroup(\n        self._file, \"/userdata\"\n    )\n    self.links: Links = Links(self._file)"
            },
            "fromUID": {
              "name": "fromUID",
              "path": "bamboost.simulation.Simulation.fromUID",
              "signature": "(cls, full_uid, *, index_database = None) -> typing_extensions.Self",
              "description": "Return the `Simulation` with given UID.",
              "parameters": [
                {
                  "name": "cls",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "full_uid",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "the full id (Database uid : simulation uid)"
                    }
                  ]
                },
                {
                  "name": "index_database",
                  "annotation": "index.IndexAPI",
                  "description": null,
                  "value": "None"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "typing_extensions.Self",
                "description": null
              },
              "docstring": [],
              "source": "@classmethod\ndef fromUID(cls, full_uid: str, *, index_database: index.IndexAPI = None) -> Self:\n    \"\"\"Return the `Simulation` with given UID.\n\n    Args:\n        full_uid: the full id (Database uid : simulation uid)\n    \"\"\"\n    if index_database is None:\n        index_database = index.IndexAPI()\n    db_uid, sim_uid = full_uid.split(\":\")\n    db_path = index_database.get_path(db_uid)\n    return cls(sim_uid, db_path, create_if_not_exists=False)"
            },
            "__getitem__": {
              "name": "__getitem__",
              "path": "bamboost.simulation.Simulation.__getitem__",
              "signature": "(self, key) -> bamboost.common.hdf_pointer.BasePointer",
              "description": "Direct access to HDF5 file.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "key",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "bamboost.common.hdf_pointer.BasePointer",
                "description": "class:`~bamboost.common.file_handler.BasePointer`"
              },
              "docstring": [],
              "source": "@with_file_open()\ndef __getitem__(self, key) -> hdf_pointer.BasePointer:\n    \"\"\"Direct access to HDF5 file.\n\n    Returns:\n        :class:`~bamboost.common.file_handler.BasePointer`\n    \"\"\"\n    return hdf_pointer.BasePointer.new_pointer(self._file, key)"
            },
            "_repr_html_": {
              "name": "_repr_html_",
              "path": "bamboost.simulation.Simulation._repr_html_",
              "signature": "(self) -> str",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "str",
                "description": null
              },
              "docstring": [],
              "source": "def _repr_html_(self) -> str:\n    html_string = pkgutil.get_data(__name__, \"html/simulation.html\").decode()\n    icon = pkgutil.get_data(__name__, \"html/icon.txt\").decode()\n\n    table_string = \"\"\n    for key, value in self.parameters.items():\n        if (\n            isinstance(value, Iterable)\n            and not isinstance(value, str)\n            and len(value) > 5\n        ):\n            value = \"...\"\n        table_string += f\"\"\"\n        <tr>\n            <td>{key}</td>\n            <td>{value}</td>\n        </tr>\n        \"\"\"\n\n    metadata = self.metadata\n\n    def get_pill_div(text: str, color: str):\n        return (\n            f'<div class=\"status\" style=\"background-color:'\n            f'var(--bb-{color});\">{text}</div>'\n        )\n\n    status_options = {\n        \"Finished\": get_pill_div(\"Finished\", \"green\"),\n        \"Failed\": get_pill_div(\"Failed\", \"red\"),\n        \"Initiated\": get_pill_div(\"Initiated\", \"grey\"),\n    }\n    submitted_options = {\n        True: get_pill_div(\"Submitted\", \"green\"),\n        False: get_pill_div(\"Not submitted\", \"grey\"),\n    }\n\n    html_string = (\n        html_string.replace(\"$UID\", self.uid)\n        .replace(\"$ICON\", icon)\n        .replace(\"$TREE\", self.show_files(printit=False).replace(\"\\n\", \"<br>\"))\n        .replace(\"$TABLE\", table_string)\n        .replace(\"$NOTE\", metadata[\"notes\"])\n        .replace(\n            \"$STATUS\",\n            status_options.get(\n                metadata[\"status\"],\n                f'<div class=\"status\">{metadata[\"status\"]}</div>',\n            ),\n        )\n        .replace(\"$SUBMITTED\", submitted_options[metadata.get(\"submitted\", False)])\n        .replace(\"$TIMESTAMP\", metadata[\"time_stamp\"])\n    )\n    return html_string"
            },
            "_push_update_to_sqlite": {
              "name": "_push_update_to_sqlite",
              "path": "bamboost.simulation.Simulation._push_update_to_sqlite",
              "signature": "(self, update_dict) -> None",
              "description": "Push update to sqlite database.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "update_dict",
                  "annotation": "dict",
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def _push_update_to_sqlite(self, update_dict: dict) -> None:\n    \"\"\"Push update to sqlite database.\n\n    Args:\n        - update_dict (dict): key value pair to push\n    \"\"\"\n    if not config[\"options\"].get(\"sync_table\", True):\n        return\n    try:\n        index.DatabaseTable(self.database_id).update_entry(self.uid, update_dict)\n    except index.Error as e:\n        log.warning(f\"Could not update sqlite database: {e}\")"
            },
            "files": {
              "name": "files",
              "path": "bamboost.simulation.Simulation.files",
              "signature": "(self, filename) -> str",
              "description": "Get the path to the file.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "filename",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "name of the file"
                    }
                  ]
                }
              ],
              "returns": {
                "name": "",
                "annotation": "str",
                "description": null
              },
              "docstring": [],
              "source": "def files(self, filename: str) -> str:\n    \"\"\"Get the path to the file.\n\n    Args:\n        filename: name of the file\n    \"\"\"\n    return os.path.join(self.path, filename)"
            },
            "show_files": {
              "name": "show_files",
              "path": "bamboost.simulation.Simulation.show_files",
              "signature": "(self, level = -1, limit_to_directories = False, length_limit = 1000, printit = True) -> str",
              "description": "Show the file tree of the simulation directory.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "level",
                  "annotation": null,
                  "description": [
                    {
                      "kind": "text",
                      "value": "how deep to print the tree"
                    }
                  ],
                  "value": "-1"
                },
                {
                  "name": "limit_to_directories",
                  "annotation": null,
                  "description": [
                    {
                      "kind": "text",
                      "value": "only print directories"
                    }
                  ],
                  "value": "False"
                },
                {
                  "name": "length_limit",
                  "annotation": null,
                  "description": [
                    {
                      "kind": "text",
                      "value": "cutoff"
                    }
                  ],
                  "value": "1000"
                },
                {
                  "name": "printit",
                  "annotation": null,
                  "description": null,
                  "value": "True"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "str",
                "description": null
              },
              "docstring": [],
              "source": "def show_files(\n    self, level=-1, limit_to_directories=False, length_limit=1000, printit=True\n) -> str:\n    \"\"\"Show the file tree of the simulation directory.\n\n    Args:\n        level: how deep to print the tree\n        limit_to_directories: only print directories\n        length_limit: cutoff\n    \"\"\"\n    tree_string = utilities.tree(\n        self.path, level, limit_to_directories, length_limit\n    )\n    if printit:\n        print(tree_string)\n    else:\n        return tree_string"
            },
            "open_in_file_explorer": {
              "name": "open_in_file_explorer",
              "path": "bamboost.simulation.Simulation.open_in_file_explorer",
              "signature": "(self) -> None",
              "description": "Open the simulation directory. Uses `xdg-open` on linux systems.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def open_in_file_explorer(self) -> None:\n    \"\"\"Open the simulation directory. Uses `xdg-open` on linux systems.\"\"\"\n    if os.name == \"nt\":  # should work on Windows\n        os.startfile(self.path)\n    else:\n        subprocess.run([\"xdg-open\", self.path])"
            },
            "open_in_paraview": {
              "name": "open_in_paraview",
              "path": "bamboost.simulation.Simulation.open_in_paraview",
              "signature": "(self) -> None",
              "description": "Open the xdmf file in paraview.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def open_in_paraview(self) -> None:\n    \"\"\"Open the xdmf file in paraview.\"\"\"\n    subprocess.Popen([\"paraview\", self.xdmffile])"
            },
            "get_full_uid": {
              "name": "get_full_uid",
              "path": "bamboost.simulation.Simulation.get_full_uid",
              "signature": "(self) -> str",
              "description": "Returns the full uid of the simulation (including the one of the database)",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "str",
                "description": null
              },
              "docstring": [],
              "source": "def get_full_uid(self) -> str:\n    \"\"\"Returns the full uid of the simulation (including the one of the database)\"\"\"\n    database_uid = index.get_uid_from_path(self.path_database)\n    return f\"{database_uid}:{self.uid}\""
            },
            "change_status": {
              "name": "change_status",
              "path": "bamboost.simulation.Simulation.change_status",
              "signature": "(self, status) -> None",
              "description": "Change status of simulation.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "status",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "new status"
                    }
                  ]
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def change_status(self, status: str) -> None:\n    \"\"\"Change status of simulation.\n\n    Args:\n        status (str): new status\n    \"\"\"\n    if self._prank == 0:\n        self._file.open(\"a\")\n        self._file.attrs[\"status\"] = status\n        self._file.close()\n\n    self._push_update_to_sqlite({\"status\": status})"
            },
            "update_metadata": {
              "name": "update_metadata",
              "path": "bamboost.simulation.Simulation.update_metadata",
              "signature": "(self, update_dict) -> None",
              "description": "Update the metadata attributes.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "update_dict",
                  "annotation": "dict",
                  "description": [
                    {
                      "kind": "text",
                      "value": "dictionary to push"
                    }
                  ]
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def update_metadata(self, update_dict: dict) -> None:\n    \"\"\"Update the metadata attributes.\n\n    Args:\n        update_dict: dictionary to push\n    \"\"\"\n    if self._prank == 0:\n        update_dict = utilities.flatten_dict(update_dict)\n        with self._file(\"a\") as file:\n            file.attrs.update(update_dict)\n\n        self._push_update_to_sqlite(update_dict)"
            },
            "update_parameters": {
              "name": "update_parameters",
              "path": "bamboost.simulation.Simulation.update_parameters",
              "signature": "(self, update_dict) -> None",
              "description": "Update the parameters dictionary.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "update_dict",
                  "annotation": "dict",
                  "description": [
                    {
                      "kind": "text",
                      "value": "dictionary to push"
                    }
                  ]
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def update_parameters(self, update_dict: dict) -> None:\n    \"\"\"Update the parameters dictionary.\n\n    Args:\n        update_dict: dictionary to push\n    \"\"\"\n    if self._prank == 0:\n        update_dict = utilities.flatten_dict(update_dict)\n        with self._file(\"a\") as file:\n            file[\"parameters\"].attrs.update(update_dict)\n\n        self._push_update_to_sqlite(update_dict)"
            },
            "create_xdmf_file": {
              "name": "create_xdmf_file",
              "path": "bamboost.simulation.Simulation.create_xdmf_file",
              "signature": "(self, fields = None, nb_steps = None) -> None",
              "description": "Create the xdmf file to read in paraview.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "fields",
                  "annotation": "list",
                  "description": [
                    {
                      "kind": "text",
                      "value": "fields for which to write timeseries information,\nif not specified, all fields in data are written."
                    }
                  ],
                  "value": "None"
                },
                {
                  "name": "nb_steps",
                  "annotation": "int",
                  "description": [
                    {
                      "kind": "text",
                      "value": "number of steps the simulation has"
                    }
                  ],
                  "value": "None"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def create_xdmf_file(self, fields: list = None, nb_steps: int = None) -> None:\n    \"\"\"Create the xdmf file to read in paraview.\n\n    Args:\n        fields (list[str]): fields for which to write timeseries information,\n            if not specified, all fields in data are written.\n        nb_steps (int): number of steps the simulation has\n    \"\"\"\n\n    if self._prank == 0:\n        with self._file(\"r\"):\n            f = self._file.file_object\n            if \"data\" not in f.keys():\n                fields, nb_steps = [], 0\n            if fields is None:\n                fields = list(f[\"data\"].keys())\n\n            if nb_steps is None:\n                grp_name = list(f[\"data\"].keys())[0]\n                nb_steps = list(f[f\"data/{grp_name}\"].keys())\n                nb_steps = max(\n                    [\n                        int(step)\n                        for step in nb_steps\n                        if not (\n                            step.startswith(\"__\") or step.endswith(\"_intermediates\")\n                        )\n                    ]\n                )\n\n            # temporary fix to load coordinates/geometry\n            coords_name = (\n                \"geometry\"\n                if \"geometry\"\n                in f[f\"{self._mesh_location}/{self._default_mesh}\"].keys()\n                else \"coordinates\"\n            )\n\n        with self._file(\"r\"):\n            xdmf_writer = XDMFWriter(self.xdmffile, self._file)\n            xdmf_writer.write_points_cells(\n                f\"{self._mesh_location}/{self._default_mesh}/{coords_name}\",\n                f\"{self._mesh_location}/{self._default_mesh}/topology\",\n            )\n\n            if fields:\n                xdmf_writer.add_timeseries(nb_steps + 1, fields)\n            xdmf_writer.write_file()\n\n    self._comm.barrier()"
            },
            "create_run_script": {
              "name": "create_run_script",
              "path": "bamboost.simulation.Simulation.create_run_script",
              "signature": "(self, commands, euler = True, sbatch_kwargs = None) -> None",
              "description": "Create a batch job and put it into the folder.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "commands",
                  "annotation": "list",
                  "description": [
                    {
                      "kind": "text",
                      "value": "A list of strings being the user defined commands to run"
                    }
                  ]
                },
                {
                  "name": "euler",
                  "annotation": "bool",
                  "description": [
                    {
                      "kind": "text",
                      "value": "If false, a local bash script will be written"
                    }
                  ],
                  "value": "True"
                },
                {
                  "name": "sbatch_kwargs",
                  "annotation": "dict",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Additional sbatch arguments.\nThis parameter allows you to provide additional arguments to the `sbatch` command\nwhen submitting jobs to a Slurm workload manager. The arguments should be provided\nin the format of a dict of sbatch option name and values.\n\nUse this parameter to specify various job submission options such as the number of\ntasks, CPU cores, memory requirements, email notifications, and other sbatch options\nthat are not covered by default settings.\nBy default, the following sbatch options are set:\n- `--output`: The output file is set to `<uid>.out`.\n- `--job-name`: The job name is set to `<full_uid>`.\n\nThe following arguments should bring you far:\n- `--ntasks`: The number of tasks to run. This is the number of MPI processes to start.\n- `--mem-per-cpu`: The memory required per CPU core.\n- `--time`: The maximum time the job is allowed to run.\n- `--tmp`: Temporary scratch space to use for the job."
                    }
                  ],
                  "value": "None"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def create_run_script(\n    self,\n    commands: list[str],\n    euler: bool = True,\n    sbatch_kwargs: dict[str, Any] = None,\n) -> None:\n    \"\"\"Create a batch job and put it into the folder.\n\n    Args:\n        commands: A list of strings being the user defined commands to run\n        euler: If false, a local bash script will be written\n        sbatch_kwargs: Additional sbatch arguments.\n            This parameter allows you to provide additional arguments to the `sbatch` command\n            when submitting jobs to a Slurm workload manager. The arguments should be provided\n            in the format of a dict of sbatch option name and values.\n\n            Use this parameter to specify various job submission options such as the number of\n            tasks, CPU cores, memory requirements, email notifications, and other sbatch options\n            that are not covered by default settings.\n            By default, the following sbatch options are set:\n            - `--output`: The output file is set to `<uid>.out`.\n            - `--job-name`: The job name is set to `<full_uid>`.\n\n            The following arguments should bring you far:\n            - `--ntasks`: The number of tasks to run. This is the number of MPI processes to start.\n            - `--mem-per-cpu`: The memory required per CPU core.\n            - `--time`: The maximum time the job is allowed to run.\n            - `--tmp`: Temporary scratch space to use for the job.\n    \"\"\"\n\n    def _set_environment_variables():\n        return (\n            f\"\"\"DATABASE_DIR=$(sqlite3 {paths['DATABASE_FILE']} \"SELECT path FROM dbindex WHERE id='{self.database_id}'\")\\n\"\"\"\n            f\"SIMULATION_DIR=$DATABASE_DIR/{self.uid}\\n\"\n            f\"SIMULATION_ID={self.database_id}:{self.uid}\\n\\n\"\n        )\n\n    script = \"#!/bin/bash\\n\\n\"\n    if euler:\n        # Write sbatch submission script for EULER\n        # filename: sbatch_{self.uid}.sh\n        if sbatch_kwargs is None:\n            sbatch_kwargs = {}\n\n        sbatch_kwargs.setdefault(\"--output\", f\"{self.path}/{self.uid}.out\")\n        sbatch_kwargs.setdefault(\"--job-name\", self.get_full_uid())\n\n        for key, value in sbatch_kwargs.items():\n            script += f\"#SBATCH {key}={value}\\n\"\n\n        script += \"\\n\"\n        script += _set_environment_variables()\n        script += \"\\n\".join(commands)\n\n        with open(self.files(f\"sbatch_{self.uid}.sh\"), \"w\") as file:\n            file.write(script)\n    else:\n        # Write local bash script\n        # filename: {self.uid}.sh\n        script += _set_environment_variables()\n        script += \"\\n\".join(commands)\n\n        with open(self.files(f\"{self.uid}.sh\"), \"w\") as file:\n            file.write(script)\n\n    with self._file(\"a\") as file:\n        file.attrs.update({\"submitted\": False})\n    self._push_update_to_sqlite({\"submitted\": False})"
            },
            "create_batch_script": {
              "name": "create_batch_script",
              "path": "bamboost.simulation.Simulation.create_batch_script",
              "signature": "(self, *args, **kwargs)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "args",
                  "annotation": null,
                  "description": null,
                  "value": "()"
                },
                {
                  "name": "kwargs",
                  "annotation": null,
                  "description": null,
                  "value": "{}"
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "@deprecated(\"use `create_run_script` instead\")\ndef create_batch_script(self, *args, **kwargs):\n    return self.create_run_script(*args, **kwargs)"
            },
            "submit": {
              "name": "submit",
              "path": "bamboost.simulation.Simulation.submit",
              "signature": "(self) -> None",
              "description": "Submit the job for this simulation.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def submit(self) -> None:\n    \"\"\"Submit the job for this simulation.\"\"\"\n    if f\"sbatch_{self.uid}.sh\" in os.listdir(self.path):\n        batch_script = os.path.abspath(\n            os.path.join(self.path, f\"sbatch_{self.uid}.sh\")\n        )\n        env = os.environ.copy()\n        _ = env.pop(\"BAMBOOST_MPI\", None)\n        subprocess.run([\"sbatch\", f\"{batch_script}\"], env=env)\n    elif f\"{self.uid}.sh\" in os.listdir(self.path):\n        bash_script = os.path.abspath(os.path.join(self.path, f\"{self.uid}.sh\"))\n        env = os.environ.copy()\n        _ = env.pop(\"BAMBOOST_MPI\", None)\n        subprocess.run([\"bash\", f\"{bash_script}\"], env=env)\n    else:\n        raise FileNotFoundError(\n            f\"Could not find a batch script for simulation {self.uid}.\"\n        )\n\n    log.info(f\"Simulation {self.uid} submitted!\")\n\n    with self._file(\"a\") as file:\n        file.attrs.update({\"submitted\": True})\n\n    self._push_update_to_sqlite({\"submitted\": True})"
            },
            "change_note": {
              "name": "change_note",
              "path": "bamboost.simulation.Simulation.change_note",
              "signature": "(self, note) -> None",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "note",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "@with_file_open(\"a\")\ndef change_note(self, note) -> None:\n    if self._prank == 0:\n        self._file.attrs[\"notes\"] = note\n        self._push_update_to_sqlite({\"notes\": note})"
            },
            "open": {
              "name": "open",
              "path": "bamboost.simulation.Simulation.open",
              "signature": "(self, mode = 'r', driver = None, comm = None) -> bamboost.common.file_handler.FileHandler",
              "description": "Use this as a context manager in a `with` statement.\nPurpose: keeping the file open to directly access/edit something in the\nHDF5 file of this simulation.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "mode",
                  "annotation": "`str`",
                  "description": [
                    {
                      "kind": "text",
                      "value": "file mode (see h5py docs)"
                    }
                  ],
                  "value": "'r'"
                },
                {
                  "name": "driver",
                  "annotation": "`str`",
                  "description": [
                    {
                      "kind": "text",
                      "value": "file driver (see h5py docs)"
                    }
                  ],
                  "value": "None"
                },
                {
                  "name": "comm",
                  "annotation": "`str`",
                  "description": [
                    {
                      "kind": "text",
                      "value": "mpi communicator"
                    }
                  ],
                  "value": "None"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "bamboost.common.file_handler.FileHandler",
                "description": null
              },
              "docstring": [],
              "source": "def open(self, mode: str = \"r\", driver=None, comm=None) -> FileHandler:\n    \"\"\"Use this as a context manager in a `with` statement.\n    Purpose: keeping the file open to directly access/edit something in the\n    HDF5 file of this simulation.\n\n    Args:\n        mode (`str`): file mode (see h5py docs)\n        driver (`str`): file driver (see h5py docs)\n        comm (`str`): mpi communicator\n    \"\"\"\n    return self._file(mode, driver, comm)"
            },
            "get_mesh": {
              "name": "get_mesh",
              "path": "bamboost.simulation.Simulation.get_mesh",
              "signature": "(self, mesh_name = None) -> typing.Tuple",
              "description": "Return coordinates and connectivity. Currently returns numpy arrays.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "mesh_name",
                  "annotation": "`str`",
                  "description": [
                    {
                      "kind": "text",
                      "value": "optional, name of mesh to read (default = mesh)"
                    }
                  ],
                  "value": "None"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "typing.Tuple",
                "description": null
              },
              "docstring": [
                {
                  "kind": "text",
                  "value": "Returns:\n    Tuple of np.arrays (coordinates, connectivity)"
                }
              ],
              "source": "@with_file_open(\"r\")\ndef get_mesh(self, mesh_name: str = None) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Return coordinates and connectivity. Currently returns numpy arrays.\n\n    Args:\n        mesh_name (`str`): optional, name of mesh to read (default = mesh)\n    Returns:\n        Tuple of np.arrays (coordinates, connectivity)\n    \"\"\"\n    if mesh_name is None:\n        mesh_name = self._default_mesh\n\n    # Raise an error if the mesh is not found\n    if (self._mesh_location.split(\"/\")[0] not in self._file.keys()) or (\n        mesh_name not in self._file[self._mesh_location].keys()\n    ):\n        raise KeyError(f\"Mesh location {self._mesh_location} not found in file.\")\n\n    mesh = self.meshes[mesh_name]\n    return mesh.coordinates, mesh.connectivity"
            },
            "get_data_interpolator": {
              "name": "get_data_interpolator",
              "path": "bamboost.simulation.Simulation.get_data_interpolator",
              "signature": "(self, field, step)",
              "description": "Get Linear interpolator for data field at step. Uses the linked mesh.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "field",
                  "annotation": "str",
                  "description": null,
                  "value": null
                },
                {
                  "name": "step",
                  "annotation": "`int`",
                  "description": [
                    {
                      "kind": "text",
                      "value": "step"
                    }
                  ]
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [
                {
                  "kind": "text",
                  "value": "Returns:\n    :class:`scipy.interpolate.LinearNDInterpolator`"
                }
              ],
              "source": "def get_data_interpolator(self, field: str, step: int):\n    \"\"\"Get Linear interpolator for data field at step. Uses the linked mesh.\n\n    Args:\n        name (`str`): name of the data field\n        step (`int`): step\n    Returns:\n        :class:`scipy.interpolate.LinearNDInterpolator`\n    \"\"\"\n    from scipy.interpolate import LinearNDInterpolator\n\n    return LinearNDInterpolator(\n        self.data[field].mesh.coordinates, self.data[field].at_step(step)\n    )"
            },
            "show_h5tree": {
              "name": "show_h5tree",
              "path": "bamboost.simulation.Simulation.show_h5tree",
              "signature": "(self) -> None",
              "description": "Print the tree inside the h5 file.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "@with_file_open()\ndef show_h5tree(self) -> None:\n    \"\"\"Print the tree inside the h5 file.\"\"\"\n    # print('\\U00002B57 ' + os.path.basename(self.h5file))\n    print(\"\\U0001f43c \" + os.path.basename(self.h5file))\n    utilities.h5_tree(self._file.file_object)"
            },
            "enter_path": {
              "name": "enter_path",
              "path": "bamboost.simulation.Simulation.enter_path",
              "signature": "(self)",
              "description": "A context manager for changing the working directory to this simulations' path.\n\n>>> with sim.working_directory():\n>>>     ...",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "@contextmanager\ndef enter_path(self):\n    \"\"\"A context manager for changing the working directory to this simulations' path.\n\n    >>> with sim.working_directory():\n    >>>     ...\n    \"\"\"\n\n    current_dir = os.getcwd()\n    try:\n        os.chdir(self.path)\n        yield\n    finally:\n        os.chdir(current_dir)"
            }
          },
          "source": "class Simulation:\n    \"\"\"A single dataset/simulation. Used to write to it, read from it or append.\n\n    Args:\n        uid (str): unique identifier\n        path (str): path to parent/database folder\n        comm (MPI.Comm): MPI communicator (default=MPI.COMM_WORLD)\n    \"\"\"\n\n    _mesh_location = \"Mesh/0\"\n    _default_mesh = \"mesh\"\n\n    def __init__(\n        self,\n        uid: str,\n        path: str,\n        comm: MPI.Comm = MPI.COMM_WORLD,\n        create_if_not_exists: bool = False,\n        *,\n        _db_id: str = None,\n    ):\n        self.uid: str = uid\n        path = comm.bcast(path, root=0)\n        self.path_database: str = os.path.abspath(path)\n        self.database_id = _db_id or index.get_uid_from_path(self.path_database)\n        self.path: str = os.path.abspath(os.path.join(path, uid))\n        self.h5file: str = os.path.join(self.path, f\"{self.uid}.h5\")\n        self.xdmffile: str = os.path.join(self.path, f\"{self.uid}.xdmf\")\n\n        if not os.path.exists(self.h5file) and not create_if_not_exists:\n            raise FileNotFoundError(\n                f\"Simulation {self.uid} does not exist in {self.path}.\"\n            )\n\n        os.makedirs(self.path, exist_ok=True)\n\n        # MPI information\n        self._comm = comm\n        self._psize = self._comm.size\n        self._prank = self._comm.rank\n        self._ranks = np.array([i for i in range(self._psize)])\n\n        self._file = FileHandler(self.h5file)\n\n        # Initialize groups to meshes, data and userdata. Create groups.\n        self.meshes: MeshGroup = MeshGroup(self._file)\n        self.data: DataGroup = DataGroup(self._file, self.meshes)\n        self.globals: GlobalGroup = GlobalGroup(self._file, \"/globals\")\n        self.userdata: hdf_pointer.MutableGroup = hdf_pointer.MutableGroup(\n            self._file, \"/userdata\"\n        )\n        self.links: Links = Links(self._file)\n\n    @classmethod\n    def fromUID(cls, full_uid: str, *, index_database: index.IndexAPI = None) -> Self:\n        \"\"\"Return the `Simulation` with given UID.\n\n        Args:\n            full_uid: the full id (Database uid : simulation uid)\n        \"\"\"\n        if index_database is None:\n            index_database = index.IndexAPI()\n        db_uid, sim_uid = full_uid.split(\":\")\n        db_path = index_database.get_path(db_uid)\n        return cls(sim_uid, db_path, create_if_not_exists=False)\n\n    @with_file_open()\n    def __getitem__(self, key) -> hdf_pointer.BasePointer:\n        \"\"\"Direct access to HDF5 file.\n\n        Returns:\n            :class:`~bamboost.common.file_handler.BasePointer`\n        \"\"\"\n        return hdf_pointer.BasePointer.new_pointer(self._file, key)\n\n    def _repr_html_(self) -> str:\n        html_string = pkgutil.get_data(__name__, \"html/simulation.html\").decode()\n        icon = pkgutil.get_data(__name__, \"html/icon.txt\").decode()\n\n        table_string = \"\"\n        for key, value in self.parameters.items():\n            if (\n                isinstance(value, Iterable)\n                and not isinstance(value, str)\n                and len(value) > 5\n            ):\n                value = \"...\"\n            table_string += f\"\"\"\n            <tr>\n                <td>{key}</td>\n                <td>{value}</td>\n            </tr>\n            \"\"\"\n\n        metadata = self.metadata\n\n        def get_pill_div(text: str, color: str):\n            return (\n                f'<div class=\"status\" style=\"background-color:'\n                f'var(--bb-{color});\">{text}</div>'\n            )\n\n        status_options = {\n            \"Finished\": get_pill_div(\"Finished\", \"green\"),\n            \"Failed\": get_pill_div(\"Failed\", \"red\"),\n            \"Initiated\": get_pill_div(\"Initiated\", \"grey\"),\n        }\n        submitted_options = {\n            True: get_pill_div(\"Submitted\", \"green\"),\n            False: get_pill_div(\"Not submitted\", \"grey\"),\n        }\n\n        html_string = (\n            html_string.replace(\"$UID\", self.uid)\n            .replace(\"$ICON\", icon)\n            .replace(\"$TREE\", self.show_files(printit=False).replace(\"\\n\", \"<br>\"))\n            .replace(\"$TABLE\", table_string)\n            .replace(\"$NOTE\", metadata[\"notes\"])\n            .replace(\n                \"$STATUS\",\n                status_options.get(\n                    metadata[\"status\"],\n                    f'<div class=\"status\">{metadata[\"status\"]}</div>',\n                ),\n            )\n            .replace(\"$SUBMITTED\", submitted_options[metadata.get(\"submitted\", False)])\n            .replace(\"$TIMESTAMP\", metadata[\"time_stamp\"])\n        )\n        return html_string\n\n    def _push_update_to_sqlite(self, update_dict: dict) -> None:\n        \"\"\"Push update to sqlite database.\n\n        Args:\n            - update_dict (dict): key value pair to push\n        \"\"\"\n        if not config[\"options\"].get(\"sync_table\", True):\n            return\n        try:\n            index.DatabaseTable(self.database_id).update_entry(self.uid, update_dict)\n        except index.Error as e:\n            log.warning(f\"Could not update sqlite database: {e}\")\n\n    @property\n    def parameters(self) -> Dict[str, Any]:\n        tmp_dict = dict()\n        if self._prank == 0:\n            with self._file(\"r\"):\n                # return if parameters is not in the file\n                if \"parameters\" not in self._file.keys():\n                    return {}\n                tmp_dict.update(self._file[\"parameters\"].attrs)\n                for key in self._file[\"parameters\"].keys():\n                    tmp_dict.update({key: self._file[f\"parameters/{key}\"][()]})\n\n        tmp_dict = utilities.unflatten_dict(tmp_dict)\n\n        tmp_dict = self._comm.bcast(tmp_dict, root=0)\n        return tmp_dict\n\n    @property\n    def metadata(self) -> dict:\n        tmp_dict = dict()\n        if self._prank == 0:\n            with self._file(\"r\") as file:\n                tmp_dict.update(file.attrs)\n\n        tmp_dict = utilities.unflatten_dict(tmp_dict)\n        tmp_dict = self._comm.bcast(tmp_dict, root=0)\n        return tmp_dict\n\n    def files(self, filename: str) -> str:\n        \"\"\"Get the path to the file.\n\n        Args:\n            filename: name of the file\n        \"\"\"\n        return os.path.join(self.path, filename)\n\n    def show_files(\n        self, level=-1, limit_to_directories=False, length_limit=1000, printit=True\n    ) -> str:\n        \"\"\"Show the file tree of the simulation directory.\n\n        Args:\n            level: how deep to print the tree\n            limit_to_directories: only print directories\n            length_limit: cutoff\n        \"\"\"\n        tree_string = utilities.tree(\n            self.path, level, limit_to_directories, length_limit\n        )\n        if printit:\n            print(tree_string)\n        else:\n            return tree_string\n\n    def open_in_file_explorer(self) -> None:\n        \"\"\"Open the simulation directory. Uses `xdg-open` on linux systems.\"\"\"\n        if os.name == \"nt\":  # should work on Windows\n            os.startfile(self.path)\n        else:\n            subprocess.run([\"xdg-open\", self.path])\n\n    def open_in_paraview(self) -> None:\n        \"\"\"Open the xdmf file in paraview.\"\"\"\n        subprocess.Popen([\"paraview\", self.xdmffile])\n\n    def get_full_uid(self) -> str:\n        \"\"\"Returns the full uid of the simulation (including the one of the database)\"\"\"\n        database_uid = index.get_uid_from_path(self.path_database)\n        return f\"{database_uid}:{self.uid}\"\n\n    def change_status(self, status: str) -> None:\n        \"\"\"Change status of simulation.\n\n        Args:\n            status (str): new status\n        \"\"\"\n        if self._prank == 0:\n            self._file.open(\"a\")\n            self._file.attrs[\"status\"] = status\n            self._file.close()\n\n        self._push_update_to_sqlite({\"status\": status})\n\n    def update_metadata(self, update_dict: dict) -> None:\n        \"\"\"Update the metadata attributes.\n\n        Args:\n            update_dict: dictionary to push\n        \"\"\"\n        if self._prank == 0:\n            update_dict = utilities.flatten_dict(update_dict)\n            with self._file(\"a\") as file:\n                file.attrs.update(update_dict)\n\n            self._push_update_to_sqlite(update_dict)\n\n    def update_parameters(self, update_dict: dict) -> None:\n        \"\"\"Update the parameters dictionary.\n\n        Args:\n            update_dict: dictionary to push\n        \"\"\"\n        if self._prank == 0:\n            update_dict = utilities.flatten_dict(update_dict)\n            with self._file(\"a\") as file:\n                file[\"parameters\"].attrs.update(update_dict)\n\n            self._push_update_to_sqlite(update_dict)\n\n    def create_xdmf_file(self, fields: list = None, nb_steps: int = None) -> None:\n        \"\"\"Create the xdmf file to read in paraview.\n\n        Args:\n            fields (list[str]): fields for which to write timeseries information,\n                if not specified, all fields in data are written.\n            nb_steps (int): number of steps the simulation has\n        \"\"\"\n\n        if self._prank == 0:\n            with self._file(\"r\"):\n                f = self._file.file_object\n                if \"data\" not in f.keys():\n                    fields, nb_steps = [], 0\n                if fields is None:\n                    fields = list(f[\"data\"].keys())\n\n                if nb_steps is None:\n                    grp_name = list(f[\"data\"].keys())[0]\n                    nb_steps = list(f[f\"data/{grp_name}\"].keys())\n                    nb_steps = max(\n                        [\n                            int(step)\n                            for step in nb_steps\n                            if not (\n                                step.startswith(\"__\") or step.endswith(\"_intermediates\")\n                            )\n                        ]\n                    )\n\n                # temporary fix to load coordinates/geometry\n                coords_name = (\n                    \"geometry\"\n                    if \"geometry\"\n                    in f[f\"{self._mesh_location}/{self._default_mesh}\"].keys()\n                    else \"coordinates\"\n                )\n\n            with self._file(\"r\"):\n                xdmf_writer = XDMFWriter(self.xdmffile, self._file)\n                xdmf_writer.write_points_cells(\n                    f\"{self._mesh_location}/{self._default_mesh}/{coords_name}\",\n                    f\"{self._mesh_location}/{self._default_mesh}/topology\",\n                )\n\n                if fields:\n                    xdmf_writer.add_timeseries(nb_steps + 1, fields)\n                xdmf_writer.write_file()\n\n        self._comm.barrier()\n\n    def create_run_script(\n        self,\n        commands: list[str],\n        euler: bool = True,\n        sbatch_kwargs: dict[str, Any] = None,\n    ) -> None:\n        \"\"\"Create a batch job and put it into the folder.\n\n        Args:\n            commands: A list of strings being the user defined commands to run\n            euler: If false, a local bash script will be written\n            sbatch_kwargs: Additional sbatch arguments.\n                This parameter allows you to provide additional arguments to the `sbatch` command\n                when submitting jobs to a Slurm workload manager. The arguments should be provided\n                in the format of a dict of sbatch option name and values.\n\n                Use this parameter to specify various job submission options such as the number of\n                tasks, CPU cores, memory requirements, email notifications, and other sbatch options\n                that are not covered by default settings.\n                By default, the following sbatch options are set:\n                - `--output`: The output file is set to `<uid>.out`.\n                - `--job-name`: The job name is set to `<full_uid>`.\n\n                The following arguments should bring you far:\n                - `--ntasks`: The number of tasks to run. This is the number of MPI processes to start.\n                - `--mem-per-cpu`: The memory required per CPU core.\n                - `--time`: The maximum time the job is allowed to run.\n                - `--tmp`: Temporary scratch space to use for the job.\n        \"\"\"\n\n        def _set_environment_variables():\n            return (\n                f\"\"\"DATABASE_DIR=$(sqlite3 {paths['DATABASE_FILE']} \"SELECT path FROM dbindex WHERE id='{self.database_id}'\")\\n\"\"\"\n                f\"SIMULATION_DIR=$DATABASE_DIR/{self.uid}\\n\"\n                f\"SIMULATION_ID={self.database_id}:{self.uid}\\n\\n\"\n            )\n\n        script = \"#!/bin/bash\\n\\n\"\n        if euler:\n            # Write sbatch submission script for EULER\n            # filename: sbatch_{self.uid}.sh\n            if sbatch_kwargs is None:\n                sbatch_kwargs = {}\n\n            sbatch_kwargs.setdefault(\"--output\", f\"{self.path}/{self.uid}.out\")\n            sbatch_kwargs.setdefault(\"--job-name\", self.get_full_uid())\n\n            for key, value in sbatch_kwargs.items():\n                script += f\"#SBATCH {key}={value}\\n\"\n\n            script += \"\\n\"\n            script += _set_environment_variables()\n            script += \"\\n\".join(commands)\n\n            with open(self.files(f\"sbatch_{self.uid}.sh\"), \"w\") as file:\n                file.write(script)\n        else:\n            # Write local bash script\n            # filename: {self.uid}.sh\n            script += _set_environment_variables()\n            script += \"\\n\".join(commands)\n\n            with open(self.files(f\"{self.uid}.sh\"), \"w\") as file:\n                file.write(script)\n\n        with self._file(\"a\") as file:\n            file.attrs.update({\"submitted\": False})\n        self._push_update_to_sqlite({\"submitted\": False})\n\n    @deprecated(\"use `create_run_script` instead\")\n    def create_batch_script(self, *args, **kwargs):\n        return self.create_run_script(*args, **kwargs)\n\n    def submit(self) -> None:\n        \"\"\"Submit the job for this simulation.\"\"\"\n        if f\"sbatch_{self.uid}.sh\" in os.listdir(self.path):\n            batch_script = os.path.abspath(\n                os.path.join(self.path, f\"sbatch_{self.uid}.sh\")\n            )\n            env = os.environ.copy()\n            _ = env.pop(\"BAMBOOST_MPI\", None)\n            subprocess.run([\"sbatch\", f\"{batch_script}\"], env=env)\n        elif f\"{self.uid}.sh\" in os.listdir(self.path):\n            bash_script = os.path.abspath(os.path.join(self.path, f\"{self.uid}.sh\"))\n            env = os.environ.copy()\n            _ = env.pop(\"BAMBOOST_MPI\", None)\n            subprocess.run([\"bash\", f\"{bash_script}\"], env=env)\n        else:\n            raise FileNotFoundError(\n                f\"Could not find a batch script for simulation {self.uid}.\"\n            )\n\n        log.info(f\"Simulation {self.uid} submitted!\")\n\n        with self._file(\"a\") as file:\n            file.attrs.update({\"submitted\": True})\n\n        self._push_update_to_sqlite({\"submitted\": True})\n\n    @with_file_open(\"a\")\n    def change_note(self, note) -> None:\n        if self._prank == 0:\n            self._file.attrs[\"notes\"] = note\n            self._push_update_to_sqlite({\"notes\": note})\n\n    # Ex-Simulation reader methods\n    # ----------------------------\n\n    def open(self, mode: str = \"r\", driver=None, comm=None) -> FileHandler:\n        \"\"\"Use this as a context manager in a `with` statement.\n        Purpose: keeping the file open to directly access/edit something in the\n        HDF5 file of this simulation.\n\n        Args:\n            mode (`str`): file mode (see h5py docs)\n            driver (`str`): file driver (see h5py docs)\n            comm (`str`): mpi communicator\n        \"\"\"\n        return self._file(mode, driver, comm)\n\n    @property\n    def mesh(self) -> Mesh:\n        \"\"\"Return the default mesh.\n\n        Returns:\n            MeshGroup\n        \"\"\"\n        return self.meshes[self._default_mesh]\n\n    @with_file_open(\"r\")\n    def get_mesh(self, mesh_name: str = None) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"Return coordinates and connectivity. Currently returns numpy arrays.\n\n        Args:\n            mesh_name (`str`): optional, name of mesh to read (default = mesh)\n        Returns:\n            Tuple of np.arrays (coordinates, connectivity)\n        \"\"\"\n        if mesh_name is None:\n            mesh_name = self._default_mesh\n\n        # Raise an error if the mesh is not found\n        if (self._mesh_location.split(\"/\")[0] not in self._file.keys()) or (\n            mesh_name not in self._file[self._mesh_location].keys()\n        ):\n            raise KeyError(f\"Mesh location {self._mesh_location} not found in file.\")\n\n        mesh = self.meshes[mesh_name]\n        return mesh.coordinates, mesh.connectivity\n\n    @property\n    @deprecated(\"Use `data.info` instead\")\n    @with_file_open(\"r\")\n    def data_info(self) -> pd.DataFrame:\n        \"\"\"View the data stored.\n\n        Returns:\n            :class:`pd.DataFrame`\n        \"\"\"\n        tmp_dictionary = dict()\n        for data in self.data:\n            steps = len(data)\n            shape = data.obj[\"0\"].shape\n            dtype = data.obj[\"0\"].dtype\n            tmp_dictionary[data._name] = {\n                \"dtype\": dtype,\n                \"shape\": shape,\n                \"steps\": steps,\n            }\n        return pd.DataFrame.from_dict(tmp_dictionary)\n\n    @property\n    @with_file_open(\"r\")\n    def git(self) -> dict:\n        \"\"\"Get Git information.\n\n        Returns:\n            :class:`dict` with different repositories.\n        \"\"\"\n        if \"git\" not in self._file.keys():\n            return \"Sorrrry, no git information stored :()\"\n        grp = self._file[\"git\"]\n        tmp_dict = {}\n        for repo in grp.keys():\n            tmp_dict[repo] = grp[repo][()].decode(\"utf8\")\n        return tmp_dict\n\n    def get_data_interpolator(self, field: str, step: int):\n        \"\"\"Get Linear interpolator for data field at step. Uses the linked mesh.\n\n        Args:\n            name (`str`): name of the data field\n            step (`int`): step\n        Returns:\n            :class:`scipy.interpolate.LinearNDInterpolator`\n        \"\"\"\n        from scipy.interpolate import LinearNDInterpolator\n\n        return LinearNDInterpolator(\n            self.data[field].mesh.coordinates, self.data[field].at_step(step)\n        )\n\n    @with_file_open()\n    def show_h5tree(self) -> None:\n        \"\"\"Print the tree inside the h5 file.\"\"\"\n        # print('\\U00002B57 ' + os.path.basename(self.h5file))\n        print(\"\\U0001f43c \" + os.path.basename(self.h5file))\n        utilities.h5_tree(self._file.file_object)\n\n    @contextmanager\n    def enter_path(self):\n        \"\"\"A context manager for changing the working directory to this simulations' path.\n\n        >>> with sim.working_directory():\n        >>>     ...\n        \"\"\"\n\n        current_dir = os.getcwd()\n        try:\n            os.chdir(self.path)\n            yield\n        finally:\n            os.chdir(current_dir)",
          "inherited_members": {}
        }
      },
      "functions": {}
    },
    "_version": {
      "name": "_version",
      "path": "bamboost._version",
      "filepath": "/home/florez/work/code/bamboost/bamboost/_version.py",
      "description": null,
      "docstring": [],
      "attributes": [
        {
          "name": "TYPE_CHECKING",
          "annotation": null,
          "description": null,
          "value": "False"
        },
        {
          "name": "VERSION_TUPLE",
          "annotation": null,
          "description": null,
          "value": "Tuple"
        },
        {
          "name": "version",
          "annotation": "str",
          "description": null,
          "value": "'0.8.1'"
        },
        {
          "name": "__version__",
          "annotation": "str",
          "description": null,
          "value": "'0.8.1'"
        },
        {
          "name": "__version_tuple__",
          "annotation": "VERSION_TUPLE",
          "description": null,
          "value": "(0, 8, 1)"
        },
        {
          "name": "version_tuple",
          "annotation": "VERSION_TUPLE",
          "description": null,
          "value": "(0, 8, 1)"
        }
      ],
      "modules": {},
      "classes": {},
      "functions": {}
    },
    "manager": {
      "name": "manager",
      "path": "bamboost.manager",
      "filepath": "/home/florez/work/code/bamboost/bamboost/manager.py",
      "description": "This module provides the Manager class, which is the main interface to the\ndatabase. It provides access to the simulations and their parameters.",
      "docstring": [],
      "attributes": [
        {
          "name": "__all__",
          "annotation": null,
          "description": null,
          "value": "['Manager', 'ManagerFromUID', 'ManagerFromName']"
        },
        {
          "name": "log",
          "annotation": null,
          "description": null,
          "value": "BAMBOOST_LOGGER.getChild(__name__.split('.')[-1])"
        }
      ],
      "modules": {},
      "classes": {
        "ManagerFromUID": {
          "name": "ManagerFromUID",
          "path": "bamboost.manager.ManagerFromUID",
          "description": "Get a database by its UID. This is used for autocompletion in ipython.",
          "parameters": [
            {
              "name": "self",
              "annotation": null,
              "description": null,
              "value": null
            }
          ],
          "attributes": [
            {
              "name": "completion_keys",
              "annotation": null,
              "description": null,
              "value": "tuple([f'{key} - {'...' + val[-25:] if len(val) >= 25 else val}' for (key, val) in ids])"
            }
          ],
          "docstring": [],
          "functions": {
            "__init__": {
              "name": "__init__",
              "path": "bamboost.manager.ManagerFromUID.__init__",
              "signature": "(self) -> None",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def __init__(self) -> None:\n    # or [] to circumvent Null type (MPI)\n    ids = IndexAPI().fetch(f\"SELECT id, path FROM dbindex\") or []\n    self.completion_keys = tuple(\n        [f'{key} - {\"...\"+val[-25:] if len(val)>=25 else val}' for key, val in ids]\n    )"
            },
            "_ipython_key_completions_": {
              "name": "_ipython_key_completions_",
              "path": "bamboost.manager.ManagerFromUID._ipython_key_completions_",
              "signature": "(self)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def _ipython_key_completions_(self):\n    return self.completion_keys"
            },
            "__getitem__": {
              "name": "__getitem__",
              "path": "bamboost.manager.ManagerFromUID.__getitem__",
              "signature": "(self, key) -> bamboost.manager.Manager",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "key",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "bamboost.manager.Manager",
                "description": null
              },
              "docstring": [],
              "source": "def __getitem__(self, key) -> Manager:\n    key = key.split()[0]  # take only uid\n    return Manager(uid=key, create_if_not_exist=False)"
            }
          },
          "source": "class ManagerFromUID(object):\n    \"\"\"Get a database by its UID. This is used for autocompletion in ipython.\"\"\"\n\n    def __init__(self) -> None:\n        # or [] to circumvent Null type (MPI)\n        ids = IndexAPI().fetch(f\"SELECT id, path FROM dbindex\") or []\n        self.completion_keys = tuple(\n            [f'{key} - {\"...\"+val[-25:] if len(val)>=25 else val}' for key, val in ids]\n        )\n\n    def _ipython_key_completions_(self):\n        return self.completion_keys\n\n    def __getitem__(self, key) -> Manager:\n        key = key.split()[0]  # take only uid\n        return Manager(uid=key, create_if_not_exist=False)",
          "inherited_members": {}
        },
        "ManagerFromName": {
          "name": "ManagerFromName",
          "path": "bamboost.manager.ManagerFromName",
          "description": "Get a database by its path/name. This is used for autocompletion in ipython.",
          "parameters": [
            {
              "name": "self",
              "annotation": null,
              "description": null,
              "value": null
            }
          ],
          "attributes": [
            {
              "name": "completion_keys",
              "annotation": null,
              "description": null,
              "value": "tuple(paths)"
            }
          ],
          "docstring": [],
          "functions": {
            "__init__": {
              "name": "__init__",
              "path": "bamboost.manager.ManagerFromName.__init__",
              "signature": "(self) -> None",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def __init__(self) -> None:\n    paths = IndexAPI().fetch(\"SELECT path FROM dbindex\") or []\n    self.completion_keys = tuple(paths)"
            },
            "_ipython_key_completions_": {
              "name": "_ipython_key_completions_",
              "path": "bamboost.manager.ManagerFromName._ipython_key_completions_",
              "signature": "(self)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def _ipython_key_completions_(self):\n    return self.completion_keys"
            },
            "__getitem__": {
              "name": "__getitem__",
              "path": "bamboost.manager.ManagerFromName.__getitem__",
              "signature": "(self, key) -> bamboost.manager.Manager",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "key",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "bamboost.manager.Manager",
                "description": null
              },
              "docstring": [],
              "source": "def __getitem__(self, key) -> Manager:\n    return Manager(key, create_if_not_exist=False)"
            }
          },
          "source": "class ManagerFromName(object):\n    \"\"\"Get a database by its path/name. This is used for autocompletion in ipython.\"\"\"\n\n    def __init__(self) -> None:\n        paths = IndexAPI().fetch(\"SELECT path FROM dbindex\") or []\n        self.completion_keys = tuple(paths)\n\n    def _ipython_key_completions_(self):\n        return self.completion_keys\n\n    def __getitem__(self, key) -> Manager:\n        return Manager(key, create_if_not_exist=False)",
          "inherited_members": {}
        },
        "Manager": {
          "name": "Manager",
          "path": "bamboost.manager.Manager",
          "description": "View of database.",
          "parameters": [
            {
              "name": "self",
              "annotation": null,
              "description": null,
              "value": null
            },
            {
              "name": "path",
              "annotation": "`str`",
              "description": [
                {
                  "kind": "text",
                  "value": "path to the directory of the database. If doesn't exist,\na new database will be created."
                }
              ],
              "value": "None"
            },
            {
              "name": "comm",
              "annotation": "`MPI.Comm`",
              "description": [
                {
                  "kind": "text",
                  "value": "MPI communicator"
                }
              ],
              "value": "MPI.COMM_WORLD"
            },
            {
              "name": "uid",
              "annotation": "str",
              "description": [
                {
                  "kind": "text",
                  "value": "UID of the database"
                }
              ],
              "value": "None"
            },
            {
              "name": "create_if_not_exist",
              "annotation": "bool",
              "description": null,
              "value": "True"
            }
          ],
          "attributes": [
            {
              "name": "FIX_DF",
              "annotation": null,
              "description": "If False, the dataframe of the database is reconstructed every\ntime it is accessed.",
              "value": "True"
            },
            {
              "name": "fromUID",
              "annotation": "ManagerFromUID",
              "description": "Access a database by its UID",
              "value": "ManagerFromUID()"
            },
            {
              "name": "fromName",
              "annotation": "ManagerFromName",
              "description": "Access a database by its path/name",
              "value": "ManagerFromName()"
            },
            {
              "name": "path",
              "annotation": null,
              "description": null,
              "value": "path"
            },
            {
              "name": "comm",
              "annotation": null,
              "description": null,
              "value": "comm"
            },
            {
              "name": "UID",
              "annotation": null,
              "description": null,
              "value": "uid or self._retrieve_uid()"
            },
            {
              "name": "_index",
              "annotation": "IndexAPI",
              "description": null,
              "value": null
            },
            {
              "name": "_table",
              "annotation": "DatabaseTable",
              "description": null,
              "value": null
            },
            {
              "name": "all_uids",
              "annotation": "list",
              "description": null,
              "value": null
            },
            {
              "name": "df",
              "annotation": "pd.DataFrame",
              "description": null,
              "value": null
            },
            {
              "name": "data_info",
              "annotation": "pd.DataFrame",
              "description": null,
              "value": null
            }
          ],
          "docstring": [
            {
              "kind": "examples",
              "value": [
                [
                  "examples",
                  ">>> db = Manager(\"path/to/db\")\n>>> db.df # DataFrame of the database"
                ]
              ]
            }
          ],
          "functions": {
            "__init__": {
              "name": "__init__",
              "path": "bamboost.manager.Manager.__init__",
              "signature": "(self, path = None, comm = MPI.COMM_WORLD, uid = None, create_if_not_exist = True)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "path",
                  "annotation": "str",
                  "description": null,
                  "value": "None"
                },
                {
                  "name": "comm",
                  "annotation": "MPI.Comm",
                  "description": null,
                  "value": "MPI.COMM_WORLD"
                },
                {
                  "name": "uid",
                  "annotation": "str",
                  "description": null,
                  "value": "None"
                },
                {
                  "name": "create_if_not_exist",
                  "annotation": "bool",
                  "description": null,
                  "value": "True"
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def __init__(\n    self,\n    path: str = None,\n    comm: MPI.Comm = MPI.COMM_WORLD,\n    uid: str = None,\n    create_if_not_exist: bool = True,\n):\n    # provided uid has precedence\n    if uid is not None:\n        path = self._index.get_path(uid.upper())\n        path = comm.bcast(path, root=0)\n    self.path = path\n    self.comm = comm\n\n    # check if path exists\n    if not os.path.isdir(path):\n        if not create_if_not_exist:\n            raise NotADirectoryError(\"Specified path is not a valid path.\")\n        log.info(f\"Created new database ({path})\")\n        self._make_new(path)\n\n    # retrieve the UID of the database from the id file\n    # if not found, a new one is generated\n    self.UID = uid or self._retrieve_uid()\n\n    # Update the SQL table for the database\n    try:\n        with self._index.open():\n            self._index.insert_path(self.UID, self.path)\n            self._table.create_database_table()\n            self._table.sync()\n    except index.Error as e:\n        log.warning(f\"index error: {e}\")"
            },
            "__getitem__": {
              "name": "__getitem__",
              "path": "bamboost.manager.Manager.__getitem__",
              "signature": "(self, key) -> bamboost.simulation.Simulation",
              "description": "Returns the simulation in the specified row of the dataframe.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "key",
                  "annotation": "Union",
                  "description": [
                    {
                      "kind": "text",
                      "value": "The simulation identifier (`str`) or the row index (`int`)."
                    }
                  ]
                }
              ],
              "returns": {
                "name": "",
                "annotation": "bamboost.simulation.Simulation",
                "description": null
              },
              "docstring": [
                {
                  "kind": "text",
                  "value": "Returns:\n    The selected simulation object."
                }
              ],
              "source": "def __getitem__(self, key: Union[str, int]) -> Simulation:\n    \"\"\"Returns the simulation in the specified row of the dataframe.\n\n    Args:\n        key: The simulation identifier (`str`) or the row index (`int`).\n    Returns:\n        The selected simulation object.\n    \"\"\"\n    if isinstance(key, str):\n        return self.sim(key)\n    else:\n        return self.sim(self.df.loc[key, \"id\"])"
            },
            "_repr_html_": {
              "name": "_repr_html_",
              "path": "bamboost.manager.Manager._repr_html_",
              "signature": "(self) -> str",
              "description": "HTML repr for ipython/notebooks. Uses string replacement to fill the\ntemplate code.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "str",
                "description": null
              },
              "docstring": [],
              "source": "def _repr_html_(self) -> str:\n    \"\"\"HTML repr for ipython/notebooks. Uses string replacement to fill the\n    template code.\n    \"\"\"\n    html_string = pkgutil.get_data(__name__, \"html/manager.html\").decode()\n    icon = pkgutil.get_data(__name__, \"html/icon.txt\").decode()\n    return (\n        html_string.replace(\"$ICON\", icon)\n        .replace(\"$db_path\", self.path)\n        .replace(\"$db_uid\", self.UID)\n        .replace(\"$db_size\", str(len(self)))\n    )"
            },
            "__len__": {
              "name": "__len__",
              "path": "bamboost.manager.Manager.__len__",
              "signature": "(self) -> int",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "int",
                "description": null
              },
              "docstring": [],
              "source": "def __len__(self) -> int:\n    return len(self.all_uids)"
            },
            "__iter__": {
              "name": "__iter__",
              "path": "bamboost.manager.Manager.__iter__",
              "signature": "(self) -> typing.Generator",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "typing.Generator",
                "description": null
              },
              "docstring": [],
              "source": "def __iter__(self) -> Generator[Simulation, None, None]:\n    for sim in self.sims():\n        yield sim"
            },
            "_ipython_key_completions_": {
              "name": "_ipython_key_completions_",
              "path": "bamboost.manager.Manager._ipython_key_completions_",
              "signature": "(self)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def _ipython_key_completions_(self):\n    return self.all_uids"
            },
            "_retrieve_uid": {
              "name": "_retrieve_uid",
              "path": "bamboost.manager.Manager._retrieve_uid",
              "signature": "(self) -> str",
              "description": "Get the UID of this database from the file tree.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "str",
                "description": null
              },
              "docstring": [],
              "source": "def _retrieve_uid(self) -> str:\n    \"\"\"Get the UID of this database from the file tree.\"\"\"\n    try:\n        return index.get_uid_from_path(self.path)\n    except FileNotFoundError:\n        pass\n\n    log.warning(\"Database exists but no UID found. Generating new UID.\")\n    return self._make_new(self.path)"
            },
            "_make_new": {
              "name": "_make_new",
              "path": "bamboost.manager.Manager._make_new",
              "signature": "(self, path) -> str",
              "description": "Initialize a new database.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "path",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "str",
                "description": null
              },
              "docstring": [],
              "source": "def _make_new(self, path) -> str:\n    \"\"\"Initialize a new database.\"\"\"\n    from datetime import datetime\n\n    # Create directory for database\n    os.makedirs(path, exist_ok=True)\n\n    # Assign a unique id to the database\n    self.UID = f\"{uuid.uuid4().hex[:10]}\".upper()\n    uid_file = os.path.join(path, f\".BAMBOOST-{self.UID}\")\n    with open(uid_file, \"a\") as f:\n        f.write(self.UID + \"\\n\")\n        f.write(f'Date of creation: {datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")}')\n    os.chmod(uid_file, 0o444)  # read only for uid file\n\n    log.info(f\"Registered new database (uid = {self.UID})\")\n    self._index.insert_path(self.UID, path)\n    return self.UID"
            },
            "_get_uids": {
              "name": "_get_uids",
              "path": "bamboost.manager.Manager._get_uids",
              "signature": "(self) -> list",
              "description": "Get all simulation names in the database.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "list",
                "description": null
              },
              "docstring": [],
              "source": "def _get_uids(self) -> list:\n    \"\"\"Get all simulation names in the database.\"\"\"\n    all_uids = list()\n    for dir in os.listdir(self.path):\n        if not os.path.isdir(os.path.join(self.path, dir)):\n            continue\n        if any(\n            [i.endswith(\".h5\") for i in os.listdir(os.path.join(self.path, dir))]\n        ):\n            all_uids.append(dir)\n    return all_uids"
            },
            "_get_parameters_for_uid": {
              "name": "_get_parameters_for_uid",
              "path": "bamboost.manager.Manager._get_parameters_for_uid",
              "signature": "(self, uid, include_linked_sims = False) -> dict",
              "description": "Get the parameters for a given uid.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "uid",
                  "annotation": "`str`",
                  "description": [
                    {
                      "kind": "text",
                      "value": "uid of the simulation"
                    }
                  ]
                },
                {
                  "name": "include_linked_sims",
                  "annotation": "`bool`",
                  "description": [
                    {
                      "kind": "text",
                      "value": "if True, include the parameters of linked sims"
                    }
                  ],
                  "value": "False"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "dict",
                "description": null
              },
              "docstring": [],
              "source": "def _get_parameters_for_uid(\n    self, uid: str, include_linked_sims: bool = False\n) -> dict:\n    \"\"\"Get the parameters for a given uid.\n\n    Args:\n        uid (`str`): uid of the simulation\n        include_linked_sims (`bool`): if True, include the parameters of linked sims\n    \"\"\"\n    h5file_for_uid = os.path.join(self.path, uid, f\"{uid}.h5\")\n    tmp_dict = dict()\n\n    with open_h5file(h5file_for_uid, \"r\") as f:\n        if \"parameters\" in f.keys():\n            tmp_dict.update(f[\"parameters\"].attrs)\n        if \"additionals\" in f.keys():\n            tmp_dict.update({\"additionals\": dict(f[\"additionals\"].attrs)})\n        tmp_dict.update(f.attrs)\n\n    if include_linked_sims:\n        for linked, full_uid in self.sim(uid).links.attrs.items():\n            sim = Simulation.fromUID(full_uid)\n            tmp_dict.update(\n                {f\"{linked}.{key}\": val for key, val in sim.parameters.items()}\n            )\n    return tmp_dict"
            },
            "get_view": {
              "name": "get_view",
              "path": "bamboost.manager.Manager.get_view",
              "signature": "(self, include_linked_sims = False) -> pandas.DataFrame",
              "description": "View of the database and its parametric space. Read from the sql\ndatabase. If `include_linked_sims` is True, the individual h5 files are\nscanned.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "include_linked_sims",
                  "annotation": "bool",
                  "description": [
                    {
                      "kind": "text",
                      "value": "if True, include the parameters of linked sims"
                    }
                  ],
                  "value": "False"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "pandas.DataFrame",
                "description": null
              },
              "docstring": [
                {
                  "kind": "examples",
                  "value": [
                    [
                      "examples",
                      ">>> db.get_view()\n>>> db.get_view(include_linked_sims=True)"
                    ]
                  ]
                }
              ],
              "source": "def get_view(self, include_linked_sims: bool = False) -> pd.DataFrame:\n    \"\"\"View of the database and its parametric space. Read from the sql\n    database. If `include_linked_sims` is True, the individual h5 files are\n    scanned.\n\n    Args:\n        include_linked_sims: if True, include the parameters of linked sims\n\n    Examples:\n        >>> db.get_view()\n        >>> db.get_view(include_linked_sims=True)\n    \"\"\"\n    if include_linked_sims:\n        return self.get_view_from_hdf_files(include_linked_sims=include_linked_sims)\n\n    try:\n        with self._table.open():\n            self._table.sync()\n            df = self._table.read_table()\n    except index.Error as e:\n        log.warning(f\"index error: {e}\")\n        return self.get_view_from_hdf_files(include_linked_sims=include_linked_sims)\n\n    if df.empty:\n        return df\n    df[\"time_stamp\"] = pd.to_datetime(df[\"time_stamp\"])\n\n    # Sort dataframe columns\n    columns_start = [\"id\", \"notes\", \"status\", \"time_stamp\"]\n    columns_start = [col for col in columns_start if col in df.columns]\n    self._dataframe = df[[*columns_start, *df.columns.difference(columns_start)]]\n\n    opts = config.get(\"options\", {})\n    if \"sort_table_key\" in opts:\n        self._dataframe.sort_values(\n            opts.get(\"sort_table_key\", \"id\"),\n            ascending=opts.get(\"sort_table_order\", \"asc\") == \"asc\",\n            inplace=True,\n        )\n    return self._dataframe"
            },
            "get_view_from_hdf_files": {
              "name": "get_view_from_hdf_files",
              "path": "bamboost.manager.Manager.get_view_from_hdf_files",
              "signature": "(self, include_linked_sims = False) -> pandas.DataFrame",
              "description": "View of the database and its parametric space. Read from the h5\nfiles metadata.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "include_linked_sims",
                  "annotation": "bool",
                  "description": [
                    {
                      "kind": "text",
                      "value": "if True, include the parameters of linked sims"
                    }
                  ],
                  "value": "False"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "pandas.DataFrame",
                "description": null
              },
              "docstring": [],
              "source": "def get_view_from_hdf_files(\n    self, include_linked_sims: bool = False\n) -> pd.DataFrame:\n    \"\"\"View of the database and its parametric space. Read from the h5\n    files metadata.\n\n    Args:\n        include_linked_sims: if True, include the parameters of linked sims\n    \"\"\"\n    all_uids = self._get_uids()\n    data = list()\n\n    for uid in all_uids:\n        tmp_dict = self._get_parameters_for_uid(\n            uid, include_linked_sims=include_linked_sims\n        )\n        data.append(tmp_dict)\n\n    df = pd.DataFrame.from_records(data)\n    if df.empty:\n        return df\n    df[\"time_stamp\"] = pd.to_datetime(df[\"time_stamp\"])\n\n    # Sort dataframe columns\n    columns_start = [\"id\", \"notes\", \"status\", \"time_stamp\"]\n    columns_start = [col for col in columns_start if col in df.columns]\n    self._dataframe = df[[*columns_start, *df.columns.difference(columns_start)]]\n    return self._dataframe"
            },
            "sim": {
              "name": "sim",
              "path": "bamboost.manager.Manager.sim",
              "signature": "(self, uid, return_writer = False, writer_type = SimulationWriter) -> bamboost.simulation.Simulation",
              "description": "Get an existing simulation with uid. Same as accessing with `db[uid]` directly.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "uid",
                  "annotation": "`str`",
                  "description": [
                    {
                      "kind": "text",
                      "value": "unique identifier"
                    }
                  ]
                },
                {
                  "name": "return_writer",
                  "annotation": "bool",
                  "description": [
                    {
                      "kind": "text",
                      "value": "if true, return `SimulationWriter`, otherwise\nreturn `Simulation`"
                    }
                  ],
                  "value": "False"
                },
                {
                  "name": "writer_type",
                  "annotation": "SimulationWriter",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Optionally, you can specify a custom writer type to return."
                    }
                  ],
                  "value": "SimulationWriter"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "bamboost.simulation.Simulation",
                "description": "class:`~bamboost.simulation.Simulation`"
              },
              "docstring": [],
              "source": "def sim(\n    self,\n    uid: str,\n    return_writer: bool = False,\n    writer_type: SimulationWriter = SimulationWriter,\n) -> Simulation:\n    \"\"\"Get an existing simulation with uid. Same as accessing with `db[uid]` directly.\n\n    Args:\n        uid (`str`): unique identifier\n        return_writer: if true, return `SimulationWriter`, otherwise\n            return `Simulation`\n        writer_type: Optionally, you can specify a custom writer type to return.\n\n    Returns:\n        :class:`~bamboost.simulation.Simulation`\n    \"\"\"\n    if return_writer:\n        return writer_type(uid, self.path, self.comm)\n    return Simulation(uid, self.path, self.comm, _db_id=self.UID)"
            },
            "sims": {
              "name": "sims",
              "path": "bamboost.manager.Manager.sims",
              "signature": "(self, select = None, sort = None, reverse = False, exclude = None, return_writer = False) -> list",
              "description": "Get all simulations in a list. Optionally, get all simulations matching the\ngiven selection using pandas.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "select",
                  "annotation": "pd.Series | pd.DataFrame | dict",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Selection of simulations. Can be one of the following.\n- Pandas boolean series: A boolean series with the same length as the dataframe.\n- Pandas DataFrame: A subset of the full dataframe.\n- Dictionary: A dictionary with the parameters to select (see `find` for details)."
                    }
                  ],
                  "value": "None"
                },
                {
                  "name": "sort",
                  "annotation": "`str`",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Optionally sort the list with this keyword"
                    }
                  ],
                  "value": "None"
                },
                {
                  "name": "reverse",
                  "annotation": "`bool`",
                  "description": [
                    {
                      "kind": "text",
                      "value": "swap sort direction"
                    }
                  ],
                  "value": "False"
                },
                {
                  "name": "exclude",
                  "annotation": "`list[str]`",
                  "description": [
                    {
                      "kind": "text",
                      "value": "sims to exclude"
                    }
                  ],
                  "value": "None"
                },
                {
                  "name": "return_writer",
                  "annotation": "bool",
                  "description": [
                    {
                      "kind": "text",
                      "value": "if true, return `SimulationWriter`, otherwise\nreturn `Simulation`"
                    }
                  ],
                  "value": "False"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "list",
                "description": "A list of `:class:~bamboost.simulation.Simulation` objects"
              },
              "docstring": [
                {
                  "kind": "examples",
                  "value": [
                    [
                      "examples",
                      ">>> db.sims(select=db.df[\"status\"] == \"finished\", sort=\"time_stamp\")"
                    ]
                  ]
                }
              ],
              "source": "def sims(\n    self,\n    select: pd.Series | pd.DataFrame | dict = None,\n    sort: str = None,\n    reverse: bool = False,\n    exclude: set = None,\n    return_writer: bool = False,\n) -> list[Simulation]:\n    \"\"\"Get all simulations in a list. Optionally, get all simulations matching the\n    given selection using pandas.\n\n    Args:\n        select: Selection of simulations. Can be one of the following.\n            - Pandas boolean series: A boolean series with the same length as the dataframe.\n            - Pandas DataFrame: A subset of the full dataframe.\n            - Dictionary: A dictionary with the parameters to select (see `find` for details).\n        sort (`str`): Optionally sort the list with this keyword\n        reverse (`bool`): swap sort direction\n        exclude (`list[str]`): sims to exclude\n        return_writer: if true, return `SimulationWriter`, otherwise\n            return `Simulation`\n\n    Returns:\n        A list of `:class:~bamboost.simulation.Simulation` objects\n\n    Examples:\n        >>> db.sims(select=db.df[\"status\"] == \"finished\", sort=\"time_stamp\")\n    \"\"\"\n    if select is None:\n        id_list = self.all_uids\n    elif isinstance(select, pd.DataFrame):\n        id_list = select[\"id\"].values\n    elif isinstance(select, pd.Series):\n        id_list = self.df[select][\"id\"].values\n    elif isinstance(select, dict):\n        id_list = self.find(select)[\"id\"].values\n    else:\n        raise ArgumentError('Invalid argument for argument \"select\"')\n\n    if exclude is not None:\n        exclude = list([exclude]) if isinstance(exclude, str) else exclude\n        id_list = [id for id in id_list if id not in exclude]\n\n    existing_sims = [self.sim(uid, return_writer) for uid in id_list]\n\n    if sort is None:\n        return existing_sims\n    else:\n        return sorted(\n            existing_sims, key=lambda s: s.parameters[sort], reverse=reverse\n        )"
            },
            "create_simulation": {
              "name": "create_simulation",
              "path": "bamboost.manager.Manager.create_simulation",
              "signature": "(self, uid = None, parameters = None, skip_duplicate_check = False, *, prefix = None, duplicate_action = 'prompt', note = None, files = None, links = None) -> bamboost.simulation_writer.SimulationWriter",
              "description": "Get a writer object for a new simulation. This is written for paralell use\nas it is likely that this may be used in an executable, creating multiple runs\nfor a parametric space, which may be run in paralell.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "uid",
                  "annotation": "`str`",
                  "description": [
                    {
                      "kind": "text",
                      "value": "The name/uid for the simulation. If not specified, a random id\nwill be assigned."
                    }
                  ],
                  "value": "None"
                },
                {
                  "name": "parameters",
                  "annotation": "`dict`",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Parameter dictionary. If provided, the parameters will be\nchecked against the existing sims for duplication. Otherwise, they may be\nspecified later with `bamboost.simulation_writer.SimulationWriter.add_parameters`."
                    },
                    {
                      "kind": "admonition",
                      "value": {
                        "annotation": "note",
                        "description": "The parameters are stored in the h5 file as attributes.\n- If the value is a dict, it is flattened using\n  `bamboost.common.utilities.flatten_dict`.\n- If the value is a list/array, it is stored as a dataset."
                      },
                      "title": "Note"
                    }
                  ],
                  "value": "None"
                },
                {
                  "name": "skip_duplicate_check",
                  "annotation": "`bool`",
                  "description": [
                    {
                      "kind": "text",
                      "value": "if True, the duplicate check is skipped."
                    }
                  ],
                  "value": "False"
                },
                {
                  "name": "prefix",
                  "annotation": "`str`",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Prefix for the uid. If not specified, no prefix is used."
                    }
                  ],
                  "value": "None"
                },
                {
                  "name": "duplicate_action",
                  "annotation": "`str`",
                  "description": [
                    {
                      "kind": "text",
                      "value": "how to deal with duplicates. Replace\nfirst duplicate ('r'), Create with altered uid (`c`), Create new\nwith new id (`n`), Abort (`a`) default \"prompt\" for each\nduplicate on a case by case basis."
                    }
                  ],
                  "value": "'prompt'"
                },
                {
                  "name": "note",
                  "annotation": "`str`",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Note for the simulation."
                    }
                  ],
                  "value": "None"
                },
                {
                  "name": "files",
                  "annotation": "`list`",
                  "description": [
                    {
                      "kind": "text",
                      "value": "List of files to copy to the simulation directory."
                    }
                  ],
                  "value": "None"
                },
                {
                  "name": "links",
                  "annotation": "`dict`",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Dictionary of links to other simulations."
                    }
                  ],
                  "value": "None"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "bamboost.simulation_writer.SimulationWriter",
                "description": "A simulation writer object."
              },
              "docstring": [
                {
                  "kind": "admonition",
                  "value": {
                    "annotation": "note",
                    "description": "The files and links are copied to the simulation directory. The files are\ncopied with the same name as the original file. The links are copied with\nthe given name."
                  },
                  "title": "Note"
                },
                {
                  "kind": "examples",
                  "value": [
                    [
                      "examples",
                      ">>> db.create_simulation(parameters={\"a\": 1, \"b\": 2})"
                    ],
                    [
                      "examples",
                      ">>> db.create_simulation(uid=\"my_sim\", parameters={\"a\": 1, \"b\": 2}, prefix=\"test\")"
                    ]
                  ]
                }
              ],
              "source": "def create_simulation(\n    self,\n    uid: str = None,\n    parameters: dict = None,\n    skip_duplicate_check: bool = False,\n    *,\n    prefix: str = None,\n    duplicate_action: str = \"prompt\",\n    note: str = None,\n    files: list[str] = None,\n    links: dict[str, str] = None,\n) -> SimulationWriter:\n    \"\"\"Get a writer object for a new simulation. This is written for paralell use\n    as it is likely that this may be used in an executable, creating multiple runs\n    for a parametric space, which may be run in paralell.\n\n    Note:\n        The files and links are copied to the simulation directory. The files are\n        copied with the same name as the original file. The links are copied with\n        the given name.\n\n    Args:\n        uid (`str`): The name/uid for the simulation. If not specified, a random id\n            will be assigned.\n        parameters (`dict`): Parameter dictionary. If provided, the parameters will be\n            checked against the existing sims for duplication. Otherwise, they may be\n            specified later with `bamboost.simulation_writer.SimulationWriter.add_parameters`.\n\n            Note:\n                The parameters are stored in the h5 file as attributes.\n                - If the value is a dict, it is flattened using\n                  `bamboost.common.utilities.flatten_dict`.\n                - If the value is a list/array, it is stored as a dataset.\n\n        skip_duplicate_check (`bool`): if True, the duplicate check is skipped.\n        prefix (`str`): Prefix for the uid. If not specified, no prefix is used.\n        duplicate_action (`str`): how to deal with duplicates. Replace\n            first duplicate ('r'), Create with altered uid (`c`), Create new\n            with new id (`n`), Abort (`a`) default \"prompt\" for each\n            duplicate on a case by case basis.\n        note (`str`): Note for the simulation.\n        files (`list`): List of files to copy to the simulation directory.\n        links (`dict`): Dictionary of links to other simulations.\n\n    Examples:\n        >>> db.create_simulation(parameters={\"a\": 1, \"b\": 2})\n\n        >>> db.create_simulation(uid=\"my_sim\", parameters={\"a\": 1, \"b\": 2}, prefix=\"test\")\n\n    Returns:\n        A simulation writer object.\n    \"\"\"\n    if parameters and not skip_duplicate_check:\n        go_on = True\n        if self.comm.rank == 0:\n            go_on, uid = self._check_duplicate(\n                parameters, uid, duplicate_action=duplicate_action\n            )\n        self.comm.bcast((go_on, uid), root=0)\n        if not go_on:\n            print(\"Aborting by user desire...\")\n            return None\n\n    if self.comm.rank == 0:\n        if not uid:\n            uid = uuid.uuid4().hex[:8]  # Assign random unique identifier\n        if isinstance(prefix, str) and prefix != \"\":\n            uid = \"_\".join([prefix, uid])\n    uid = self.comm.bcast(uid, root=0)\n\n    try:\n        # Create directory and h5 file\n        if self.comm.rank == 0:\n            os.makedirs(os.path.join(self.path, uid), exist_ok=True)\n            path_to_h5_file = os.path.join(self.path, uid, f\"{uid}.h5\")\n            if os.path.exists(path_to_h5_file):\n                os.remove(path_to_h5_file)\n            h5py.File(path_to_h5_file, \"a\").close()  # create file\n\n        new_sim = SimulationWriter(uid, self.path, self.comm)\n        new_sim.initialize()  # sets metadata and status\n        # add the id to the (fixed) _all_uids list\n        if hasattr(self, \"_all_uids\"):\n            self._all_uids.append(new_sim.uid)\n\n        # Add parameters, note, files, and links\n        if not any([parameters, note, files, links]):\n            return new_sim\n\n        with new_sim._file(\"r+\"):\n            if parameters:\n                new_sim.add_parameters(parameters)\n            if note:\n                new_sim.change_note(note)\n            if files:\n                new_sim.copy_file(files)\n            if links:\n                [\n                    new_sim.links.__setitem__(name, uid)\n                    for name, uid in links.items()\n                ]\n\n        return new_sim\n\n    except Exception as e:\n        # If any error occurs, remove the partially created simulation\n        if self.comm.rank == 0:\n            self.remove(uid)\n        raise e  # Re-raise the exception after cleanup"
            },
            "remove": {
              "name": "remove",
              "path": "bamboost.manager.Manager.remove",
              "signature": "(self, uid) -> None",
              "description": "CAUTION, DELETING DATA. Remove the data of a simulation.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "uid",
                  "annotation": "`str`",
                  "description": [
                    {
                      "kind": "text",
                      "value": "uid"
                    }
                  ]
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def remove(self, uid: str) -> None:\n    \"\"\"CAUTION, DELETING DATA. Remove the data of a simulation.\n\n    Args:\n        uid (`str`): uid\n    \"\"\"\n    shutil.rmtree(os.path.join(self.path, uid))\n    self._table.sync()"
            },
            "find": {
              "name": "find",
              "path": "bamboost.manager.Manager.find",
              "signature": "(self, parameter_selection) -> pandas.DataFrame",
              "description": "Find simulations with the given parameters.\n\nThe dictionary can contain callables to filter inequalities or other\nfilters.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "parameter_selection",
                  "annotation": "dict",
                  "description": [
                    {
                      "kind": "text",
                      "value": "parameter selection dictionary"
                    }
                  ]
                }
              ],
              "returns": {
                "name": "",
                "annotation": "pandas.DataFrame",
                "description": null
              },
              "docstring": [
                {
                  "kind": "examples",
                  "value": [
                    [
                      "examples",
                      ">>> db.find({\"a\": 1, \"b\": lambda x: x > 2})\n>>> db.find({\"a\": 1, \"b\": 2})"
                    ]
                  ]
                }
              ],
              "source": "def find(self, parameter_selection: dict[str, Any]) -> pd.DataFrame:\n    \"\"\"Find simulations with the given parameters.\n\n    The dictionary can contain callables to filter inequalities or other\n    filters.\n\n    Examples:\n        >>> db.find({\"a\": 1, \"b\": lambda x: x > 2})\n        >>> db.find({\"a\": 1, \"b\": 2})\n\n    Args:\n        parameter_selection (dict): parameter selection dictionary\n    \"\"\"\n    parameter_selection = flatten_dict(parameter_selection)\n    params = {}\n    filters = {}\n    for key, val in parameter_selection.items():\n        if callable(val):\n            filters[key] = val\n        else:\n            params[key] = val\n\n    df = self.df\n    matches = self._list_duplicates(params, df=df)\n    matches = df[df.id.isin(matches)]\n    if len(matches) == 0:\n        return matches\n\n    for key, func in filters.items():\n        matches = matches[matches[key].apply(func)]\n\n    return matches"
            },
            "_list_duplicates": {
              "name": "_list_duplicates",
              "path": "bamboost.manager.Manager._list_duplicates",
              "signature": "(self, parameters, *, df = None) -> list",
              "description": "List ids of duplicates of the given parameters.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "parameters",
                  "annotation": "dict",
                  "description": [
                    {
                      "kind": "text",
                      "value": "parameter dictionary"
                    }
                  ]
                },
                {
                  "name": "df",
                  "annotation": "pd.DataFrame",
                  "description": [
                    {
                      "kind": "text",
                      "value": "dataframe to search in. If not provided, the\ndataframe from the sql database is used."
                    }
                  ],
                  "value": "None"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "list",
                "description": null
              },
              "docstring": [],
              "source": "def _list_duplicates(\n    self, parameters: dict, *, df: pd.DataFrame = None\n) -> list[str]:\n    \"\"\"List ids of duplicates of the given parameters.\n\n    Args:\n        parameters (dict): parameter dictionary\n        df (pd.DataFrame): dataframe to search in. If not provided, the\n            dataframe from the sql database is used.\n    \"\"\"\n    if df is None:\n        df: pd.DataFrame = self._table.read_table()\n    params = flatten_dict(parameters)\n\n    class ComparableIterable:\n        def __init__(self, ori):\n            self.ori = np.asarray(ori)\n\n        def __eq__(self, other):\n            other = np.asarray(other)\n            if other.shape != self.ori.shape:\n                return False\n            return (other == self.ori).all()\n\n    # make all iterables comparable by converting them to ComparableIterable\n    for k in params.keys():\n        if isinstance(params[k], Iterable) and not isinstance(params[k], str):\n            params[k] = ComparableIterable(params[k])\n\n    # if any of the parameters is not in the dataframe, no duplicates\n    for p in params:\n        if p not in df.keys():\n            return []\n\n    # get matching rows where all values of the series are equal to the corresponding values in the dataframe\n    s = pd.Series(params)\n    match = df.loc[(df[s.keys()].apply(lambda row: (s == row).all(), axis=1))]\n    return match.id.tolist()"
            },
            "_check_duplicate": {
              "name": "_check_duplicate",
              "path": "bamboost.manager.Manager._check_duplicate",
              "signature": "(self, parameters, uid, duplicate_action = 'prompt') -> tuple",
              "description": "Checking whether the parameters dictionary exists already.\nMay need to be improved...",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "parameters",
                  "annotation": "`dict`",
                  "description": [
                    {
                      "kind": "text",
                      "value": "parameter dictionary to check for"
                    }
                  ]
                },
                {
                  "name": "uid",
                  "annotation": "`str`",
                  "description": [
                    {
                      "kind": "text",
                      "value": "uid"
                    }
                  ]
                },
                {
                  "name": "duplicate_action",
                  "annotation": "str",
                  "description": null,
                  "value": "'prompt'"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "tuple",
                "description": null
              },
              "docstring": [
                {
                  "kind": "text",
                  "value": "Returns:\n    Tuple(Bool, uid) wheter to continue and with what uid."
                }
              ],
              "source": "def _check_duplicate(\n    self, parameters: dict, uid: str, duplicate_action: str = \"prompt\"\n) -> tuple:\n    \"\"\"Checking whether the parameters dictionary exists already.\n    May need to be improved...\n\n    Args:\n        parameters (`dict`): parameter dictionary to check for\n        uid (`str`): uid\n    Returns:\n        Tuple(Bool, uid) wheter to continue and with what uid.\n    \"\"\"\n\n    duplicates = self._list_duplicates(parameters)\n\n    if not duplicates:\n        return True, uid\n\n    print(\n        \"The parameter space already exists. Here are the duplicates:\",\n        flush=True,\n    )\n    print(self.df[self.df[\"id\"].isin([i for i in duplicates])], flush=True)\n\n    if duplicate_action == \"prompt\":\n        # What should be done?\n        prompt = input(\n            \"Replace first duplicate ('r'), Create with altered uid (`c`), \"\n            + \"Create new with new id (`n`), Abort (`a`): \"\n        )\n    else:\n        prompt = duplicate_action\n\n    if prompt == \"r\":\n        self.remove(duplicates[0])\n        return True, uid\n    if prompt == \"a\":\n        return False, uid\n    if prompt == \"n\":\n        return True, uid\n    if prompt == \"c\":\n        return True, self._generate_subuid(duplicates[0].split(\".\")[0])\n\n    raise ArgumentError(\"Answer not valid! Aborting\")"
            },
            "_generate_subuid": {
              "name": "_generate_subuid",
              "path": "bamboost.manager.Manager._generate_subuid",
              "signature": "(self, uid_base) -> str",
              "description": "Return a new sub uid for the base uid.\nFollowing the following format: `base_uid.1`",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "uid_base",
                  "annotation": "`str`",
                  "description": [
                    {
                      "kind": "text",
                      "value": "base uid for which to find the next subid."
                    }
                  ]
                }
              ],
              "returns": {
                "name": "",
                "annotation": "str",
                "description": null
              },
              "docstring": [
                {
                  "kind": "text",
                  "value": "Returns:\n    New uid string"
                }
              ],
              "source": "def _generate_subuid(self, uid_base: str) -> str:\n    \"\"\"Return a new sub uid for the base uid.\n    Following the following format: `base_uid.1`\n\n    Args:\n        uid_base (`str`): base uid for which to find the next subid.\n    Returns:\n        New uid string\n    \"\"\"\n    uid_list = [uid for uid in self.all_uids if uid.startswith(uid_base)]\n    subiterator = max(\n        [int(id.split(\".\")[1]) for id in uid_list if len(id.split(\".\")) > 1] + [0]\n    )\n    return f\"{uid_base}.{subiterator+1}\""
            },
            "global_fields_in_all": {
              "name": "global_fields_in_all",
              "path": "bamboost.manager.Manager.global_fields_in_all",
              "signature": "(self) -> list",
              "description": "Get a list of all global fields in all simulations.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "list",
                "description": "List of global fields"
              },
              "docstring": [],
              "source": "def global_fields_in_all(self) -> list:\n    \"\"\"Get a list of all global fields in all simulations.\n\n    Returns:\n        List of global fields\n    \"\"\"\n    fields = set()\n    for sim in self:\n        try:\n            fields.update(sim.globals.columns)\n        except KeyError:\n            continue\n\n    return fields"
            },
            "get_parameters": {
              "name": "get_parameters",
              "path": "bamboost.manager.Manager.get_parameters",
              "signature": "(self) -> dict",
              "description": "Get the parameters used in this database.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "dict",
                "description": "Dictionary of parameters with it's count, range, and type. Sorted by count."
              },
              "docstring": [],
              "source": "def get_parameters(self) -> dict:\n    \"\"\"Get the parameters used in this database.\n\n    Returns:\n        Dictionary of parameters with it's count, range, and type. Sorted by count.\n    \"\"\"\n    parameters = dict()\n    for sim in self:\n        for key, val in sim.parameters.items():\n            if key not in parameters:\n                range = (val, val) if isinstance(val, numbers.Number) else None\n                parameters[key] = {\"range\": range, \"count\": 1, \"type\": type(val)}\n            else:\n                if isinstance(val, numbers.Number):\n                    parameters[key][\"range\"] = (\n                        min(parameters[key][\"range\"][0], val),\n                        max(parameters[key][\"range\"][1], val),\n                    )\n                parameters[key][\"count\"] += 1\n                parameters[key][\"type\"] = type(val)\n    return dict(\n        sorted(parameters.items(), key=lambda x: x[1][\"count\"], reverse=True)\n    )"
            }
          },
          "source": "class Manager:\n    \"\"\"View of database.\n\n    Args:\n        path (`str`): path to the directory of the database. If doesn't exist,\n            a new database will be created.\n        comm (`MPI.Comm`): MPI communicator\n        uid: UID of the database\n\n    Attributes:\n        FIX_DF: If False, the dataframe of the database is reconstructed every\n            time it is accessed.\n        fromUID: Access a database by its UID\n        fromName: Access a database by its path/name\n\n    Examples:\n        >>> db = Manager(\"path/to/db\")\n        >>> db.df # DataFrame of the database\n    \"\"\"\n\n    FIX_DF = True\n    fromUID: ManagerFromUID = ManagerFromUID()\n    fromName: ManagerFromName = ManagerFromName()\n\n    def __init__(\n        self,\n        path: str = None,\n        comm: MPI.Comm = MPI.COMM_WORLD,\n        uid: str = None,\n        create_if_not_exist: bool = True,\n    ):\n        # provided uid has precedence\n        if uid is not None:\n            path = self._index.get_path(uid.upper())\n            path = comm.bcast(path, root=0)\n        self.path = path\n        self.comm = comm\n\n        # check if path exists\n        if not os.path.isdir(path):\n            if not create_if_not_exist:\n                raise NotADirectoryError(\"Specified path is not a valid path.\")\n            log.info(f\"Created new database ({path})\")\n            self._make_new(path)\n\n        # retrieve the UID of the database from the id file\n        # if not found, a new one is generated\n        self.UID = uid or self._retrieve_uid()\n\n        # Update the SQL table for the database\n        try:\n            with self._index.open():\n                self._index.insert_path(self.UID, self.path)\n                self._table.create_database_table()\n                self._table.sync()\n        except index.Error as e:\n            log.warning(f\"index error: {e}\")\n\n    def __getitem__(self, key: Union[str, int]) -> Simulation:\n        \"\"\"Returns the simulation in the specified row of the dataframe.\n\n        Args:\n            key: The simulation identifier (`str`) or the row index (`int`).\n        Returns:\n            The selected simulation object.\n        \"\"\"\n        if isinstance(key, str):\n            return self.sim(key)\n        else:\n            return self.sim(self.df.loc[key, \"id\"])\n\n    def _repr_html_(self) -> str:\n        \"\"\"HTML repr for ipython/notebooks. Uses string replacement to fill the\n        template code.\n        \"\"\"\n        html_string = pkgutil.get_data(__name__, \"html/manager.html\").decode()\n        icon = pkgutil.get_data(__name__, \"html/icon.txt\").decode()\n        return (\n            html_string.replace(\"$ICON\", icon)\n            .replace(\"$db_path\", self.path)\n            .replace(\"$db_uid\", self.UID)\n            .replace(\"$db_size\", str(len(self)))\n        )\n\n    def __len__(self) -> int:\n        return len(self.all_uids)\n\n    def __iter__(self) -> Generator[Simulation, None, None]:\n        for sim in self.sims():\n            yield sim\n\n    def _ipython_key_completions_(self):\n        return self.all_uids\n\n    @property\n    def _index(self) -> IndexAPI:\n        \"\"\"The index which contains this database.\"\"\"\n        return IndexAPI()\n\n    @property\n    def _table(self) -> DatabaseTable:\n        \"\"\"The table in the sql database for this database.\"\"\"\n        return self._index.get_database_table(self.UID)\n\n    def _retrieve_uid(self) -> str:\n        \"\"\"Get the UID of this database from the file tree.\"\"\"\n        try:\n            return index.get_uid_from_path(self.path)\n        except FileNotFoundError:\n            pass\n\n        log.warning(\"Database exists but no UID found. Generating new UID.\")\n        return self._make_new(self.path)\n\n    def _make_new(self, path) -> str:\n        \"\"\"Initialize a new database.\"\"\"\n        from datetime import datetime\n\n        # Create directory for database\n        os.makedirs(path, exist_ok=True)\n\n        # Assign a unique id to the database\n        self.UID = f\"{uuid.uuid4().hex[:10]}\".upper()\n        uid_file = os.path.join(path, f\".BAMBOOST-{self.UID}\")\n        with open(uid_file, \"a\") as f:\n            f.write(self.UID + \"\\n\")\n            f.write(f'Date of creation: {datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")}')\n        os.chmod(uid_file, 0o444)  # read only for uid file\n\n        log.info(f\"Registered new database (uid = {self.UID})\")\n        self._index.insert_path(self.UID, path)\n        return self.UID\n\n    @property\n    def all_uids(self) -> list:\n        if not self.FIX_DF or not hasattr(self, \"_all_uids\"):\n            self._all_uids = self._get_uids()\n        return self._all_uids\n\n    @all_uids.setter\n    def all_uids(self, value: set | list):\n        self._all_uids = value\n\n    def _get_uids(self) -> list:\n        \"\"\"Get all simulation names in the database.\"\"\"\n        all_uids = list()\n        for dir in os.listdir(self.path):\n            if not os.path.isdir(os.path.join(self.path, dir)):\n                continue\n            if any(\n                [i.endswith(\".h5\") for i in os.listdir(os.path.join(self.path, dir))]\n            ):\n                all_uids.append(dir)\n        return all_uids\n\n    @property\n    def df(self) -> pd.DataFrame:\n        \"\"\"View of the database and its parametric space.\n\n        Returns:\n            :class:`pd.DataFrame`\n        \"\"\"\n        if not hasattr(self, \"_dataframe\"):\n            return self.get_view()\n        if self.FIX_DF and self._dataframe is not None:\n            return self._dataframe\n        return self.get_view()\n\n    def _get_parameters_for_uid(\n        self, uid: str, include_linked_sims: bool = False\n    ) -> dict:\n        \"\"\"Get the parameters for a given uid.\n\n        Args:\n            uid (`str`): uid of the simulation\n            include_linked_sims (`bool`): if True, include the parameters of linked sims\n        \"\"\"\n        h5file_for_uid = os.path.join(self.path, uid, f\"{uid}.h5\")\n        tmp_dict = dict()\n\n        with open_h5file(h5file_for_uid, \"r\") as f:\n            if \"parameters\" in f.keys():\n                tmp_dict.update(f[\"parameters\"].attrs)\n            if \"additionals\" in f.keys():\n                tmp_dict.update({\"additionals\": dict(f[\"additionals\"].attrs)})\n            tmp_dict.update(f.attrs)\n\n        if include_linked_sims:\n            for linked, full_uid in self.sim(uid).links.attrs.items():\n                sim = Simulation.fromUID(full_uid)\n                tmp_dict.update(\n                    {f\"{linked}.{key}\": val for key, val in sim.parameters.items()}\n                )\n        return tmp_dict\n\n    def get_view(self, include_linked_sims: bool = False) -> pd.DataFrame:\n        \"\"\"View of the database and its parametric space. Read from the sql\n        database. If `include_linked_sims` is True, the individual h5 files are\n        scanned.\n\n        Args:\n            include_linked_sims: if True, include the parameters of linked sims\n\n        Examples:\n            >>> db.get_view()\n            >>> db.get_view(include_linked_sims=True)\n        \"\"\"\n        if include_linked_sims:\n            return self.get_view_from_hdf_files(include_linked_sims=include_linked_sims)\n\n        try:\n            with self._table.open():\n                self._table.sync()\n                df = self._table.read_table()\n        except index.Error as e:\n            log.warning(f\"index error: {e}\")\n            return self.get_view_from_hdf_files(include_linked_sims=include_linked_sims)\n\n        if df.empty:\n            return df\n        df[\"time_stamp\"] = pd.to_datetime(df[\"time_stamp\"])\n\n        # Sort dataframe columns\n        columns_start = [\"id\", \"notes\", \"status\", \"time_stamp\"]\n        columns_start = [col for col in columns_start if col in df.columns]\n        self._dataframe = df[[*columns_start, *df.columns.difference(columns_start)]]\n\n        opts = config.get(\"options\", {})\n        if \"sort_table_key\" in opts:\n            self._dataframe.sort_values(\n                opts.get(\"sort_table_key\", \"id\"),\n                ascending=opts.get(\"sort_table_order\", \"asc\") == \"asc\",\n                inplace=True,\n            )\n        return self._dataframe\n\n    def get_view_from_hdf_files(\n        self, include_linked_sims: bool = False\n    ) -> pd.DataFrame:\n        \"\"\"View of the database and its parametric space. Read from the h5\n        files metadata.\n\n        Args:\n            include_linked_sims: if True, include the parameters of linked sims\n        \"\"\"\n        all_uids = self._get_uids()\n        data = list()\n\n        for uid in all_uids:\n            tmp_dict = self._get_parameters_for_uid(\n                uid, include_linked_sims=include_linked_sims\n            )\n            data.append(tmp_dict)\n\n        df = pd.DataFrame.from_records(data)\n        if df.empty:\n            return df\n        df[\"time_stamp\"] = pd.to_datetime(df[\"time_stamp\"])\n\n        # Sort dataframe columns\n        columns_start = [\"id\", \"notes\", \"status\", \"time_stamp\"]\n        columns_start = [col for col in columns_start if col in df.columns]\n        self._dataframe = df[[*columns_start, *df.columns.difference(columns_start)]]\n        return self._dataframe\n\n    @property\n    def data_info(self) -> pd.DataFrame:\n        \"\"\"Return view of stored data for all simulations\n\n        Returns:\n            :class:`pd.DataFrame`\n        \"\"\"\n        data = list()\n        for uid in self.all_uids:\n            h5file_for_uid = os.path.join(self.path, uid, f\"{uid}.h5\")\n            with open_h5file(h5file_for_uid, \"r\") as file:\n                try:\n                    tmp_dict = dict()\n                    tmp_dict = {\n                        key: (\n                            len(file[f\"data/{key}\"]),\n                            file[f\"data/{key}/0\"].shape,\n                            file[f\"data/{key}/0\"].dtype,\n                        )\n                        for key in file[\"data\"].keys()\n                    }\n                except KeyError:\n                    tmp_dict = dict()\n                data.append(tmp_dict)\n        return pd.DataFrame.from_records(data)\n\n    def sim(\n        self,\n        uid: str,\n        return_writer: bool = False,\n        writer_type: SimulationWriter = SimulationWriter,\n    ) -> Simulation:\n        \"\"\"Get an existing simulation with uid. Same as accessing with `db[uid]` directly.\n\n        Args:\n            uid (`str`): unique identifier\n            return_writer: if true, return `SimulationWriter`, otherwise\n                return `Simulation`\n            writer_type: Optionally, you can specify a custom writer type to return.\n\n        Returns:\n            :class:`~bamboost.simulation.Simulation`\n        \"\"\"\n        if return_writer:\n            return writer_type(uid, self.path, self.comm)\n        return Simulation(uid, self.path, self.comm, _db_id=self.UID)\n\n    def sims(\n        self,\n        select: pd.Series | pd.DataFrame | dict = None,\n        sort: str = None,\n        reverse: bool = False,\n        exclude: set = None,\n        return_writer: bool = False,\n    ) -> list[Simulation]:\n        \"\"\"Get all simulations in a list. Optionally, get all simulations matching the\n        given selection using pandas.\n\n        Args:\n            select: Selection of simulations. Can be one of the following.\n                - Pandas boolean series: A boolean series with the same length as the dataframe.\n                - Pandas DataFrame: A subset of the full dataframe.\n                - Dictionary: A dictionary with the parameters to select (see `find` for details).\n            sort (`str`): Optionally sort the list with this keyword\n            reverse (`bool`): swap sort direction\n            exclude (`list[str]`): sims to exclude\n            return_writer: if true, return `SimulationWriter`, otherwise\n                return `Simulation`\n\n        Returns:\n            A list of `:class:~bamboost.simulation.Simulation` objects\n\n        Examples:\n            >>> db.sims(select=db.df[\"status\"] == \"finished\", sort=\"time_stamp\")\n        \"\"\"\n        if select is None:\n            id_list = self.all_uids\n        elif isinstance(select, pd.DataFrame):\n            id_list = select[\"id\"].values\n        elif isinstance(select, pd.Series):\n            id_list = self.df[select][\"id\"].values\n        elif isinstance(select, dict):\n            id_list = self.find(select)[\"id\"].values\n        else:\n            raise ArgumentError('Invalid argument for argument \"select\"')\n\n        if exclude is not None:\n            exclude = list([exclude]) if isinstance(exclude, str) else exclude\n            id_list = [id for id in id_list if id not in exclude]\n\n        existing_sims = [self.sim(uid, return_writer) for uid in id_list]\n\n        if sort is None:\n            return existing_sims\n        else:\n            return sorted(\n                existing_sims, key=lambda s: s.parameters[sort], reverse=reverse\n            )\n\n    def create_simulation(\n        self,\n        uid: str = None,\n        parameters: dict = None,\n        skip_duplicate_check: bool = False,\n        *,\n        prefix: str = None,\n        duplicate_action: str = \"prompt\",\n        note: str = None,\n        files: list[str] = None,\n        links: dict[str, str] = None,\n    ) -> SimulationWriter:\n        \"\"\"Get a writer object for a new simulation. This is written for paralell use\n        as it is likely that this may be used in an executable, creating multiple runs\n        for a parametric space, which may be run in paralell.\n\n        Note:\n            The files and links are copied to the simulation directory. The files are\n            copied with the same name as the original file. The links are copied with\n            the given name.\n\n        Args:\n            uid (`str`): The name/uid for the simulation. If not specified, a random id\n                will be assigned.\n            parameters (`dict`): Parameter dictionary. If provided, the parameters will be\n                checked against the existing sims for duplication. Otherwise, they may be\n                specified later with `bamboost.simulation_writer.SimulationWriter.add_parameters`.\n\n                Note:\n                    The parameters are stored in the h5 file as attributes.\n                    - If the value is a dict, it is flattened using\n                      `bamboost.common.utilities.flatten_dict`.\n                    - If the value is a list/array, it is stored as a dataset.\n\n            skip_duplicate_check (`bool`): if True, the duplicate check is skipped.\n            prefix (`str`): Prefix for the uid. If not specified, no prefix is used.\n            duplicate_action (`str`): how to deal with duplicates. Replace\n                first duplicate ('r'), Create with altered uid (`c`), Create new\n                with new id (`n`), Abort (`a`) default \"prompt\" for each\n                duplicate on a case by case basis.\n            note (`str`): Note for the simulation.\n            files (`list`): List of files to copy to the simulation directory.\n            links (`dict`): Dictionary of links to other simulations.\n\n        Examples:\n            >>> db.create_simulation(parameters={\"a\": 1, \"b\": 2})\n\n            >>> db.create_simulation(uid=\"my_sim\", parameters={\"a\": 1, \"b\": 2}, prefix=\"test\")\n\n        Returns:\n            A simulation writer object.\n        \"\"\"\n        if parameters and not skip_duplicate_check:\n            go_on = True\n            if self.comm.rank == 0:\n                go_on, uid = self._check_duplicate(\n                    parameters, uid, duplicate_action=duplicate_action\n                )\n            self.comm.bcast((go_on, uid), root=0)\n            if not go_on:\n                print(\"Aborting by user desire...\")\n                return None\n\n        if self.comm.rank == 0:\n            if not uid:\n                uid = uuid.uuid4().hex[:8]  # Assign random unique identifier\n            if isinstance(prefix, str) and prefix != \"\":\n                uid = \"_\".join([prefix, uid])\n        uid = self.comm.bcast(uid, root=0)\n\n        try:\n            # Create directory and h5 file\n            if self.comm.rank == 0:\n                os.makedirs(os.path.join(self.path, uid), exist_ok=True)\n                path_to_h5_file = os.path.join(self.path, uid, f\"{uid}.h5\")\n                if os.path.exists(path_to_h5_file):\n                    os.remove(path_to_h5_file)\n                h5py.File(path_to_h5_file, \"a\").close()  # create file\n\n            new_sim = SimulationWriter(uid, self.path, self.comm)\n            new_sim.initialize()  # sets metadata and status\n            # add the id to the (fixed) _all_uids list\n            if hasattr(self, \"_all_uids\"):\n                self._all_uids.append(new_sim.uid)\n\n            # Add parameters, note, files, and links\n            if not any([parameters, note, files, links]):\n                return new_sim\n\n            with new_sim._file(\"r+\"):\n                if parameters:\n                    new_sim.add_parameters(parameters)\n                if note:\n                    new_sim.change_note(note)\n                if files:\n                    new_sim.copy_file(files)\n                if links:\n                    [\n                        new_sim.links.__setitem__(name, uid)\n                        for name, uid in links.items()\n                    ]\n\n            return new_sim\n\n        except Exception as e:\n            # If any error occurs, remove the partially created simulation\n            if self.comm.rank == 0:\n                self.remove(uid)\n            raise e  # Re-raise the exception after cleanup\n\n    def remove(self, uid: str) -> None:\n        \"\"\"CAUTION, DELETING DATA. Remove the data of a simulation.\n\n        Args:\n            uid (`str`): uid\n        \"\"\"\n        shutil.rmtree(os.path.join(self.path, uid))\n        self._table.sync()\n\n    def find(self, parameter_selection: dict[str, Any]) -> pd.DataFrame:\n        \"\"\"Find simulations with the given parameters.\n\n        The dictionary can contain callables to filter inequalities or other\n        filters.\n\n        Examples:\n            >>> db.find({\"a\": 1, \"b\": lambda x: x > 2})\n            >>> db.find({\"a\": 1, \"b\": 2})\n\n        Args:\n            parameter_selection (dict): parameter selection dictionary\n        \"\"\"\n        parameter_selection = flatten_dict(parameter_selection)\n        params = {}\n        filters = {}\n        for key, val in parameter_selection.items():\n            if callable(val):\n                filters[key] = val\n            else:\n                params[key] = val\n\n        df = self.df\n        matches = self._list_duplicates(params, df=df)\n        matches = df[df.id.isin(matches)]\n        if len(matches) == 0:\n            return matches\n\n        for key, func in filters.items():\n            matches = matches[matches[key].apply(func)]\n\n        return matches\n\n    def _list_duplicates(\n        self, parameters: dict, *, df: pd.DataFrame = None\n    ) -> list[str]:\n        \"\"\"List ids of duplicates of the given parameters.\n\n        Args:\n            parameters (dict): parameter dictionary\n            df (pd.DataFrame): dataframe to search in. If not provided, the\n                dataframe from the sql database is used.\n        \"\"\"\n        if df is None:\n            df: pd.DataFrame = self._table.read_table()\n        params = flatten_dict(parameters)\n\n        class ComparableIterable:\n            def __init__(self, ori):\n                self.ori = np.asarray(ori)\n\n            def __eq__(self, other):\n                other = np.asarray(other)\n                if other.shape != self.ori.shape:\n                    return False\n                return (other == self.ori).all()\n\n        # make all iterables comparable by converting them to ComparableIterable\n        for k in params.keys():\n            if isinstance(params[k], Iterable) and not isinstance(params[k], str):\n                params[k] = ComparableIterable(params[k])\n\n        # if any of the parameters is not in the dataframe, no duplicates\n        for p in params:\n            if p not in df.keys():\n                return []\n\n        # get matching rows where all values of the series are equal to the corresponding values in the dataframe\n        s = pd.Series(params)\n        match = df.loc[(df[s.keys()].apply(lambda row: (s == row).all(), axis=1))]\n        return match.id.tolist()\n\n    def _check_duplicate(\n        self, parameters: dict, uid: str, duplicate_action: str = \"prompt\"\n    ) -> tuple:\n        \"\"\"Checking whether the parameters dictionary exists already.\n        May need to be improved...\n\n        Args:\n            parameters (`dict`): parameter dictionary to check for\n            uid (`str`): uid\n        Returns:\n            Tuple(Bool, uid) wheter to continue and with what uid.\n        \"\"\"\n\n        duplicates = self._list_duplicates(parameters)\n\n        if not duplicates:\n            return True, uid\n\n        print(\n            \"The parameter space already exists. Here are the duplicates:\",\n            flush=True,\n        )\n        print(self.df[self.df[\"id\"].isin([i for i in duplicates])], flush=True)\n\n        if duplicate_action == \"prompt\":\n            # What should be done?\n            prompt = input(\n                \"Replace first duplicate ('r'), Create with altered uid (`c`), \"\n                + \"Create new with new id (`n`), Abort (`a`): \"\n            )\n        else:\n            prompt = duplicate_action\n\n        if prompt == \"r\":\n            self.remove(duplicates[0])\n            return True, uid\n        if prompt == \"a\":\n            return False, uid\n        if prompt == \"n\":\n            return True, uid\n        if prompt == \"c\":\n            return True, self._generate_subuid(duplicates[0].split(\".\")[0])\n\n        raise ArgumentError(\"Answer not valid! Aborting\")\n\n    def _generate_subuid(self, uid_base: str) -> str:\n        \"\"\"Return a new sub uid for the base uid.\n        Following the following format: `base_uid.1`\n\n        Args:\n            uid_base (`str`): base uid for which to find the next subid.\n        Returns:\n            New uid string\n        \"\"\"\n        uid_list = [uid for uid in self.all_uids if uid.startswith(uid_base)]\n        subiterator = max(\n            [int(id.split(\".\")[1]) for id in uid_list if len(id.split(\".\")) > 1] + [0]\n        )\n        return f\"{uid_base}.{subiterator+1}\"\n\n    def global_fields_in_all(self) -> list:\n        \"\"\"Get a list of all global fields in all simulations.\n\n        Returns:\n            List of global fields\n        \"\"\"\n        fields = set()\n        for sim in self:\n            try:\n                fields.update(sim.globals.columns)\n            except KeyError:\n                continue\n\n        return fields\n\n    def get_parameters(self) -> dict:\n        \"\"\"Get the parameters used in this database.\n\n        Returns:\n            Dictionary of parameters with it's count, range, and type. Sorted by count.\n        \"\"\"\n        parameters = dict()\n        for sim in self:\n            for key, val in sim.parameters.items():\n                if key not in parameters:\n                    range = (val, val) if isinstance(val, numbers.Number) else None\n                    parameters[key] = {\"range\": range, \"count\": 1, \"type\": type(val)}\n                else:\n                    if isinstance(val, numbers.Number):\n                        parameters[key][\"range\"] = (\n                            min(parameters[key][\"range\"][0], val),\n                            max(parameters[key][\"range\"][1], val),\n                        )\n                    parameters[key][\"count\"] += 1\n                    parameters[key][\"type\"] = type(val)\n        return dict(\n            sorted(parameters.items(), key=lambda x: x[1][\"count\"], reverse=True)\n        )",
          "inherited_members": {}
        }
      },
      "functions": {}
    },
    "index": {
      "name": "index",
      "path": "bamboost.index",
      "filepath": "/home/florez/work/code/bamboost/bamboost/index.py",
      "description": "Module to manage the database index and its ID's.",
      "docstring": [],
      "attributes": [
        {
          "name": "__all__",
          "annotation": null,
          "description": null,
          "value": "['Null', 'IndexAPI', 'DatabaseTable', 'Entry', 'find', 'get_uid_from_path', 'get_known_paths', 'uid2', 'DatabaseNotFoundError', 'THREAD_SAFE', 'CONVERT_ARRAYS', 'PREFIX', 'DOT_REPLACEMENT']"
        },
        {
          "name": "log",
          "annotation": null,
          "description": null,
          "value": "BAMBOOST_LOGGER.getChild(__name__.split('.')[-1])"
        },
        {
          "name": "PREFIX",
          "annotation": null,
          "description": null,
          "value": "'.BAMBOOST-'"
        },
        {
          "name": "DOT_REPLACEMENT",
          "annotation": null,
          "description": null,
          "value": "'DOT'"
        },
        {
          "name": "_comm",
          "annotation": null,
          "description": null,
          "value": "MPI.COMM_WORLD"
        },
        {
          "name": "THREAD_SAFE",
          "annotation": null,
          "description": "if True, the index is thread safe",
          "value": "False"
        },
        {
          "name": "CONVERT_ARRAYS",
          "annotation": null,
          "description": "if True, convert numpy arrays to lists",
          "value": "True"
        },
        {
          "name": "Error",
          "annotation": null,
          "description": null,
          "value": "sql.sqlite3.Error"
        }
      ],
      "modules": {},
      "classes": {
        "DatabaseNotFoundError": {
          "name": "DatabaseNotFoundError",
          "path": "bamboost.index.DatabaseNotFoundError",
          "description": "Exception raised when a database is not found in the index.",
          "parameters": [],
          "attributes": [],
          "docstring": [],
          "functions": {},
          "source": "class DatabaseNotFoundError(Exception):\n    \"\"\"Exception raised when a database is not found in the index.\"\"\"\n\n    pass",
          "inherited_members": {}
        },
        "Null": {
          "name": "Null",
          "path": "bamboost.index.Null",
          "description": "Null object to replace API classes for off-root processes.",
          "parameters": [],
          "attributes": [],
          "docstring": [],
          "functions": {
            "__getattr__": {
              "name": "__getattr__",
              "path": "bamboost.index.Null.__getattr__",
              "signature": "(self, _)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "_",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def __getattr__(self, _):\n    return self"
            },
            "__bool__": {
              "name": "__bool__",
              "path": "bamboost.index.Null.__bool__",
              "signature": "(self)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def __bool__(self):\n    # Allows the instance to behave like `None` in boolean contexts\n    return False"
            },
            "__call__": {
              "name": "__call__",
              "path": "bamboost.index.Null.__call__",
              "signature": "(self, *args, **kwargs)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "args",
                  "annotation": null,
                  "description": null,
                  "value": "()"
                },
                {
                  "name": "kwargs",
                  "annotation": null,
                  "description": null,
                  "value": "{}"
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def __call__(self, *args, **kwargs):\n    # Allows the instance to be called like a function\n    return self"
            },
            "__getitem__": {
              "name": "__getitem__",
              "path": "bamboost.index.Null.__getitem__",
              "signature": "(self, _)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "_",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def __getitem__(self, _):\n    return self"
            },
            "__enter__": {
              "name": "__enter__",
              "path": "bamboost.index.Null.__enter__",
              "signature": "(self, *args, **kwargs)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "args",
                  "annotation": null,
                  "description": null,
                  "value": "()"
                },
                {
                  "name": "kwargs",
                  "annotation": null,
                  "description": null,
                  "value": "{}"
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def __enter__(self, *args, **kwargs):\n    return self"
            },
            "__exit__": {
              "name": "__exit__",
              "path": "bamboost.index.Null.__exit__",
              "signature": "(self, *args, **kwargs)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "args",
                  "annotation": null,
                  "description": null,
                  "value": "()"
                },
                {
                  "name": "kwargs",
                  "annotation": null,
                  "description": null,
                  "value": "{}"
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def __exit__(self, *args, **kwargs):\n    return False"
            }
          },
          "source": "class Null:\n    \"\"\"Null object to replace API classes for off-root processes.\"\"\"\n\n    def __getattr__(self, _):\n        return self\n\n    def __bool__(self):\n        # Allows the instance to behave like `None` in boolean contexts\n        return False\n\n    def __call__(self, *args, **kwargs):\n        # Allows the instance to be called like a function\n        return self\n\n    def __getitem__(self, _):\n        return self\n\n    def __enter__(self, *args, **kwargs):\n        return self\n\n    def __exit__(self, *args, **kwargs):\n        return False",
          "inherited_members": {}
        },
        "IndexAPI": {
          "name": "IndexAPI",
          "path": "bamboost.index.IndexAPI",
          "description": "SQLite database to store database ID, path lookup. As well as the table for\neach database. Location: `~/.local/share/bamboost/bamboost.db`.\nSingleton pattern.",
          "parameters": [
            {
              "name": "self",
              "annotation": null,
              "description": null,
              "value": null
            },
            {
              "name": "_file",
              "annotation": "str",
              "description": [
                {
                  "kind": "text",
                  "value": "path to the database file"
                }
              ],
              "value": "None"
            },
            {
              "name": "convert_arrays",
              "annotation": "bool",
              "description": [
                {
                  "kind": "text",
                  "value": "Defaults to True. If False, when reading from the database,\nlists with tag ARRAY are not converted back to numpy arrays but\nremain a standard list."
                }
              ],
              "value": "None"
            }
          ],
          "attributes": [
            {
              "name": "_instances",
              "annotation": null,
              "description": null,
              "value": "{}"
            },
            {
              "name": "_initialized",
              "annotation": null,
              "description": null,
              "value": "True"
            }
          ],
          "docstring": [],
          "functions": {
            "__new__": {
              "name": "__new__",
              "path": "bamboost.index.IndexAPI.__new__",
              "signature": "(cls, *, _file = None, **kwargs) -> bamboost.index.IndexAPI",
              "description": null,
              "parameters": [
                {
                  "name": "cls",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "_file",
                  "annotation": "str",
                  "description": null,
                  "value": "None"
                },
                {
                  "name": "kwargs",
                  "annotation": null,
                  "description": null,
                  "value": "{}"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "bamboost.index.IndexAPI",
                "description": null
              },
              "docstring": [],
              "source": "def __new__(cls, *, _file: str = None, **kwargs) -> IndexAPI:\n    if THREAD_SAFE:\n        return super().__new__(cls)\n\n    if _comm.rank != 0:\n        return Null()\n\n    _file = _file or paths[\"DATABASE_FILE\"]\n    if _file not in cls._instances:\n        cls._instances[_file] = super().__new__(cls)\n    return cls._instances[_file]"
            },
            "__init__": {
              "name": "__init__",
              "path": "bamboost.index.IndexAPI.__init__",
              "signature": "(self, *, _file = None, convert_arrays = None)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "_file",
                  "annotation": "str",
                  "description": null,
                  "value": "None"
                },
                {
                  "name": "convert_arrays",
                  "annotation": "bool",
                  "description": null,
                  "value": "None"
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def __init__(self, *, _file: str = None, convert_arrays: bool = None):\n    convert_arrays = (\n        convert_arrays if convert_arrays is not None else CONVERT_ARRAYS\n    )\n    if hasattr(self, \"_initialized\"):\n        return\n    _file = _file or paths[\"DATABASE_FILE\"]\n    super().__init__(file=_file, convert_arrays=convert_arrays)\n    self.create_index_table()\n    self.clean()\n    self._initialized = True"
            },
            "ThreadSafe": {
              "name": "ThreadSafe",
              "path": "bamboost.index.IndexAPI.ThreadSafe",
              "signature": "(cls, *args, **kwargs) -> bamboost.index.IndexAPI",
              "description": null,
              "parameters": [
                {
                  "name": "cls",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "args",
                  "annotation": null,
                  "description": null,
                  "value": "()"
                },
                {
                  "name": "kwargs",
                  "annotation": null,
                  "description": null,
                  "value": "{}"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "bamboost.index.IndexAPI",
                "description": null
              },
              "docstring": [],
              "source": "@classmethod\ndef ThreadSafe(cls, *args, **kwargs) -> IndexAPI:\n    instance = super().__new__(cls)\n    instance.__init__(*args, **kwargs)\n    return instance"
            },
            "__repr__": {
              "name": "__repr__",
              "path": "bamboost.index.IndexAPI.__repr__",
              "signature": "(self) -> str",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "str",
                "description": null
              },
              "docstring": [],
              "source": "def __repr__(self) -> str:\n    return self.read_table().__repr__()"
            },
            "_repr_html_": {
              "name": "_repr_html_",
              "path": "bamboost.index.IndexAPI._repr_html_",
              "signature": "(self) -> str",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "str",
                "description": null
              },
              "docstring": [],
              "source": "def _repr_html_(self) -> str:\n    return self.read_table()._repr_html_()"
            },
            "__getitem__": {
              "name": "__getitem__",
              "path": "bamboost.index.IndexAPI.__getitem__",
              "signature": "(self, id) -> bamboost.index.DatabaseTable",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "id",
                  "annotation": "str",
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "bamboost.index.DatabaseTable",
                "description": null
              },
              "docstring": [],
              "source": "def __getitem__(self, id: str) -> DatabaseTable:\n    return DatabaseTable(id, _index=self)"
            },
            "_ipython_key_completions_": {
              "name": "_ipython_key_completions_",
              "path": "bamboost.index.IndexAPI._ipython_key_completions_",
              "signature": "(self) -> list",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "list",
                "description": null
              },
              "docstring": [],
              "source": "def _ipython_key_completions_(self) -> list:\n    return self.read_table().id.tolist()"
            },
            "create_index_table": {
              "name": "create_index_table",
              "path": "bamboost.index.IndexAPI.create_index_table",
              "signature": "(self) -> None",
              "description": "Create the index table if it does not exist.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "@sql.with_connection\ndef create_index_table(self) -> None:\n    \"\"\"Create the index table if it does not exist.\"\"\"\n    self._cursor.execute(\n        \"\"\"CREATE TABLE IF NOT EXISTS dbindex (id TEXT PRIMARY KEY, path TEXT)\"\"\"\n    )"
            },
            "get_database_table": {
              "name": "get_database_table",
              "path": "bamboost.index.IndexAPI.get_database_table",
              "signature": "(self, id) -> bamboost.index.DatabaseTable",
              "description": "Get the table of a database.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "id",
                  "annotation": "str",
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "bamboost.index.DatabaseTable",
                "description": null
              },
              "docstring": [],
              "source": "def get_database_table(self, id: str) -> DatabaseTable:\n    \"\"\"Get the table of a database.\n\n    Args:\n        - id (str): ID of the database\n    \"\"\"\n    return DatabaseTable(id, _index=self)"
            },
            "read_table": {
              "name": "read_table",
              "path": "bamboost.index.IndexAPI.read_table",
              "signature": "(self, *args, **kwargs) -> pandas.DataFrame",
              "description": "Read the index table.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "args",
                  "annotation": null,
                  "description": null,
                  "value": "()"
                },
                {
                  "name": "kwargs",
                  "annotation": null,
                  "description": null,
                  "value": "{}"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "pandas.DataFrame",
                "description": "pd.DataFrame: index table"
              },
              "docstring": [],
              "source": "@sql.with_connection\ndef read_table(self, *args, **kwargs) -> pd.DataFrame:\n    \"\"\"Read the index table.\n\n    Returns:\n        pd.DataFrame: index table\n    \"\"\"\n    return pd.read_sql_query(\"SELECT * FROM dbindex\", self._conn, *args, **kwargs)"
            },
            "fetch": {
              "name": "fetch",
              "path": "bamboost.index.IndexAPI.fetch",
              "signature": "(self, query, *args, **kwargs) -> pandas.DataFrame",
              "description": "Query the index table.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "query",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "query string"
                    }
                  ]
                },
                {
                  "name": "args",
                  "annotation": null,
                  "description": null,
                  "value": "()"
                },
                {
                  "name": "kwargs",
                  "annotation": null,
                  "description": null,
                  "value": "{}"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "pandas.DataFrame",
                "description": null
              },
              "docstring": [],
              "source": "@sql.with_connection\ndef fetch(self, query: str, *args, **kwargs) -> pd.DataFrame:\n    \"\"\"Query the index table.\n\n    Args:\n        query (str): query string\n    \"\"\"\n    self._cursor.execute(query, *args, **kwargs)\n    return self._cursor.fetchall()"
            },
            "get_path": {
              "name": "get_path",
              "path": "bamboost.index.IndexAPI.get_path",
              "signature": "(self, id) -> str",
              "description": "Get the path of a database from its ID.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "id",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "ID of the database"
                    }
                  ]
                }
              ],
              "returns": {
                "name": "str",
                "annotation": "str",
                "description": "path of the database"
              },
              "docstring": [],
              "source": "@sql.with_connection\ndef get_path(self, id: str) -> str:\n    \"\"\"Get the path of a database from its ID.\n\n    Args:\n        id (str): ID of the database\n\n    Returns:\n        str: path of the database\n    \"\"\"\n    self._cursor.execute(\"SELECT path FROM dbindex WHERE id=?\", (id,))\n    path_db = self._cursor.fetchone()\n    if path_db and _check_path(id, path_db[0]):\n        return path_db[0]\n\n    # if path is wrong, try to find it\n    for root_dir in get_known_paths():\n        res = find(id, root_dir)\n        if res:\n            path = os.path.dirname(res[0])\n            self.insert_path(id, path)\n            return path\n\n    # last resort, check home\n    res = find(id, paths[\"HOME\"])\n    if res:\n        path = os.path.dirname(res[0])\n        self.insert_path(id, path)\n        return path\n\n    raise FileNotFoundError(f\"Database {id} not found on system.\")"
            },
            "insert_path": {
              "name": "insert_path",
              "path": "bamboost.index.IndexAPI.insert_path",
              "signature": "(self, id, path) -> None",
              "description": "Insert a database path into the index.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "id",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "ID of the database"
                    }
                  ]
                },
                {
                  "name": "path",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "path of the database"
                    }
                  ]
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "@sql.with_connection\ndef insert_path(self, id: str, path: str) -> None:\n    \"\"\"Insert a database path into the index.\n\n    Args:\n        id (str): ID of the database\n        path (str): path of the database\n    \"\"\"\n    path = os.path.abspath(path)\n    self._cursor.execute(\"INSERT OR REPLACE INTO dbindex VALUES (?, ?)\", (id, path))"
            },
            "get_id": {
              "name": "get_id",
              "path": "bamboost.index.IndexAPI.get_id",
              "signature": "(self, path) -> str",
              "description": "Get the ID of a database from its path.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "path",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "path of the database"
                    }
                  ]
                }
              ],
              "returns": {
                "name": "str",
                "annotation": "str",
                "description": "ID of the database"
              },
              "docstring": [
                {
                  "kind": "raises",
                  "value": [
                    {
                      "annotation": "DatabaseNotFoundError",
                      "description": "if the database is not found in the index"
                    }
                  ]
                }
              ],
              "source": "@sql.with_connection\ndef get_id(self, path: str) -> str:\n    \"\"\"Get the ID of a database from its path.\n\n    Args:\n        path (str): path of the database\n\n    Returns:\n        str: ID of the database\n\n    Raises:\n        DatabaseNotFoundError: if the database is not found in the index\n    \"\"\"\n    path = os.path.abspath(path)\n    self._cursor.execute(\"SELECT id FROM dbindex WHERE path=?\", (path,))\n    fetched = self._cursor.fetchone()\n    if fetched is None:\n        raise DatabaseNotFoundError(f\"Database at {path} not found in index.\")\n    return fetched[0]"
            },
            "scan_known_paths": {
              "name": "scan_known_paths",
              "path": "bamboost.index.IndexAPI.scan_known_paths",
              "signature": "(self) -> dict",
              "description": "Scan known paths for databases and update the index.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "dict",
                "description": null
              },
              "docstring": [],
              "source": "@sql.with_connection\ndef scan_known_paths(self) -> dict:\n    \"\"\"Scan known paths for databases and update the index.\"\"\"\n    for path in get_known_paths():\n        completed_process = subprocess.run(\n            [\"find\", path, \"-iname\", f\"{PREFIX}*\", \"-not\", \"-path\", r\"*/\\.git/*\"],\n            capture_output=True,\n        )\n        databases_found = completed_process.stdout.decode(\"utf-8\").splitlines()\n        for database in databases_found:\n            name = os.path.basename(database)\n            id = name.split(\"-\")[1]\n            self.insert_path(id, os.path.dirname(database))"
            },
            "commit_once": {
              "name": "commit_once",
              "path": "bamboost.index.IndexAPI.commit_once",
              "signature": "(self, func) -> typing.Callable",
              "description": "Decorator to bundle changes to a single commit.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "func",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "typing.Callable",
                "description": null
              },
              "docstring": [
                {
                  "kind": "admonition",
                  "value": {
                    "annotation": "example",
                    "description": ">>> @Index.commit_once\n>>> def create_a_bunch_of_simulations():\n>>>     for i in range(1000):\n>>>         db.create_simulation(parameters={...})\n>>>\n>>> create_a_bunch_of_simulations()"
                  },
                  "title": "Example"
                }
              ],
              "source": "def commit_once(self, func) -> Callable:\n    \"\"\"Decorator to bundle changes to a single commit.\n\n    Example:\n        >>> @Index.commit_once\n        >>> def create_a_bunch_of_simulations():\n        >>>     for i in range(1000):\n        >>>         db.create_simulation(parameters={...})\n        >>>\n        >>> create_a_bunch_of_simulations()\n    \"\"\"\n\n    def wrapper(*args, **kwargs):\n        with self.open(ensure_commit=True):\n            return func(*args, **kwargs)\n\n    return wrapper"
            },
            "clean": {
              "name": "clean",
              "path": "bamboost.index.IndexAPI.clean",
              "signature": "(self, purge = False) -> bamboost.index.IndexAPI",
              "description": "Clean the index from wrong paths.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "purge",
                  "annotation": "bool",
                  "description": [
                    {
                      "kind": "text",
                      "value": "Also deletes the table of unmatching uid/path pairs. Defaults to False."
                    }
                  ],
                  "value": "False"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "bamboost.index.IndexAPI",
                "description": null
              },
              "docstring": [],
              "source": "@sql.with_connection\ndef clean(self, purge: bool = False) -> IndexAPI:\n    \"\"\"Clean the index from wrong paths.\n\n    Args:\n        purge (bool, optional): Also deletes the table of unmatching uid/path pairs. Defaults to False.\n    \"\"\"\n    index = self._cursor.execute(\"SELECT id, path FROM dbindex\").fetchall()\n    for id, path in index:\n        if not _check_path(id, path):\n            self._cursor.execute(\"DELETE FROM dbindex WHERE id=?\", (id,))\n\n    if purge:\n        # all tables starting with db_ are tables of databases\n        all_tables = self._cursor.execute(\n            \"SELECT name FROM sqlite_master WHERE type='table'\"\n        ).fetchall()\n        id_list_tables = {\n            i[0].split(\"_\")[1] for i in all_tables if i[0].startswith(\"db_\")\n        }\n        id_list = self._cursor.execute(\"SELECT id FROM dbindex\").fetchall()\n\n        for id in id_list_tables:\n            if id not in id_list:\n                self._cursor.execute(f\"DROP TABLE db_{id}\")\n                self._cursor.execute(f\"DROP TABLE db_{id}_t\")\n\n    return self"
            },
            "drop_path": {
              "name": "drop_path",
              "path": "bamboost.index.IndexAPI.drop_path",
              "signature": "(self, id) -> None",
              "description": "Drop a path from the index.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "id",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "ID of the database"
                    }
                  ]
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "@sql.with_connection\ndef drop_path(self, id: str) -> None:\n    \"\"\"Drop a path from the index.\n\n    Args:\n        id (str): ID of the database\n    \"\"\"\n    self._cursor.execute(\"DELETE FROM dbindex WHERE id=?\", (id,))"
            },
            "check_path": {
              "name": "check_path",
              "path": "bamboost.index.IndexAPI.check_path",
              "signature": "(self, id, path) -> bool",
              "description": "Check if path is going to the correct database.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "id",
                  "annotation": "str",
                  "description": null,
                  "value": null
                },
                {
                  "name": "path",
                  "annotation": "str",
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "bool",
                "description": null
              },
              "docstring": [],
              "source": "def check_path(self, id: str, path: str) -> bool:\n    \"\"\"Check if path is going to the correct database.\"\"\"\n    return _check_path(id, path)"
            }
          },
          "source": "class IndexAPI(sql.SQLiteHandler):\n    \"\"\"SQLite database to store database ID, path lookup. As well as the table for\n    each database. Location: `~/.local/share/bamboost/bamboost.db`.\n    Singleton pattern.\n\n    Args:\n        _file: path to the database file\n        convert_arrays: Defaults to True. If False, when reading from the database,\n            lists with tag ARRAY are not converted back to numpy arrays but\n            remain a standard list.\n    \"\"\"\n\n    _instances = {}\n\n    def __new__(cls, *, _file: str = None, **kwargs) -> IndexAPI:\n        if THREAD_SAFE:\n            return super().__new__(cls)\n\n        if _comm.rank != 0:\n            return Null()\n\n        _file = _file or paths[\"DATABASE_FILE\"]\n        if _file not in cls._instances:\n            cls._instances[_file] = super().__new__(cls)\n        return cls._instances[_file]\n\n    def __init__(self, *, _file: str = None, convert_arrays: bool = None):\n        convert_arrays = (\n            convert_arrays if convert_arrays is not None else CONVERT_ARRAYS\n        )\n        if hasattr(self, \"_initialized\"):\n            return\n        _file = _file or paths[\"DATABASE_FILE\"]\n        super().__init__(file=_file, convert_arrays=convert_arrays)\n        self.create_index_table()\n        self.clean()\n        self._initialized = True\n\n    @classmethod\n    def ThreadSafe(cls, *args, **kwargs) -> IndexAPI:\n        instance = super().__new__(cls)\n        instance.__init__(*args, **kwargs)\n        return instance\n\n    def __repr__(self) -> str:\n        return self.read_table().__repr__()\n\n    def _repr_html_(self) -> str:\n        return self.read_table()._repr_html_()\n\n    def __getitem__(self, id: str) -> DatabaseTable:\n        return DatabaseTable(id, _index=self)\n\n    def _ipython_key_completions_(self) -> list:\n        return self.read_table().id.tolist()\n\n    @sql.with_connection\n    def create_index_table(self) -> None:\n        \"\"\"Create the index table if it does not exist.\"\"\"\n        self._cursor.execute(\n            \"\"\"CREATE TABLE IF NOT EXISTS dbindex (id TEXT PRIMARY KEY, path TEXT)\"\"\"\n        )\n\n    def get_database_table(self, id: str) -> DatabaseTable:\n        \"\"\"Get the table of a database.\n\n        Args:\n            - id (str): ID of the database\n        \"\"\"\n        return DatabaseTable(id, _index=self)\n\n    @sql.with_connection\n    def read_table(self, *args, **kwargs) -> pd.DataFrame:\n        \"\"\"Read the index table.\n\n        Returns:\n            pd.DataFrame: index table\n        \"\"\"\n        return pd.read_sql_query(\"SELECT * FROM dbindex\", self._conn, *args, **kwargs)\n\n    @sql.with_connection\n    def fetch(self, query: str, *args, **kwargs) -> pd.DataFrame:\n        \"\"\"Query the index table.\n\n        Args:\n            query (str): query string\n        \"\"\"\n        self._cursor.execute(query, *args, **kwargs)\n        return self._cursor.fetchall()\n\n    @sql.with_connection\n    def get_path(self, id: str) -> str:\n        \"\"\"Get the path of a database from its ID.\n\n        Args:\n            id (str): ID of the database\n\n        Returns:\n            str: path of the database\n        \"\"\"\n        self._cursor.execute(\"SELECT path FROM dbindex WHERE id=?\", (id,))\n        path_db = self._cursor.fetchone()\n        if path_db and _check_path(id, path_db[0]):\n            return path_db[0]\n\n        # if path is wrong, try to find it\n        for root_dir in get_known_paths():\n            res = find(id, root_dir)\n            if res:\n                path = os.path.dirname(res[0])\n                self.insert_path(id, path)\n                return path\n\n        # last resort, check home\n        res = find(id, paths[\"HOME\"])\n        if res:\n            path = os.path.dirname(res[0])\n            self.insert_path(id, path)\n            return path\n\n        raise FileNotFoundError(f\"Database {id} not found on system.\")\n\n    @sql.with_connection\n    def insert_path(self, id: str, path: str) -> None:\n        \"\"\"Insert a database path into the index.\n\n        Args:\n            id (str): ID of the database\n            path (str): path of the database\n        \"\"\"\n        path = os.path.abspath(path)\n        self._cursor.execute(\"INSERT OR REPLACE INTO dbindex VALUES (?, ?)\", (id, path))\n\n    @sql.with_connection\n    def get_id(self, path: str) -> str:\n        \"\"\"Get the ID of a database from its path.\n\n        Args:\n            path (str): path of the database\n\n        Returns:\n            str: ID of the database\n\n        Raises:\n            DatabaseNotFoundError: if the database is not found in the index\n        \"\"\"\n        path = os.path.abspath(path)\n        self._cursor.execute(\"SELECT id FROM dbindex WHERE path=?\", (path,))\n        fetched = self._cursor.fetchone()\n        if fetched is None:\n            raise DatabaseNotFoundError(f\"Database at {path} not found in index.\")\n        return fetched[0]\n\n    @sql.with_connection\n    def scan_known_paths(self) -> dict:\n        \"\"\"Scan known paths for databases and update the index.\"\"\"\n        for path in get_known_paths():\n            completed_process = subprocess.run(\n                [\"find\", path, \"-iname\", f\"{PREFIX}*\", \"-not\", \"-path\", r\"*/\\.git/*\"],\n                capture_output=True,\n            )\n            databases_found = completed_process.stdout.decode(\"utf-8\").splitlines()\n            for database in databases_found:\n                name = os.path.basename(database)\n                id = name.split(\"-\")[1]\n                self.insert_path(id, os.path.dirname(database))\n\n    def commit_once(self, func) -> Callable:\n        \"\"\"Decorator to bundle changes to a single commit.\n\n        Example:\n            >>> @Index.commit_once\n            >>> def create_a_bunch_of_simulations():\n            >>>     for i in range(1000):\n            >>>         db.create_simulation(parameters={...})\n            >>>\n            >>> create_a_bunch_of_simulations()\n        \"\"\"\n\n        def wrapper(*args, **kwargs):\n            with self.open(ensure_commit=True):\n                return func(*args, **kwargs)\n\n        return wrapper\n\n    @sql.with_connection\n    def clean(self, purge: bool = False) -> IndexAPI:\n        \"\"\"Clean the index from wrong paths.\n\n        Args:\n            purge (bool, optional): Also deletes the table of unmatching uid/path pairs. Defaults to False.\n        \"\"\"\n        index = self._cursor.execute(\"SELECT id, path FROM dbindex\").fetchall()\n        for id, path in index:\n            if not _check_path(id, path):\n                self._cursor.execute(\"DELETE FROM dbindex WHERE id=?\", (id,))\n\n        if purge:\n            # all tables starting with db_ are tables of databases\n            all_tables = self._cursor.execute(\n                \"SELECT name FROM sqlite_master WHERE type='table'\"\n            ).fetchall()\n            id_list_tables = {\n                i[0].split(\"_\")[1] for i in all_tables if i[0].startswith(\"db_\")\n            }\n            id_list = self._cursor.execute(\"SELECT id FROM dbindex\").fetchall()\n\n            for id in id_list_tables:\n                if id not in id_list:\n                    self._cursor.execute(f\"DROP TABLE db_{id}\")\n                    self._cursor.execute(f\"DROP TABLE db_{id}_t\")\n\n        return self\n\n    @sql.with_connection\n    def drop_path(self, id: str) -> None:\n        \"\"\"Drop a path from the index.\n\n        Args:\n            id (str): ID of the database\n        \"\"\"\n        self._cursor.execute(\"DELETE FROM dbindex WHERE id=?\", (id,))\n\n    def check_path(self, id: str, path: str) -> bool:\n        \"\"\"Check if path is going to the correct database.\"\"\"\n        return _check_path(id, path)",
          "inherited_members": {
            "bamboost._sqlite_database.SQLiteHandler": [
              {
                "kind": "attribute",
                "path": "bamboost._sqlite_database.SQLiteHandler.file"
              },
              {
                "kind": "attribute",
                "path": "bamboost._sqlite_database.SQLiteHandler._conn"
              },
              {
                "kind": "attribute",
                "path": "bamboost._sqlite_database.SQLiteHandler._cursor"
              },
              {
                "kind": "attribute",
                "path": "bamboost._sqlite_database.SQLiteHandler._is_open"
              },
              {
                "kind": "attribute",
                "path": "bamboost._sqlite_database.SQLiteHandler._lock_stack"
              },
              {
                "kind": "function",
                "path": "bamboost._sqlite_database.SQLiteHandler.connect"
              },
              {
                "kind": "function",
                "path": "bamboost._sqlite_database.SQLiteHandler.close"
              },
              {
                "kind": "function",
                "path": "bamboost._sqlite_database.SQLiteHandler.commit"
              },
              {
                "kind": "function",
                "path": "bamboost._sqlite_database.SQLiteHandler.open"
              }
            ]
          }
        },
        "DatabaseTable": {
          "name": "DatabaseTable",
          "path": "bamboost.index.DatabaseTable",
          "description": "Class to manage the table of a database. Multiton pattern. One table per\ndatabase.",
          "parameters": [
            {
              "name": "self",
              "annotation": null,
              "description": null,
              "value": null
            },
            {
              "name": "id",
              "annotation": "str",
              "description": null,
              "value": null
            },
            {
              "name": "_index",
              "annotation": "IndexAPI",
              "description": null,
              "value": "None"
            }
          ],
          "attributes": [
            {
              "name": "_instances",
              "annotation": null,
              "description": null,
              "value": "{}"
            },
            {
              "name": "id",
              "annotation": null,
              "description": null,
              "value": "id"
            },
            {
              "name": "_entries",
              "annotation": null,
              "description": null,
              "value": "{}"
            },
            {
              "name": "_initialized",
              "annotation": null,
              "description": null,
              "value": "True"
            },
            {
              "name": "_index",
              "annotation": null,
              "description": null,
              "value": "_index if _index is not None else IndexAPI()"
            },
            {
              "name": "path",
              "annotation": null,
              "description": null,
              "value": "self._index.get_path(self.id)"
            },
            {
              "name": "tablename_db",
              "annotation": null,
              "description": null,
              "value": "f'db_{self.id}'"
            },
            {
              "name": "tablename_update_times",
              "annotation": null,
              "description": null,
              "value": "f'db_{self.id}_t'"
            }
          ],
          "docstring": [],
          "functions": {
            "__new__": {
              "name": "__new__",
              "path": "bamboost.index.DatabaseTable.__new__",
              "signature": "(cls, id, *args, **kwargs) -> bamboost.index.DatabaseTable",
              "description": null,
              "parameters": [
                {
                  "name": "cls",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "id",
                  "annotation": "str",
                  "description": null,
                  "value": null
                },
                {
                  "name": "args",
                  "annotation": null,
                  "description": null,
                  "value": "()"
                },
                {
                  "name": "kwargs",
                  "annotation": null,
                  "description": null,
                  "value": "{}"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "bamboost.index.DatabaseTable",
                "description": null
              },
              "docstring": [],
              "source": "def __new__(cls, id: str, *args, **kwargs) -> DatabaseTable:\n    if _comm.rank != 0:\n        return Null()\n\n    if id not in cls._instances:\n        cls._instances[id] = super().__new__(cls)\n    return cls._instances[id]"
            },
            "__init__": {
              "name": "__init__",
              "path": "bamboost.index.DatabaseTable.__init__",
              "signature": "(self, id, *, _index = None)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "id",
                  "annotation": "str",
                  "description": null,
                  "value": null
                },
                {
                  "name": "_index",
                  "annotation": "IndexAPI",
                  "description": null,
                  "value": "None"
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def __init__(self, id: str, *, _index: IndexAPI = None):\n    if hasattr(self, \"_initialized\"):\n        return\n\n    self.id = id\n    self._entries = {}\n    self._initialized = True\n    self._index = _index if _index is not None else IndexAPI()\n    self.path = self._index.get_path(self.id)\n    self.tablename_db = f\"db_{self.id}\"\n    self.tablename_update_times = f\"db_{self.id}_t\"\n    self.create_database_table()"
            },
            "__getattr__": {
              "name": "__getattr__",
              "path": "bamboost.index.DatabaseTable.__getattr__",
              "signature": "(self, name)",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "name",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def __getattr__(self, name):\n    if name in {\n        \"_conn\",\n        \"_cursor\",\n        \"open\",\n        \"close\",\n        \"commit\",\n        \"_is_open\",\n        \"commit_once\",\n    }:\n        return getattr(self._index, name)\n    return self.__getattribute__(name)"
            },
            "read_table": {
              "name": "read_table",
              "path": "bamboost.index.DatabaseTable.read_table",
              "signature": "(self) -> pandas.DataFrame",
              "description": "Read the table of the database.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "pandas.DataFrame",
                "description": "pd.DataFrame: table of the database"
              },
              "docstring": [],
              "source": "@sql.with_connection\ndef read_table(self) -> pd.DataFrame:\n    \"\"\"Read the table of the database.\n\n    Returns:\n        pd.DataFrame: table of the database\n    \"\"\"\n    df = pd.read_sql_query(f\"SELECT * FROM {self.tablename_db}\", self._conn)\n    # drop \"hidden\" columns which start with _\n    df = df.loc[:, ~df.columns.str.startswith(\"_\")]\n    df.rename(columns=lambda x: x.replace(DOT_REPLACEMENT, \".\"), inplace=True)\n    return df"
            },
            "read_entry": {
              "name": "read_entry",
              "path": "bamboost.index.DatabaseTable.read_entry",
              "signature": "(self, entry_id) -> pandas.Series",
              "description": "Read an entry from the database.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "entry_id",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "ID of the entry"
                    }
                  ]
                }
              ],
              "returns": {
                "name": "",
                "annotation": "pandas.Series",
                "description": "pd.Series: entry from the database"
              },
              "docstring": [],
              "source": "@sql.with_connection\ndef read_entry(self, entry_id: str) -> pd.Series:\n    \"\"\"Read an entry from the database.\n\n    Args:\n        entry_id (str): ID of the entry\n\n    Returns:\n        pd.Series: entry from the database\n    \"\"\"\n    self._cursor.execute(\n        f\"SELECT * FROM {self.tablename_db} WHERE id=?\", (entry_id,)\n    )\n    series = pd.Series(*self._cursor.fetchall())\n    series.index = [description[0] for description in self._cursor.description]\n    series.rename(index=lambda x: x.replace(DOT_REPLACEMENT, \".\"), inplace=True)\n    return series"
            },
            "read_column": {
              "name": "read_column",
              "path": "bamboost.index.DatabaseTable.read_column",
              "signature": "(self, *columns) -> pandas.DataFrame",
              "description": "Read columns from the database.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "columns",
                  "annotation": "str",
                  "description": null,
                  "value": "()"
                }
              ],
              "returns": {
                "name": "",
                "annotation": "pandas.DataFrame",
                "description": "pd.DataFrame: columns from the database"
              },
              "docstring": [],
              "source": "@sql.with_connection\ndef read_column(self, *columns: str) -> pd.DataFrame:\n    \"\"\"Read columns from the database.\n\n    Args:\n        *columns (list): columns to read\n\n    Returns:\n        pd.DataFrame: columns from the database\n    \"\"\"\n    self._cursor.execute(f\"SELECT {', '.join(columns)} FROM {self.tablename_db}\")\n    df = pd.DataFrame.from_records(self._cursor.fetchall(), columns=columns)\n    df.rename(columns=lambda x: x.replace(DOT_REPLACEMENT, \".\"), inplace=True)\n    return df"
            },
            "drop_table": {
              "name": "drop_table",
              "path": "bamboost.index.DatabaseTable.drop_table",
              "signature": "(self) -> None",
              "description": "Drop the table of the database.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "@sql.with_connection\ndef drop_table(self) -> None:\n    \"\"\"Drop the table of the database.\"\"\"\n    self._cursor.execute(f\"DROP TABLE {self.tablename_db}\")\n    self._cursor.execute(f\"DROP TABLE {self.tablename_update_times}\")"
            },
            "create_database_table": {
              "name": "create_database_table",
              "path": "bamboost.index.DatabaseTable.create_database_table",
              "signature": "(self) -> None",
              "description": "Create a table for a database.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "@sql.with_connection\ndef create_database_table(self) -> None:\n    \"\"\"Create a table for a database.\"\"\"\n    self._cursor.execute(\n        f\"\"\"CREATE TABLE IF NOT EXISTS {self.tablename_db} \n            (id TEXT PRIMARY KEY NOT NULL, time_stamp DATETIME, notes TEXT, processors INTEGER)\n        \"\"\"\n    )\n    self._cursor.execute(\n        f\"\"\"CREATE TABLE IF NOT EXISTS {self.tablename_update_times} (id TEXT PRIMARY KEY,\n            update_time DATETIME)\n        \"\"\"\n    )"
            },
            "update_entry": {
              "name": "update_entry",
              "path": "bamboost.index.DatabaseTable.update_entry",
              "signature": "(self, entry_id, data) -> None",
              "description": "Update an entry in the database.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "entry_id",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "ID of the entry"
                    }
                  ]
                },
                {
                  "name": "data",
                  "annotation": "dict",
                  "description": [
                    {
                      "kind": "text",
                      "value": "data to update"
                    }
                  ]
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "@sql.with_connection\ndef update_entry(self, entry_id: str, data: dict) -> None:\n    \"\"\"Update an entry in the database.\n\n    Args:\n        entry_id (str): ID of the entry\n        data (dict): data to update\n    \"\"\"\n    # return if data is empty\n    if not data:\n        return\n\n    # get columns of table\n    self._cursor.execute(f\"PRAGMA table_info({self.tablename_db})\")\n    cols = self._cursor.fetchall()\n\n    # replace dots in keys\n    for key in list(data.keys()):\n        new_key = key.replace(\".\", DOT_REPLACEMENT)\n        new_key = _remove_illegal_column_characters(new_key)\n        if new_key != key:\n            data[new_key] = data.pop(key)\n\n    # check if columns exist\n    for key, val in data.items():\n        # key = key.replace(\".\", DOT_REPLACEMENT)\n        # key = _remove_illegal_column_characters(key)\n        if any(key == column[1] for column in cols):\n            continue\n        dtype = sql.get_sqlite_column_type(val)\n        self._cursor.execute(\n            f\"ALTER TABLE {self.tablename_db} ADD COLUMN [{key}] {dtype}\"\n        )\n\n    # insert data into table\n    data.pop(\"id\", None)\n\n    keys = \", \".join([f\"[{key}]\" for key in data.keys()])\n    values = \", \".join([f\":{key}\" for key in data.keys()])\n    updates = \", \".join([f\"[{key}] = excluded.[{key}]\" for key in data.keys()])\n\n    query = f\"\"\"\n    INSERT INTO {self.tablename_db} (id, {keys})\n    VALUES (:id, {values})\n    ON CONFLICT(id) DO UPDATE SET\n    {updates}\n    \"\"\"\n    data[\"id\"] = entry_id\n    self._cursor.execute(query, data)\n\n    # update update time\n    self._cursor.execute(\n        f\"INSERT OR REPLACE INTO {self.tablename_update_times} VALUES (?, ?)\",\n        (entry_id, time()),\n    )"
            },
            "sync": {
              "name": "sync",
              "path": "bamboost.index.DatabaseTable.sync",
              "signature": "(self) -> None",
              "description": "Sync the table with the file system.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "@sql.with_connection\ndef sync(self) -> None:\n    \"\"\"Sync the table with the file system.\"\"\"\n    all_ids_fs = set(\n        [\n            i\n            for i in os.listdir(self.path)\n            if os.path.isdir(os.path.join(self.path, i))\n        ]\n    )\n\n    self._cursor.execute(\n        f\"SELECT id, update_time FROM {self.tablename_update_times}\"\n    )\n\n    for id, last_up_time in self._cursor.fetchall():\n        # remove entries that do not exist on the file system\n        if id not in all_ids_fs:\n            self._cursor.execute(\n                f\"DELETE FROM {self.tablename_db} WHERE id=?\", (id,)\n            )\n            self._cursor.execute(\n                f\"DELETE FROM {self.tablename_update_times} WHERE id=?\", (id,)\n            )\n            continue\n\n        # update entries that have been modified\n        all_ids_fs.remove(id)\n        if self.entry(id).mtime > last_up_time:\n            self.update_entry(id, self.entry(id).get_all_metadata())\n\n    # add new entries\n    for id in all_ids_fs:\n        self.update_entry(id, self.entry(id).get_all_metadata())"
            },
            "entry": {
              "name": "entry",
              "path": "bamboost.index.DatabaseTable.entry",
              "signature": "(self, entry_id) -> bamboost.index.Entry",
              "description": "Get the Entry object of an entry.\nMultiton pattern. One Entry per entry.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "entry_id",
                  "annotation": "str",
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "bamboost.index.Entry",
                "description": null
              },
              "docstring": [],
              "source": "@sql.with_connection\ndef entry(self, entry_id: str) -> Entry:\n    \"\"\"Get the Entry object of an entry.\n    Multiton pattern. One Entry per entry.\n    \"\"\"\n    if entry_id not in self._entries:\n        self._entries[entry_id] = Entry(entry_id, self.path)\n    return self._entries[entry_id]"
            }
          },
          "source": "class DatabaseTable:\n    \"\"\"\n    Class to manage the table of a database. Multiton pattern. One table per\n    database.\n    \"\"\"\n\n    _instances = {}\n\n    def __new__(cls, id: str, *args, **kwargs) -> DatabaseTable:\n        if _comm.rank != 0:\n            return Null()\n\n        if id not in cls._instances:\n            cls._instances[id] = super().__new__(cls)\n        return cls._instances[id]\n\n    def __init__(self, id: str, *, _index: IndexAPI = None):\n        if hasattr(self, \"_initialized\"):\n            return\n\n        self.id = id\n        self._entries = {}\n        self._initialized = True\n        self._index = _index if _index is not None else IndexAPI()\n        self.path = self._index.get_path(self.id)\n        self.tablename_db = f\"db_{self.id}\"\n        self.tablename_update_times = f\"db_{self.id}_t\"\n        self.create_database_table()\n\n    def __getattr__(self, name):\n        if name in {\n            \"_conn\",\n            \"_cursor\",\n            \"open\",\n            \"close\",\n            \"commit\",\n            \"_is_open\",\n            \"commit_once\",\n        }:\n            return getattr(self._index, name)\n        return self.__getattribute__(name)\n\n    # ---------------------\n    # Database table functions\n    # ---------------------\n    @sql.with_connection\n    def read_table(self) -> pd.DataFrame:\n        \"\"\"Read the table of the database.\n\n        Returns:\n            pd.DataFrame: table of the database\n        \"\"\"\n        df = pd.read_sql_query(f\"SELECT * FROM {self.tablename_db}\", self._conn)\n        # drop \"hidden\" columns which start with _\n        df = df.loc[:, ~df.columns.str.startswith(\"_\")]\n        df.rename(columns=lambda x: x.replace(DOT_REPLACEMENT, \".\"), inplace=True)\n        return df\n\n    @sql.with_connection\n    def read_entry(self, entry_id: str) -> pd.Series:\n        \"\"\"Read an entry from the database.\n\n        Args:\n            entry_id (str): ID of the entry\n\n        Returns:\n            pd.Series: entry from the database\n        \"\"\"\n        self._cursor.execute(\n            f\"SELECT * FROM {self.tablename_db} WHERE id=?\", (entry_id,)\n        )\n        series = pd.Series(*self._cursor.fetchall())\n        series.index = [description[0] for description in self._cursor.description]\n        series.rename(index=lambda x: x.replace(DOT_REPLACEMENT, \".\"), inplace=True)\n        return series\n\n    @sql.with_connection\n    def read_column(self, *columns: str) -> pd.DataFrame:\n        \"\"\"Read columns from the database.\n\n        Args:\n            *columns (list): columns to read\n\n        Returns:\n            pd.DataFrame: columns from the database\n        \"\"\"\n        self._cursor.execute(f\"SELECT {', '.join(columns)} FROM {self.tablename_db}\")\n        df = pd.DataFrame.from_records(self._cursor.fetchall(), columns=columns)\n        df.rename(columns=lambda x: x.replace(DOT_REPLACEMENT, \".\"), inplace=True)\n        return df\n\n    @sql.with_connection\n    def drop_table(self) -> None:\n        \"\"\"Drop the table of the database.\"\"\"\n        self._cursor.execute(f\"DROP TABLE {self.tablename_db}\")\n        self._cursor.execute(f\"DROP TABLE {self.tablename_update_times}\")\n\n    @sql.with_connection\n    def create_database_table(self) -> None:\n        \"\"\"Create a table for a database.\"\"\"\n        self._cursor.execute(\n            f\"\"\"CREATE TABLE IF NOT EXISTS {self.tablename_db} \n                (id TEXT PRIMARY KEY NOT NULL, time_stamp DATETIME, notes TEXT, processors INTEGER)\n            \"\"\"\n        )\n        self._cursor.execute(\n            f\"\"\"CREATE TABLE IF NOT EXISTS {self.tablename_update_times} (id TEXT PRIMARY KEY,\n                update_time DATETIME)\n            \"\"\"\n        )\n\n    @sql.with_connection\n    def update_entry(self, entry_id: str, data: dict) -> None:\n        \"\"\"Update an entry in the database.\n\n        Args:\n            entry_id (str): ID of the entry\n            data (dict): data to update\n        \"\"\"\n        # return if data is empty\n        if not data:\n            return\n\n        # get columns of table\n        self._cursor.execute(f\"PRAGMA table_info({self.tablename_db})\")\n        cols = self._cursor.fetchall()\n\n        # replace dots in keys\n        for key in list(data.keys()):\n            new_key = key.replace(\".\", DOT_REPLACEMENT)\n            new_key = _remove_illegal_column_characters(new_key)\n            if new_key != key:\n                data[new_key] = data.pop(key)\n\n        # check if columns exist\n        for key, val in data.items():\n            # key = key.replace(\".\", DOT_REPLACEMENT)\n            # key = _remove_illegal_column_characters(key)\n            if any(key == column[1] for column in cols):\n                continue\n            dtype = sql.get_sqlite_column_type(val)\n            self._cursor.execute(\n                f\"ALTER TABLE {self.tablename_db} ADD COLUMN [{key}] {dtype}\"\n            )\n\n        # insert data into table\n        data.pop(\"id\", None)\n\n        keys = \", \".join([f\"[{key}]\" for key in data.keys()])\n        values = \", \".join([f\":{key}\" for key in data.keys()])\n        updates = \", \".join([f\"[{key}] = excluded.[{key}]\" for key in data.keys()])\n\n        query = f\"\"\"\n        INSERT INTO {self.tablename_db} (id, {keys})\n        VALUES (:id, {values})\n        ON CONFLICT(id) DO UPDATE SET\n        {updates}\n        \"\"\"\n        data[\"id\"] = entry_id\n        self._cursor.execute(query, data)\n\n        # update update time\n        self._cursor.execute(\n            f\"INSERT OR REPLACE INTO {self.tablename_update_times} VALUES (?, ?)\",\n            (entry_id, time()),\n        )\n\n    @sql.with_connection\n    def sync(self) -> None:\n        \"\"\"Sync the table with the file system.\"\"\"\n        all_ids_fs = set(\n            [\n                i\n                for i in os.listdir(self.path)\n                if os.path.isdir(os.path.join(self.path, i))\n            ]\n        )\n\n        self._cursor.execute(\n            f\"SELECT id, update_time FROM {self.tablename_update_times}\"\n        )\n\n        for id, last_up_time in self._cursor.fetchall():\n            # remove entries that do not exist on the file system\n            if id not in all_ids_fs:\n                self._cursor.execute(\n                    f\"DELETE FROM {self.tablename_db} WHERE id=?\", (id,)\n                )\n                self._cursor.execute(\n                    f\"DELETE FROM {self.tablename_update_times} WHERE id=?\", (id,)\n                )\n                continue\n\n            # update entries that have been modified\n            all_ids_fs.remove(id)\n            if self.entry(id).mtime > last_up_time:\n                self.update_entry(id, self.entry(id).get_all_metadata())\n\n        # add new entries\n        for id in all_ids_fs:\n            self.update_entry(id, self.entry(id).get_all_metadata())\n\n    @sql.with_connection\n    def entry(self, entry_id: str) -> Entry:\n        \"\"\"Get the Entry object of an entry.\n        Multiton pattern. One Entry per entry.\n        \"\"\"\n        if entry_id not in self._entries:\n            self._entries[entry_id] = Entry(entry_id, self.path)\n        return self._entries[entry_id]",
          "inherited_members": {}
        },
        "Entry": {
          "name": "Entry",
          "path": "bamboost.index.Entry",
          "description": "Simulation entry in a database.\nSimplified version of the Simulation class in the simulation module.",
          "parameters": [
            {
              "name": "self",
              "annotation": null,
              "description": null,
              "value": null
            },
            {
              "name": "id",
              "annotation": "str",
              "description": null,
              "value": null
            },
            {
              "name": "path",
              "annotation": "str",
              "description": null,
              "value": null
            }
          ],
          "attributes": [
            {
              "name": "id",
              "annotation": null,
              "description": null,
              "value": "id"
            },
            {
              "name": "path",
              "annotation": null,
              "description": null,
              "value": "path"
            },
            {
              "name": "h5file",
              "annotation": null,
              "description": null,
              "value": "os.path.join(self.path, self.id, f'{self.id}.h5')"
            },
            {
              "name": "metadata",
              "annotation": "dict",
              "description": null,
              "value": null
            },
            {
              "name": "parameters",
              "annotation": "dict",
              "description": null,
              "value": null
            },
            {
              "name": "mtime",
              "annotation": "float",
              "description": null,
              "value": null
            }
          ],
          "docstring": [],
          "functions": {
            "__init__": {
              "name": "__init__",
              "path": "bamboost.index.Entry.__init__",
              "signature": "(self, id, path) -> None",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "id",
                  "annotation": "str",
                  "description": null,
                  "value": null
                },
                {
                  "name": "path",
                  "annotation": "str",
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "None",
                "description": null
              },
              "docstring": [],
              "source": "def __init__(self, id: str, path: str) -> None:\n    self.id = id\n    self.path = path\n    self.h5file = os.path.join(self.path, self.id, f\"{self.id}.h5\")"
            },
            "get_all_metadata": {
              "name": "get_all_metadata",
              "path": "bamboost.index.Entry.get_all_metadata",
              "signature": "(self) -> dict",
              "description": "Get all metadata of the entry.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "dict",
                "description": null
              },
              "docstring": [],
              "source": "def get_all_metadata(self) -> dict:\n    \"\"\"Get all metadata of the entry.\"\"\"\n    return {**self.metadata, **self.parameters}"
            }
          },
          "source": "@dataclass\nclass Entry:\n    \"\"\"Simulation entry in a database.\n    Simplified version of the Simulation class in the simulation module.\n    \"\"\"\n\n    def __init__(self, id: str, path: str) -> None:\n        self.id = id\n        self.path = path\n        self.h5file = os.path.join(self.path, self.id, f\"{self.id}.h5\")\n\n    @property\n    def metadata(self) -> dict:\n        \"\"\"Get the metadata of the entry.\"\"\"\n        with open_h5file(self.h5file, \"r\") as file:\n            return dict(file.attrs)\n\n    @property\n    def parameters(self) -> dict:\n        \"\"\"Get the parameters of the entry.\"\"\"\n        tmp_dict = dict()\n        with open_h5file(self.h5file, \"r\") as file:\n            try:\n                tmp_dict.update(file[\"parameters\"].attrs)\n                for key in file[\"parameters\"].keys():\n                    tmp_dict.update({key: file[f\"parameters/{key}\"][()]})\n            except KeyError:\n                pass\n\n        return tmp_dict\n\n    def get_all_metadata(self) -> dict:\n        \"\"\"Get all metadata of the entry.\"\"\"\n        return {**self.metadata, **self.parameters}\n\n    @property\n    def mtime(self) -> float:\n        \"\"\"Get the modification time of the entry.\"\"\"\n        return os.path.getmtime(self.h5file)",
          "inherited_members": {}
        }
      },
      "functions": {
        "find": {
          "name": "find",
          "path": "bamboost.index.find",
          "signature": "(uid, root_dir) -> list",
          "description": "Find the database with UID under given root_dir.",
          "parameters": [
            {
              "name": "uid",
              "annotation": null,
              "description": [
                {
                  "kind": "text",
                  "value": "UID to search for"
                }
              ]
            },
            {
              "name": "root_dir",
              "annotation": null,
              "description": [
                {
                  "kind": "text",
                  "value": "root directory for search"
                }
              ]
            }
          ],
          "returns": {
            "name": "",
            "annotation": "list",
            "description": null
          },
          "docstring": [],
          "source": "def find(uid, root_dir) -> list:\n    \"\"\"Find the database with UID under given root_dir.\n\n    Args:\n        uid: UID to search for\n        root_dir: root directory for search\n    \"\"\"\n    if os.name == \"posix\":\n        paths = _find_posix(uid, root_dir)\n    else:\n        paths = _find_python(uid, root_dir)\n    if len(paths) > 1:\n        log.warning(f\"Multiple paths found for UID {uid}:\\n{paths}\")\n    return paths"
        },
        "get_uid_from_path": {
          "name": "get_uid_from_path",
          "path": "bamboost.index.get_uid_from_path",
          "signature": "(path) -> str",
          "description": "Returns the UID found in the specified path.",
          "parameters": [
            {
              "name": "path",
              "annotation": "str",
              "description": null,
              "value": null
            }
          ],
          "returns": {
            "name": "",
            "annotation": "str",
            "description": null
          },
          "docstring": [],
          "source": "def get_uid_from_path(path: str) -> str:\n    \"\"\"Returns the UID found in the specified path.\"\"\"\n    for file in os.listdir(path):\n        if file.startswith(\".BAMBOOST\"):\n            return file.split(\"-\")[1]\n    raise FileNotFoundError(\"No UID file found at specified path.\")"
        },
        "get_known_paths": {
          "name": "get_known_paths",
          "path": "bamboost.index.get_known_paths",
          "signature": "() -> list",
          "description": null,
          "parameters": [],
          "returns": {
            "name": "",
            "annotation": "list",
            "description": null
          },
          "docstring": [],
          "source": "def get_known_paths() -> list:\n    return config[\"index\"].get(\"paths\", [])"
        },
        "_find_posix": {
          "name": "_find_posix",
          "path": "bamboost.index._find_posix",
          "signature": "(uid, root_dir) -> list",
          "description": "Find function using system `find` on linux.",
          "parameters": [
            {
              "name": "uid",
              "annotation": null,
              "description": null,
              "value": null
            },
            {
              "name": "root_dir",
              "annotation": null,
              "description": null,
              "value": null
            }
          ],
          "returns": {
            "name": "",
            "annotation": "list",
            "description": null
          },
          "docstring": [],
          "source": "def _find_posix(uid, root_dir) -> list:\n    \"\"\"Find function using system `find` on linux.\"\"\"\n    completed_process = subprocess.run(\n        [\"find\", root_dir, \"-iname\", uid2(uid), \"-not\", \"-path\", r\"*/\\.git/*\"],\n        capture_output=True,\n    )\n    paths_found = completed_process.stdout.decode(\"utf-8\").splitlines()\n    return paths_found"
        },
        "_find_python": {
          "name": "_find_python",
          "path": "bamboost.index._find_python",
          "signature": "(uid, root_dir) -> list",
          "description": "Some find function for Windows or other if `find` is not working.\n\nTODO: to be implemented",
          "parameters": [
            {
              "name": "uid",
              "annotation": null,
              "description": null,
              "value": null
            },
            {
              "name": "root_dir",
              "annotation": null,
              "description": null,
              "value": null
            }
          ],
          "returns": {
            "name": "",
            "annotation": "list",
            "description": null
          },
          "docstring": [],
          "source": "def _find_python(uid, root_dir) -> list:\n    \"\"\"Some find function for Windows or other if `find` is not working.\n\n    TODO: to be implemented\n    \"\"\"\n    pass"
        },
        "uid2": {
          "name": "uid2",
          "path": "bamboost.index.uid2",
          "signature": "(uid) -> str",
          "description": null,
          "parameters": [
            {
              "name": "uid",
              "annotation": null,
              "description": null,
              "value": null
            }
          ],
          "returns": {
            "name": "",
            "annotation": "str",
            "description": null
          },
          "docstring": [],
          "source": "def uid2(uid) -> str:\n    return f\"{PREFIX}{uid}\""
        },
        "_check_path": {
          "name": "_check_path",
          "path": "bamboost.index._check_path",
          "signature": "(uid, path) -> bool",
          "description": "Check if path is going to the correct database",
          "parameters": [
            {
              "name": "uid",
              "annotation": "str",
              "description": null,
              "value": null
            },
            {
              "name": "path",
              "annotation": "str",
              "description": null,
              "value": null
            }
          ],
          "returns": {
            "name": "",
            "annotation": "bool",
            "description": null
          },
          "docstring": [],
          "source": "def _check_path(uid: str, path: str) -> bool:\n    \"\"\"Check if path is going to the correct database\"\"\"\n    if not os.path.exists(path):\n        return False\n    if f\"{PREFIX}{uid}\" in os.listdir(path):\n        return True\n    return False"
        },
        "_remove_illegal_column_characters": {
          "name": "_remove_illegal_column_characters",
          "path": "bamboost.index._remove_illegal_column_characters",
          "signature": "(key) -> str",
          "description": "Remove illegal characters in sqlite column names from a string.",
          "parameters": [
            {
              "name": "key",
              "annotation": "str",
              "description": [
                {
                  "kind": "text",
                  "value": "key to clean"
                }
              ]
            }
          ],
          "returns": {
            "name": "",
            "annotation": "str",
            "description": null
          },
          "docstring": [
            {
              "kind": "admonition",
              "value": {
                "annotation": "notes",
                "description": "Removes all content in parenthesis and replaces dashes with underscores."
              },
              "title": "Notes"
            }
          ],
          "source": "def _remove_illegal_column_characters(key: str) -> str:\n    \"\"\"Remove illegal characters in sqlite column names from a string.\n\n    Args:\n        key (str): key to clean\n\n    Notes:\n        Removes all content in parenthesis and replaces dashes with underscores.\n    \"\"\"\n    import re\n\n    # clean from parenthesis\n    key = re.sub(r\"[()]\", \"\", re.sub(r\"\\(.*?\\)\", \"\", key))\n    # clean from dashes\n    key = re.sub(r\"-\", \"_\", key)\n    return key"
        }
      }
    },
    "accessors": {
      "name": "accessors",
      "path": "bamboost.accessors",
      "filepath": "/home/florez/work/code/bamboost/bamboost/accessors/__init__.py",
      "description": null,
      "docstring": [],
      "attributes": [
        {
          "name": "__all__",
          "annotation": null,
          "description": null,
          "value": "['meshes', 'fielddata', 'globals']"
        }
      ],
      "modules": {
        "globals": {
          "name": "globals",
          "path": "bamboost.accessors.globals",
          "filepath": "/home/florez/work/code/bamboost/bamboost/accessors/globals.py",
          "description": null,
          "docstring": [],
          "attributes": [
            {
              "name": "__all__",
              "annotation": null,
              "description": null,
              "value": "['GlobalGroup']"
            }
          ],
          "modules": {},
          "classes": {
            "GlobalGroup": {
              "name": "GlobalGroup",
              "path": "bamboost.accessors.globals.GlobalGroup",
              "description": "Enhanced Group for '/globals'.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "file_handler",
                  "annotation": "FileHandler",
                  "description": [
                    {
                      "kind": "text",
                      "value": "The file handler."
                    }
                  ]
                },
                {
                  "name": "path_to_data",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "The in-file path to the group."
                    }
                  ]
                }
              ],
              "attributes": [
                {
                  "name": "df",
                  "annotation": "pd.DataFrame",
                  "description": null,
                  "value": null
                }
              ],
              "docstring": [],
              "functions": {
                "__init__": {
                  "name": "__init__",
                  "path": "bamboost.accessors.globals.GlobalGroup.__init__",
                  "signature": "(self, file_handler, path_to_data) -> None",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "file_handler",
                      "annotation": "FileHandler",
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "path_to_data",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def __init__(self, file_handler: FileHandler, path_to_data: str) -> None:\n    super().__init__(file_handler, path_to_data)"
                }
              },
              "source": "class GlobalGroup(Group):\n    \"\"\"Enhanced Group for '/globals'.\n\n    Args:\n        file_handler: The file handler.\n        path_to_data: The in-file path to the group.\n    \"\"\"\n\n    def __init__(self, file_handler: FileHandler, path_to_data: str) -> None:\n        super().__init__(file_handler, path_to_data)\n\n    @property\n    def df(self) -> pd.DataFrame:\n        \"\"\"Return a pandas DataFrame with all datasets.\"\"\"\n        d = {key: self[key][()] for key in self.datasets()}\n        for key, val in d.items():\n            d[key] = [i for i in val]\n        return pd.DataFrame.from_dict(d)",
              "inherited_members": {
                "bamboost.common.hdf_pointer.BasePointer": [
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.new_pointer"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer._file"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.path_to_data"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.obj"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__str__"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__repr__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__getattr__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__getitem__"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.attrs"
                  }
                ],
                "bamboost.common.hdf_pointer.Group": [
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group._ipython_key_completions_"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.__iter__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.keys"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.groups"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.datasets"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.extract_attrs"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group._repr_html_"
                  }
                ]
              }
            }
          },
          "functions": {}
        },
        "meshes": {
          "name": "meshes",
          "path": "bamboost.accessors.meshes",
          "filepath": "/home/florez/work/code/bamboost/bamboost/accessors/meshes.py",
          "description": null,
          "docstring": [],
          "attributes": [
            {
              "name": "__all__",
              "annotation": null,
              "description": null,
              "value": "['MeshGroup', 'Mesh']"
            },
            {
              "name": "log",
              "annotation": null,
              "description": null,
              "value": "BAMBOOST_LOGGER.getChild(__name__.split('.')[-1])"
            }
          ],
          "modules": {},
          "classes": {
            "MeshGroup": {
              "name": "MeshGroup",
              "path": "bamboost.accessors.meshes.MeshGroup",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "file_handler",
                  "annotation": "FileHandler",
                  "description": null,
                  "value": null
                },
                {
                  "name": "path_to_data",
                  "annotation": "str",
                  "description": null,
                  "value": "'/Mesh/0'"
                },
                {
                  "name": "_default_mesh",
                  "annotation": "str",
                  "description": null,
                  "value": "'mesh'"
                },
                {
                  "name": "kwargs",
                  "annotation": null,
                  "description": null,
                  "value": "{}"
                }
              ],
              "attributes": [
                {
                  "name": "_default_mesh",
                  "annotation": null,
                  "description": null,
                  "value": "_default_mesh"
                }
              ],
              "docstring": [],
              "functions": {
                "__init__": {
                  "name": "__init__",
                  "path": "bamboost.accessors.meshes.MeshGroup.__init__",
                  "signature": "(self, file_handler, path_to_data = '/Mesh/0', _default_mesh = 'mesh', **kwargs) -> None",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "file_handler",
                      "annotation": "FileHandler",
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "path_to_data",
                      "annotation": "str",
                      "description": null,
                      "value": "'/Mesh/0'"
                    },
                    {
                      "name": "_default_mesh",
                      "annotation": "str",
                      "description": null,
                      "value": "'mesh'"
                    },
                    {
                      "name": "kwargs",
                      "annotation": null,
                      "description": null,
                      "value": "{}"
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def __init__(\n    self,\n    file_handler: FileHandler,\n    path_to_data: str = \"/Mesh/0\",\n    _default_mesh: str = \"mesh\",\n    **kwargs,\n) -> None:\n    super().__init__(file_handler, path_to_data, **kwargs)\n    self._default_mesh = _default_mesh"
                },
                "__getitem__": {
                  "name": "__getitem__",
                  "path": "bamboost.accessors.meshes.MeshGroup.__getitem__",
                  "signature": "(self, key) -> bamboost.accessors.meshes.Mesh",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "key",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "bamboost.accessors.meshes.Mesh",
                    "description": null
                  },
                  "docstring": [],
                  "source": "@with_file_open(\"r\")\ndef __getitem__(self, key) -> Mesh:\n    return Mesh(self._file, f\"{self.path_to_data}/{key}\")"
                }
              },
              "source": "class MeshGroup(hdf_pointer.Group):\n    def __init__(\n        self,\n        file_handler: FileHandler,\n        path_to_data: str = \"/Mesh/0\",\n        _default_mesh: str = \"mesh\",\n        **kwargs,\n    ) -> None:\n        super().__init__(file_handler, path_to_data, **kwargs)\n        self._default_mesh = _default_mesh\n\n    @with_file_open(\"r\")\n    def __getitem__(self, key) -> Mesh:\n        return Mesh(self._file, f\"{self.path_to_data}/{key}\")",
              "inherited_members": {
                "bamboost.common.hdf_pointer.BasePointer": [
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.new_pointer"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer._file"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.path_to_data"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.obj"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__str__"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__repr__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__getattr__"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.attrs"
                  }
                ],
                "bamboost.common.hdf_pointer.Group": [
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group._ipython_key_completions_"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.__iter__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.keys"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.groups"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.datasets"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.extract_attrs"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group._repr_html_"
                  }
                ]
              }
            },
            "Mesh": {
              "name": "Mesh",
              "path": "bamboost.accessors.meshes.Mesh",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "file_handler",
                  "annotation": "FileHandler",
                  "description": null,
                  "value": null
                },
                {
                  "name": "path_to_data",
                  "annotation": "str",
                  "description": null,
                  "value": null
                }
              ],
              "attributes": [
                {
                  "name": "coordinates",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "connectivity",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "docstring": [],
              "functions": {
                "__init__": {
                  "name": "__init__",
                  "path": "bamboost.accessors.meshes.Mesh.__init__",
                  "signature": "(self, file_handler, path_to_data) -> None",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "file_handler",
                      "annotation": "FileHandler",
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "path_to_data",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def __init__(self, file_handler: FileHandler, path_to_data: str) -> None:\n    super().__init__(file_handler, path_to_data)"
                },
                "get_tuple": {
                  "name": "get_tuple",
                  "path": "bamboost.accessors.meshes.Mesh.get_tuple",
                  "signature": "(self) -> typing.Tuple",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "typing.Tuple",
                    "description": null
                  },
                  "docstring": [],
                  "source": "@with_file_open(\"r\")\ndef get_tuple(self) -> Tuple[np.ndarray, np.ndarray]:\n    return (self.coordinates, self.connectivity)"
                }
              },
              "source": "class Mesh(hdf_pointer.Group):\n    def __init__(self, file_handler: FileHandler, path_to_data: str) -> None:\n        super().__init__(file_handler, path_to_data)\n\n    @property\n    @with_file_open(\"r\")\n    def coordinates(self):\n        try:\n            return self.obj[\"geometry\"][()]\n        except KeyError:\n            return self.obj[\"coordinates\"][()]\n\n    @property\n    @with_file_open(\"r\")\n    def connectivity(self):\n        return self.obj[\"topology\"][()]\n\n    @with_file_open(\"r\")\n    def get_tuple(self) -> Tuple[np.ndarray, np.ndarray]:\n        return (self.coordinates, self.connectivity)",
              "inherited_members": {
                "bamboost.common.hdf_pointer.BasePointer": [
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.new_pointer"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer._file"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.path_to_data"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.obj"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__str__"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__repr__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__getattr__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__getitem__"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.attrs"
                  }
                ],
                "bamboost.common.hdf_pointer.Group": [
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group._ipython_key_completions_"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.__iter__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.keys"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.groups"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.datasets"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.extract_attrs"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group._repr_html_"
                  }
                ]
              }
            }
          },
          "functions": {}
        },
        "fielddata": {
          "name": "fielddata",
          "path": "bamboost.accessors.fielddata",
          "filepath": "/home/florez/work/code/bamboost/bamboost/accessors/fielddata.py",
          "description": null,
          "docstring": [],
          "attributes": [
            {
              "name": "__all__",
              "annotation": null,
              "description": null,
              "value": "['DataGroup', 'FieldData']"
            },
            {
              "name": "log",
              "annotation": null,
              "description": null,
              "value": "BAMBOOST_LOGGER.getChild(__name__.split('.')[-1])"
            }
          ],
          "modules": {},
          "classes": {
            "DataGroup": {
              "name": "DataGroup",
              "path": "bamboost.accessors.fielddata.DataGroup",
              "description": "This pointer points to the data directory. Item accessor returns the\nindividual data fields. `meshes` is passed to here for access of linked\nmeshes.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "file_handler",
                  "annotation": "FileHandler",
                  "description": null,
                  "value": null
                },
                {
                  "name": "meshes",
                  "annotation": "MeshGroup",
                  "description": null,
                  "value": null
                },
                {
                  "name": "path_to_data",
                  "annotation": "str",
                  "description": null,
                  "value": "'/data'"
                },
                {
                  "name": "kwargs",
                  "annotation": null,
                  "description": null,
                  "value": "{}"
                }
              ],
              "attributes": [
                {
                  "name": "meshes",
                  "annotation": null,
                  "description": null,
                  "value": "meshes"
                },
                {
                  "name": "info",
                  "annotation": "pd.DataFrame",
                  "description": null,
                  "value": null
                }
              ],
              "docstring": [],
              "functions": {
                "__init__": {
                  "name": "__init__",
                  "path": "bamboost.accessors.fielddata.DataGroup.__init__",
                  "signature": "(self, file_handler, meshes, path_to_data = '/data', **kwargs) -> None",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "file_handler",
                      "annotation": "FileHandler",
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "meshes",
                      "annotation": "MeshGroup",
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "path_to_data",
                      "annotation": "str",
                      "description": null,
                      "value": "'/data'"
                    },
                    {
                      "name": "kwargs",
                      "annotation": null,
                      "description": null,
                      "value": "{}"
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def __init__(\n    self,\n    file_handler: FileHandler,\n    meshes: MeshGroup,\n    path_to_data: str = \"/data\",\n    **kwargs,\n) -> None:\n    super().__init__(file_handler, path_to_data, **kwargs)\n    self.meshes = meshes"
                },
                "__getitem__": {
                  "name": "__getitem__",
                  "path": "bamboost.accessors.fielddata.DataGroup.__getitem__",
                  "signature": "(self, key) -> bamboost.accessors.fielddata.FieldData",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "key",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "bamboost.accessors.fielddata.FieldData",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def __getitem__(self, key) -> FieldData:\n    return FieldData(self._file, f\"{self.path_to_data}/{key}\", meshes=self.meshes)"
                },
                "__iter__": {
                  "name": "__iter__",
                  "path": "bamboost.accessors.fielddata.DataGroup.__iter__",
                  "signature": "(self) -> typing.Generator",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "typing.Generator",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def __iter__(self) -> Generator[FieldData, None, None]:\n    for key in self.keys():\n        yield self.__getitem__(key)"
                }
              },
              "source": "class DataGroup(hdf_pointer.Group):\n    \"\"\"This pointer points to the data directory. Item accessor returns the\n    individual data fields. `meshes` is passed to here for access of linked\n    meshes.\n    \"\"\"\n\n    def __init__(\n        self,\n        file_handler: FileHandler,\n        meshes: MeshGroup,\n        path_to_data: str = \"/data\",\n        **kwargs,\n    ) -> None:\n        super().__init__(file_handler, path_to_data, **kwargs)\n        self.meshes = meshes\n\n    def __getitem__(self, key) -> FieldData:\n        return FieldData(self._file, f\"{self.path_to_data}/{key}\", meshes=self.meshes)\n\n    def __iter__(self) -> Generator[FieldData, None, None]:\n        for key in self.keys():\n            yield self.__getitem__(key)\n\n    @property\n    @with_file_open(\"r\")\n    def info(self) -> pd.DataFrame:\n        \"\"\"View the data stored.\n\n        Returns:\n            :class:`pd.DataFrame`\n        \"\"\"\n        tmp_dictionary = dict()\n        for data in self:\n            steps = len(data)\n            shape = data.obj[\"0\"].shape\n            dtype = data.obj[\"0\"].dtype\n            tmp_dictionary[data._name] = {\n                \"dtype\": dtype,\n                \"shape\": shape,\n                \"steps\": steps,\n            }\n        return pd.DataFrame.from_dict(tmp_dictionary)",
              "inherited_members": {
                "bamboost.common.hdf_pointer.BasePointer": [
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.new_pointer"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer._file"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.path_to_data"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.obj"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__str__"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__repr__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__getattr__"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.attrs"
                  }
                ],
                "bamboost.common.hdf_pointer.Group": [
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group._ipython_key_completions_"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.keys"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.groups"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.datasets"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.extract_attrs"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group._repr_html_"
                  }
                ]
              }
            },
            "FieldData": {
              "name": "FieldData",
              "path": "bamboost.accessors.fielddata.FieldData",
              "description": "This pointer points to a specific data field. `meshes` is passed to here\nfor access of linked meshes.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "file_handler",
                  "annotation": "FileHandler",
                  "description": null,
                  "value": null
                },
                {
                  "name": "path_to_data",
                  "annotation": "str",
                  "description": null,
                  "value": null
                },
                {
                  "name": "meshes",
                  "annotation": "MeshGroup",
                  "description": null,
                  "value": null
                }
              ],
              "attributes": [
                {
                  "name": "_vds_key",
                  "annotation": null,
                  "description": null,
                  "value": "'__vds'"
                },
                {
                  "name": "_times_key",
                  "annotation": null,
                  "description": null,
                  "value": "'__times'"
                },
                {
                  "name": "meshes",
                  "annotation": null,
                  "description": null,
                  "value": "meshes"
                },
                {
                  "name": "_name",
                  "annotation": null,
                  "description": null,
                  "value": "path_to_data.split('/')"
                },
                {
                  "name": "shape",
                  "annotation": "tuple",
                  "description": null,
                  "value": null
                },
                {
                  "name": "dtype",
                  "annotation": "type",
                  "description": null,
                  "value": null
                },
                {
                  "name": "times",
                  "annotation": "np.ndarray",
                  "description": null,
                  "value": null
                },
                {
                  "name": "mesh",
                  "annotation": "Mesh",
                  "description": null,
                  "value": null
                },
                {
                  "name": "coordinates",
                  "annotation": "np.ndarray",
                  "description": null,
                  "value": null
                },
                {
                  "name": "connectivity",
                  "annotation": "np.ndarray",
                  "description": null,
                  "value": null
                },
                {
                  "name": "msh",
                  "annotation": "Tuple",
                  "description": null,
                  "value": null
                }
              ],
              "docstring": [],
              "functions": {
                "__init__": {
                  "name": "__init__",
                  "path": "bamboost.accessors.fielddata.FieldData.__init__",
                  "signature": "(self, file_handler, path_to_data, meshes) -> None",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "file_handler",
                      "annotation": "FileHandler",
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "path_to_data",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "meshes",
                      "annotation": "MeshGroup",
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def __init__(\n    self, file_handler: FileHandler, path_to_data: str, meshes: MeshGroup\n) -> None:\n    super().__init__(file_handler, path_to_data)\n    self.meshes = meshes\n    self._name = path_to_data.split(\"/\")[-1]"
                },
                "__getitem__": {
                  "name": "__getitem__",
                  "path": "bamboost.accessors.fielddata.FieldData.__getitem__",
                  "signature": "(self, key) -> numpy.ndarray",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "key",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "numpy.ndarray",
                    "description": null
                  },
                  "docstring": [],
                  "source": "@with_file_open(\"r\")\ndef __getitem__(self, key) -> np.ndarray:\n    return self._get_full_data()[key]"
                },
                "_get_full_data": {
                  "name": "_get_full_data",
                  "path": "bamboost.accessors.fielddata.FieldData._get_full_data",
                  "signature": "(self) -> h5py.Dataset",
                  "description": "Return a HDF5 virtual dataset including all steps of the field.\n\nIf the virtual dataset exists with the correct shape it will be\nreturned, otherwise it will be created.",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "h5py.Dataset",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def _get_full_data(self) -> h5py.Dataset:\n    \"\"\"Return a HDF5 virtual dataset including all steps of the field.\n\n    If the virtual dataset exists with the correct shape it will be\n    returned, otherwise it will be created.\n    \"\"\"\n    if self._vds_key not in self.keys():\n        self._create_vds()\n        return self.obj[self._vds_key]\n\n    if len(self) > self.obj.attrs.get(\"virtual_dataset_length\", 0):\n        self._create_vds()\n        self._create_times()\n        return self.obj[self._vds_key]\n\n    return self.obj[self._vds_key]"
                },
                "__len__": {
                  "name": "__len__",
                  "path": "bamboost.accessors.fielddata.FieldData.__len__",
                  "signature": "(self) -> int",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "int",
                    "description": null
                  },
                  "docstring": [],
                  "source": "@with_file_open(\"r\")\ndef __len__(self) -> int:\n    return len(self.datasets())"
                },
                "datasets": {
                  "name": "datasets",
                  "path": "bamboost.accessors.fielddata.FieldData.datasets",
                  "signature": "(self) -> set",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "set",
                    "description": null
                  },
                  "docstring": [],
                  "source": "@with_file_open(\"r\")\ndef datasets(self) -> set:\n    return super().datasets() - {self._vds_key, self._times_key}"
                },
                "at_step": {
                  "name": "at_step",
                  "path": "bamboost.accessors.fielddata.FieldData.at_step",
                  "signature": "(self, *steps) -> numpy.ndarray",
                  "description": "Direct access to data at step. Does not require the virtual dataset.",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "steps",
                      "annotation": "int",
                      "description": null,
                      "value": "()"
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "numpy.ndarray",
                    "description": null
                  },
                  "docstring": [
                    {
                      "kind": "text",
                      "value": "Returns:\n    :class:`np.ndarray`"
                    }
                  ],
                  "source": "@with_file_open()\ndef at_step(self, *steps: int) -> np.ndarray:\n    \"\"\"Direct access to data at step. Does not require the virtual dataset.\n\n    Args:\n        step0, step1, ...: step to extract (can be multiple)\n    Returns:\n        :class:`np.ndarray`\n    \"\"\"\n    data = list()\n    for step in steps:\n        if step < 0:\n            step = len(self) + step\n        data.append(self.obj[str(step)][()])\n    if len(data) <= 1:\n        return data[0]\n    else:\n        return data"
                },
                "regenerate_virtual_datasets": {
                  "name": "regenerate_virtual_datasets",
                  "path": "bamboost.accessors.fielddata.FieldData.regenerate_virtual_datasets",
                  "signature": "(self) -> None",
                  "description": "Regenerate virtual dataset. Call this if the data has changed, thus the\nvirtual datasets need to be updated to cover the actual data.",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def regenerate_virtual_datasets(self) -> None:\n    \"\"\"Regenerate virtual dataset. Call this if the data has changed, thus the\n    virtual datasets need to be updated to cover the actual data.\n    \"\"\"\n    self._create_times()\n    self._create_vds()"
                },
                "_create_times": {
                  "name": "_create_times",
                  "path": "bamboost.accessors.fielddata.FieldData._create_times",
                  "signature": "(self) -> None",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "@with_file_open(\"r+\")\ndef _create_times(self) -> None:\n    times = [self.obj[str(step)].attrs.get(\"t\", step) for step in range(len(self))]\n    if self._times_key in self.obj.keys():\n        del self.obj[self._times_key]\n    self.obj.create_dataset(self._times_key, data=np.array(times))"
                },
                "_create_vds": {
                  "name": "_create_vds",
                  "path": "bamboost.accessors.fielddata.FieldData._create_vds",
                  "signature": "(self) -> None",
                  "description": "Create virtual dataset of the full timeseries of a field.\nRequires HDF5 > 1.10 !",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def _create_vds(self) -> None:\n    \"\"\"Create virtual dataset of the full timeseries of a field.\n    Requires HDF5 > 1.10 !\n    \"\"\"\n    with self._file(\"r\"):\n        length = len(self)\n        ds_shape = self.obj[\"0\"].shape\n        ds_dtype = self.obj[\"0\"].dtype\n\n        layout = h5py.VirtualLayout(shape=(length, *ds_shape), dtype=ds_dtype)\n\n        for step in range(length):\n            vsource = h5py.VirtualSource(self.obj[str(step)])\n            layout[step] = vsource\n\n    with self._file(\"r+\"):\n        if self._vds_key in self.obj.keys():\n            del self.obj[self._vds_key]\n        self.obj.attrs[\"virtual_dataset_length\"] = length\n        self.obj.create_virtual_dataset(self._vds_key, layout)"
                }
              },
              "source": "class FieldData(hdf_pointer.Group):\n    \"\"\"This pointer points to a specific data field. `meshes` is passed to here\n    for access of linked meshes.\n    \"\"\"\n\n    _vds_key = \"__vds\"  # We create a virtual dataset for slicing across all steps\n    _times_key = (\n        \"__times\"  # We store the time of steps in a seperate dataset for performance\n    )\n\n    def __init__(\n        self, file_handler: FileHandler, path_to_data: str, meshes: MeshGroup\n    ) -> None:\n        super().__init__(file_handler, path_to_data)\n        self.meshes = meshes\n        self._name = path_to_data.split(\"/\")[-1]\n\n    @with_file_open(\"r\")\n    def __getitem__(self, key) -> np.ndarray:\n        return self._get_full_data()[key]\n\n    def _get_full_data(self) -> h5py.Dataset:\n        \"\"\"Return a HDF5 virtual dataset including all steps of the field.\n\n        If the virtual dataset exists with the correct shape it will be\n        returned, otherwise it will be created.\n        \"\"\"\n        if self._vds_key not in self.keys():\n            self._create_vds()\n            return self.obj[self._vds_key]\n\n        if len(self) > self.obj.attrs.get(\"virtual_dataset_length\", 0):\n            self._create_vds()\n            self._create_times()\n            return self.obj[self._vds_key]\n\n        return self.obj[self._vds_key]\n\n    @with_file_open(\"r\")\n    def __len__(self) -> int:\n        return len(self.datasets())\n\n    @with_file_open(\"r\")\n    def datasets(self) -> set:\n        return super().datasets() - {self._vds_key, self._times_key}\n\n    @property\n    @with_file_open(\"r\")\n    def shape(self) -> tuple:\n        return self._get_full_data().shape\n\n    @property\n    @with_file_open(\"r\")\n    def dtype(self) -> type:\n        return self._get_full_data().dtype\n\n    @with_file_open()\n    def at_step(self, *steps: int) -> np.ndarray:\n        \"\"\"Direct access to data at step. Does not require the virtual dataset.\n\n        Args:\n            step0, step1, ...: step to extract (can be multiple)\n        Returns:\n            :class:`np.ndarray`\n        \"\"\"\n        data = list()\n        for step in steps:\n            if step < 0:\n                step = len(self) + step\n            data.append(self.obj[str(step)][()])\n        if len(data) <= 1:\n            return data[0]\n        else:\n            return data\n\n    @property\n    @with_file_open()\n    def times(self) -> np.ndarray:\n        \"\"\"Return the array of timestamps.\n\n        Returns:\n            :class:`np.ndarray`\n        \"\"\"\n        if (self._times_key not in self.keys()) or (\n            len(self) > self.obj.attrs.get(\"virtual_dataset_length\", 0)\n        ):\n            self._create_times()\n\n        return self.obj[self._times_key][()]\n\n    @property\n    @with_file_open()\n    def mesh(self) -> Mesh:\n        \"\"\"Return the linked mesh. Currently returns the linked mesh of first step only.\n\n        Returns:\n            :class:`tuple[np.ndarray, np.ndarray]`\n        \"\"\"\n        mesh_name = self.obj[\"0\"].attrs.get(\"mesh\", self.meshes._default_mesh)\n        return self.meshes[mesh_name]\n\n    @property\n    def coordinates(self) -> np.ndarray:\n        \"\"\"Wrapper for mesh.coordinates\"\"\"\n        return self.mesh.coordinates\n\n    @property\n    def connectivity(self) -> np.ndarray:\n        \"\"\"Wrapper for mesh.connectivity\"\"\"\n        return self.mesh.connectivity\n\n    @property\n    @with_file_open()\n    def msh(self) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"Wrapper to get mesh as tuple\"\"\"\n        return (self.mesh.coordinates, self.mesh.connectivity)\n\n    def regenerate_virtual_datasets(self) -> None:\n        \"\"\"Regenerate virtual dataset. Call this if the data has changed, thus the\n        virtual datasets need to be updated to cover the actual data.\n        \"\"\"\n        self._create_times()\n        self._create_vds()\n\n    @with_file_open(\"r+\")\n    def _create_times(self) -> None:\n        times = [self.obj[str(step)].attrs.get(\"t\", step) for step in range(len(self))]\n        if self._times_key in self.obj.keys():\n            del self.obj[self._times_key]\n        self.obj.create_dataset(self._times_key, data=np.array(times))\n\n    def _create_vds(self) -> None:\n        \"\"\"Create virtual dataset of the full timeseries of a field.\n        Requires HDF5 > 1.10 !\n        \"\"\"\n        with self._file(\"r\"):\n            length = len(self)\n            ds_shape = self.obj[\"0\"].shape\n            ds_dtype = self.obj[\"0\"].dtype\n\n            layout = h5py.VirtualLayout(shape=(length, *ds_shape), dtype=ds_dtype)\n\n            for step in range(length):\n                vsource = h5py.VirtualSource(self.obj[str(step)])\n                layout[step] = vsource\n\n        with self._file(\"r+\"):\n            if self._vds_key in self.obj.keys():\n                del self.obj[self._vds_key]\n            self.obj.attrs[\"virtual_dataset_length\"] = length\n            self.obj.create_virtual_dataset(self._vds_key, layout)",
              "inherited_members": {
                "bamboost.common.hdf_pointer.BasePointer": [
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.new_pointer"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer._file"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.path_to_data"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.obj"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__str__"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__repr__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__getattr__"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.attrs"
                  }
                ],
                "bamboost.common.hdf_pointer.Group": [
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group._ipython_key_completions_"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.__iter__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.keys"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.groups"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.extract_attrs"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group._repr_html_"
                  }
                ]
              }
            }
          },
          "functions": {}
        }
      },
      "classes": {},
      "functions": {}
    },
    "common": {
      "name": "common",
      "path": "bamboost.common",
      "filepath": "/home/florez/work/code/bamboost/bamboost/common/__init__.py",
      "description": null,
      "docstring": [],
      "attributes": [
        {
          "name": "__all__",
          "annotation": null,
          "description": null,
          "value": "['file_handler', 'utilities', 'git_utility', 'hdf_pointer', 'mpi']"
        }
      ],
      "modules": {
        "git_utility": {
          "name": "git_utility",
          "path": "bamboost.common.git_utility",
          "filepath": "/home/florez/work/code/bamboost/bamboost/common/git_utility.py",
          "description": null,
          "docstring": [],
          "attributes": [
            {
              "name": "__all__",
              "annotation": null,
              "description": null,
              "value": "['GitStateGetter']"
            }
          ],
          "modules": {},
          "classes": {
            "GitStateGetter": {
              "name": "GitStateGetter",
              "path": "bamboost.common.git_utility.GitStateGetter",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "attributes": [],
              "docstring": [],
              "functions": {
                "__init__": {
                  "name": "__init__",
                  "path": "bamboost.common.git_utility.GitStateGetter.__init__",
                  "signature": "(self) -> None",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def __init__(self) -> None:\n    pass"
                },
                "_git_command": {
                  "name": "_git_command",
                  "path": "bamboost.common.git_utility.GitStateGetter._git_command",
                  "signature": "(command) -> str",
                  "description": null,
                  "parameters": [
                    {
                      "name": "command",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "str",
                    "description": null
                  },
                  "docstring": [],
                  "source": "@staticmethod\ndef _git_command(command: str) -> str:\n    process = subprocess.Popen(\n        command.split(),\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        universal_newlines=True,\n    )\n    stdout, stderr = process.communicate()\n    return str(stdout)"
                },
                "create_git_string": {
                  "name": "create_git_string",
                  "path": "bamboost.common.git_utility.GitStateGetter.create_git_string",
                  "signature": "(self) -> str",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "str",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def create_git_string(self) -> str:\n    self.string = \"\"\n\n    self.string += \"\\n\"\n    self.string += \"----- REMOTE ------ \\n\"\n    self.string += self._git_command(\"git remote -v\")\n\n    self.string += \"\\n\"\n    self.string += \"----- BRANCH ------ \\n\"\n    self.string += self._git_command(\"git branch -v\")\n\n    self.string += \"\\n\"\n    self.string += \"----- LAST COMMIT ------ \\n\"\n    self.string += self._git_command(\"git rev-parse HEAD\")\n\n    self.string += \"\\n\"\n    self.string += \"----- STATUS ------ \\n\"\n    self.string += self._git_command(\"git status\")\n\n    self.string += \"\\n\"\n    self.string += \"----- DIFFERENCE ------ \\n\"\n    self.string += self._git_command(\"git diff HEAD\")\n\n    return self.string"
                }
              },
              "source": "class GitStateGetter:\n    def __init__(self) -> None:\n        pass\n\n    @staticmethod\n    def _git_command(command: str) -> str:\n        process = subprocess.Popen(\n            command.split(),\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            universal_newlines=True,\n        )\n        stdout, stderr = process.communicate()\n        return str(stdout)\n\n    def create_git_string(self) -> str:\n        self.string = \"\"\n\n        self.string += \"\\n\"\n        self.string += \"----- REMOTE ------ \\n\"\n        self.string += self._git_command(\"git remote -v\")\n\n        self.string += \"\\n\"\n        self.string += \"----- BRANCH ------ \\n\"\n        self.string += self._git_command(\"git branch -v\")\n\n        self.string += \"\\n\"\n        self.string += \"----- LAST COMMIT ------ \\n\"\n        self.string += self._git_command(\"git rev-parse HEAD\")\n\n        self.string += \"\\n\"\n        self.string += \"----- STATUS ------ \\n\"\n        self.string += self._git_command(\"git status\")\n\n        self.string += \"\\n\"\n        self.string += \"----- DIFFERENCE ------ \\n\"\n        self.string += self._git_command(\"git diff HEAD\")\n\n        return self.string",
              "inherited_members": {}
            }
          },
          "functions": {}
        },
        "_mock_mpi": {
          "name": "_mock_mpi",
          "path": "bamboost.common._mock_mpi",
          "filepath": "/home/florez/work/code/bamboost/bamboost/common/_mock_mpi.py",
          "description": null,
          "docstring": [],
          "attributes": [],
          "modules": {},
          "classes": {
            "MockMPI": {
              "name": "MockMPI",
              "path": "bamboost.common._mock_mpi.MockMPI",
              "description": "Mock class for `mpi4py.MPI` to be used when MPI is not available or usage\nnot desired. Not importing MPI increases launch speed significantly, which\nis important for CLI applications.",
              "parameters": [],
              "attributes": [
                {
                  "name": "COMM_WORLD",
                  "annotation": null,
                  "description": "Mock object for `mpi4py.MPI.COMM_WORLD`",
                  "value": "Comm()"
                },
                {
                  "name": "COMM_SELF",
                  "annotation": null,
                  "description": "Mock object for `mpi4py.MPI.COMM_SELF`",
                  "value": "Comm()"
                },
                {
                  "name": "COMM_NULL",
                  "annotation": null,
                  "description": "Mock object for `mpi4py.MPI.COMM_NULL`",
                  "value": "Comm()"
                }
              ],
              "docstring": [],
              "functions": {},
              "source": "class MockMPI:\n    \"\"\"\n    Mock class for `mpi4py.MPI` to be used when MPI is not available or usage\n    not desired. Not importing MPI increases launch speed significantly, which\n    is important for CLI applications.\n\n    Attributes:\n        Comm: Mock class for `mpi4py.MPI.Comm`\n        COMM_WORLD: Mock object for `mpi4py.MPI.COMM_WORLD`\n        COMM_SELF: Mock object for `mpi4py.MPI.COMM_SELF`\n        COMM_NULL: Mock object for `mpi4py.MPI.COMM_NULL`\n    \"\"\"\n\n    class Comm:\n        def __init__(self):\n            self.size = 1\n            self.rank = 0\n            self.comm = None\n            self.is_mpi = False\n            self.is_master = True\n\n        def barrier(self):\n            pass\n\n        def finalize(self):\n            pass\n\n        def bcast(self, data, root=0):\n            return data\n\n        def scatter(self, data, root=0):\n            return data\n\n        def gather(self, data, root=0):\n            return data\n\n        def allgather(self, data):\n            return [data]\n\n        def allreduce(self, data, op):\n            return data\n\n        def reduce(self, data, op, root=0):\n            return data\n\n        def send(self, data, dest, tag=0):\n            pass\n\n        def recv(self, source, tag=0):\n            return None\n\n        def recv_any_source(self, tag=0):\n            return None\n\n        def sendrecv(self, send_data, dest, tag=0):\n            return None\n\n        def sendrecv_replace(self, data, dest, tag=0):\n            return data\n\n        def get_processor_name(self):\n            return \"localhost\"\n\n        def get_version(self):\n            return \"0.0.0\"\n\n        def get_library_version(self):\n            return \"0.0.0\"\n\n        def get_error_string(self, errorcode):\n            return \"No error\"\n\n        def get_exception_class(self):\n            return Exception\n\n        def get_exception_string(self, errorcode):\n            return \"No error\"\n\n        def get_count(self, status, datatype):\n            return 0\n\n        def get_status(self, request):\n            return None\n\n        def get_source(self, status):\n            return 0\n\n        def get_tag(self, status):\n            return 0\n\n        def get_elements(self, status):\n            return 0\n\n        def get_bytes(self, status):\n            return 0\n\n        def get_cancelled(self, status):\n            return False\n\n        def get_topo(self):\n            return None\n\n        def get_cart(self):\n            return None\n\n        def get_dims(self):\n            return None\n\n        def get_coords(self):\n            return None\n\n        def get_rank(self):\n            return 0\n\n        def get_size(self):\n            return 1\n\n        def Get_size(self):\n            return 1\n\n    COMM_WORLD = Comm()\n    COMM_SELF = Comm()\n    COMM_NULL = Comm()",
              "inherited_members": {}
            }
          },
          "functions": {}
        },
        "mpi": {
          "name": "mpi",
          "path": "bamboost.common.mpi",
          "filepath": "/home/florez/work/code/bamboost/bamboost/common/mpi.py",
          "description": null,
          "docstring": [],
          "attributes": [
            {
              "name": "log",
              "annotation": null,
              "description": null,
              "value": "BAMBOOST_LOGGER.getChild(__name__.split('.')[-1])"
            },
            {
              "name": "MPIType",
              "annotation": null,
              "description": null,
              "value": "Union"
            },
            {
              "name": "MPI_ON",
              "annotation": null,
              "description": null,
              "value": "config.get('options', {}).get('mpi', True)"
            },
            {
              "name": "ENV_BAMBOOST_MPI",
              "annotation": "bool",
              "description": null,
              "value": "os.environ.get('BAMBOOST_MPI', None)"
            },
            {
              "name": "MPI",
              "annotation": "Union",
              "description": null,
              "value": "_get_mpi_module()"
            }
          ],
          "modules": {},
          "classes": {},
          "functions": {
            "_get_mpi_module": {
              "name": "_get_mpi_module",
              "path": "bamboost.common.mpi._get_mpi_module",
              "signature": "()",
              "description": null,
              "parameters": [],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def _get_mpi_module():\n    if not MPI_ON:\n        return MockMPI\n\n    try:\n        from mpi4py import MPI\n\n        return MPI\n    except ImportError:\n        log.info(\"`mpi4py` unavailable [using a mock MPI module]\")\n        return MockMPI"
            }
          }
        },
        "hdf_pointer": {
          "name": "hdf_pointer",
          "path": "bamboost.common.hdf_pointer",
          "filepath": "/home/florez/work/code/bamboost/bamboost/common/hdf_pointer.py",
          "description": null,
          "docstring": [],
          "attributes": [
            {
              "name": "__all__",
              "annotation": null,
              "description": null,
              "value": "['BasePointer', 'Group', 'MutableGroup', 'Dataset']"
            },
            {
              "name": "log",
              "annotation": null,
              "description": null,
              "value": "bamboost.BAMBOOST_LOGGER.getChild(__name__.split('.')[-1])"
            }
          ],
          "modules": {},
          "classes": {
            "BasePointer": {
              "name": "BasePointer",
              "path": "bamboost.common.hdf_pointer.BasePointer",
              "description": "Pointer to a location in an hdf5 file. The constructor takes a\n:class:`~.file_handler.FileHandler` and the in-file path to the object.\nThe base class represents a generic group in the file",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "file_handler",
                  "annotation": "FileHandler",
                  "description": [
                    {
                      "kind": "text",
                      "value": "file this belongs to"
                    }
                  ]
                },
                {
                  "name": "path_to_data",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "infile path to object"
                    }
                  ]
                }
              ],
              "attributes": [
                {
                  "name": "_file",
                  "annotation": null,
                  "description": null,
                  "value": "file_handler"
                },
                {
                  "name": "path_to_data",
                  "annotation": null,
                  "description": null,
                  "value": "path_to_data"
                },
                {
                  "name": "obj",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "__repr__",
                  "annotation": null,
                  "description": null,
                  "value": "__str__"
                },
                {
                  "name": "attrs",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "docstring": [],
              "functions": {
                "new_pointer": {
                  "name": "new_pointer",
                  "path": "bamboost.common.hdf_pointer.BasePointer.new_pointer",
                  "signature": "(cls, file_handler, path_to_data) -> bamboost.common.hdf_pointer.BasePointer",
                  "description": "Returns a new pointer object.",
                  "parameters": [
                    {
                      "name": "cls",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "file_handler",
                      "annotation": "FileHandler",
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "path_to_data",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "bamboost.common.hdf_pointer.BasePointer",
                    "description": null
                  },
                  "docstring": [],
                  "source": "@classmethod\ndef new_pointer(cls, file_handler: FileHandler, path_to_data: str) -> BasePointer:\n    \"\"\"Returns a new pointer object.\"\"\"\n    with file_handler(\"r\") as f:\n        obj = f.file_object[path_to_data]\n        if isinstance(obj, h5py.Group):\n            if issubclass(cls, Group):\n                return cls(file_handler, path_to_data)\n            else:\n                return Group(file_handler, path_to_data)\n        elif isinstance(obj, h5py.Dataset):\n            return Dataset(file_handler, path_to_data)\n        else:\n            return BasePointer(file_handler, path_to_data)"
                },
                "__init__": {
                  "name": "__init__",
                  "path": "bamboost.common.hdf_pointer.BasePointer.__init__",
                  "signature": "(self, file_handler, path_to_data) -> None",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "file_handler",
                      "annotation": "FileHandler",
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "path_to_data",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def __init__(self, file_handler: FileHandler, path_to_data: str) -> None:\n    self._file = file_handler\n    self.path_to_data = path_to_data"
                },
                "__str__": {
                  "name": "__str__",
                  "path": "bamboost.common.hdf_pointer.BasePointer.__str__",
                  "signature": "(self) -> str",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "str",
                    "description": null
                  },
                  "docstring": [],
                  "source": "@with_file_open(\"r\")\ndef __str__(self) -> str:\n    try:\n        return (\n            f\"{self.__class__} pointing to: \"\n            + self._file[self.path_to_data].__repr__()\n        )\n    except KeyError:\n        return f\"{self.__class__} pointing to: {self.path_to_data} (No data at that location!)\""
                },
                "__getattr__": {
                  "name": "__getattr__",
                  "path": "bamboost.common.hdf_pointer.BasePointer.__getattr__",
                  "signature": "(self, __name) -> typing.Any",
                  "description": "Any attribute request is sent to the h5py object the pointer points to.",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "__name",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "typing.Any",
                    "description": null
                  },
                  "docstring": [],
                  "source": "@with_file_open(\"r\")\ndef __getattr__(self, __name: str) -> Any:\n    \"\"\"Any attribute request is sent to the h5py object the pointer points to.\"\"\"\n    if hasattr(self.obj, __name):\n        return self.obj.__getattribute__(__name)\n    return self.__getattribute__(__name)"
                },
                "__getitem__": {
                  "name": "__getitem__",
                  "path": "bamboost.common.hdf_pointer.BasePointer.__getitem__",
                  "signature": "(self, key)",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "key",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": null,
                    "description": null
                  },
                  "docstring": [],
                  "source": "@with_file_open(\"r\")\ndef __getitem__(self, key):\n    new_path = f\"{self.path_to_data}/{key}\"\n    return self.new_pointer(self._file, new_path)"
                }
              },
              "source": "class BasePointer:\n    \"\"\"Pointer to a location in an hdf5 file. The constructor takes a\n    :class:`~.file_handler.FileHandler` and the in-file path to the object.\n    The base class represents a generic group in the file\n\n    Args:\n        file_handler: file this belongs to\n        path_to_data: infile path to object\n    \"\"\"\n\n    @classmethod\n    def new_pointer(cls, file_handler: FileHandler, path_to_data: str) -> BasePointer:\n        \"\"\"Returns a new pointer object.\"\"\"\n        with file_handler(\"r\") as f:\n            obj = f.file_object[path_to_data]\n            if isinstance(obj, h5py.Group):\n                if issubclass(cls, Group):\n                    return cls(file_handler, path_to_data)\n                else:\n                    return Group(file_handler, path_to_data)\n            elif isinstance(obj, h5py.Dataset):\n                return Dataset(file_handler, path_to_data)\n            else:\n                return BasePointer(file_handler, path_to_data)\n\n    def __init__(self, file_handler: FileHandler, path_to_data: str) -> None:\n        self._file = file_handler\n        self.path_to_data = path_to_data\n\n    @property\n    def obj(self):\n        \"\"\"The object this BasePointer points to. File needs to be open for access.\"\"\"\n        return self._file[self.path_to_data]\n\n    @with_file_open(\"r\")\n    def __str__(self) -> str:\n        try:\n            return (\n                f\"{self.__class__} pointing to: \"\n                + self._file[self.path_to_data].__repr__()\n            )\n        except KeyError:\n            return f\"{self.__class__} pointing to: {self.path_to_data} (No data at that location!)\"\n\n    __repr__ = __str__\n\n    @with_file_open(\"r\")\n    def __getattr__(self, __name: str) -> Any:\n        \"\"\"Any attribute request is sent to the h5py object the pointer points to.\"\"\"\n        if hasattr(self.obj, __name):\n            return self.obj.__getattribute__(__name)\n        return self.__getattribute__(__name)\n\n    @with_file_open(\"r\")\n    def __getitem__(self, key):\n        new_path = f\"{self.path_to_data}/{key}\"\n        return self.new_pointer(self._file, new_path)\n\n    @property\n    @with_file_open()\n    def attrs(self):\n        return dict(self.obj.attrs)",
              "inherited_members": {}
            },
            "Group": {
              "name": "Group",
              "path": "bamboost.common.hdf_pointer.Group",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "file_handler",
                  "annotation": "FileHandler",
                  "description": null,
                  "value": null
                },
                {
                  "name": "path_to_data",
                  "annotation": "str",
                  "description": null,
                  "value": null
                }
              ],
              "attributes": [],
              "docstring": [],
              "functions": {
                "__init__": {
                  "name": "__init__",
                  "path": "bamboost.common.hdf_pointer.Group.__init__",
                  "signature": "(self, file_handler, path_to_data) -> None",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "file_handler",
                      "annotation": "FileHandler",
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "path_to_data",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def __init__(self, file_handler: FileHandler, path_to_data: str) -> None:\n    super().__init__(file_handler, path_to_data)"
                },
                "_ipython_key_completions_": {
                  "name": "_ipython_key_completions_",
                  "path": "bamboost.common.hdf_pointer.Group._ipython_key_completions_",
                  "signature": "(self)",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": null,
                    "description": null
                  },
                  "docstring": [],
                  "source": "def _ipython_key_completions_(self):\n    return self.keys()"
                },
                "__iter__": {
                  "name": "__iter__",
                  "path": "bamboost.common.hdf_pointer.Group.__iter__",
                  "signature": "(self)",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": null,
                    "description": null
                  },
                  "docstring": [],
                  "source": "def __iter__(self):\n    for key in self.keys():\n        yield self.__getitem__(key)"
                },
                "keys": {
                  "name": "keys",
                  "path": "bamboost.common.hdf_pointer.Group.keys",
                  "signature": "(self) -> set",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "set",
                    "description": null
                  },
                  "docstring": [],
                  "source": "@with_file_open(\"r\")\ndef keys(self) -> set:\n    return set(self.obj.keys())"
                },
                "groups": {
                  "name": "groups",
                  "path": "bamboost.common.hdf_pointer.Group.groups",
                  "signature": "(self) -> set",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "set",
                    "description": null
                  },
                  "docstring": [],
                  "source": "@with_file_open(\"r\")\ndef groups(self) -> set:\n    return {key for key in self.keys() if isinstance(self.obj[key], h5py.Group)}"
                },
                "datasets": {
                  "name": "datasets",
                  "path": "bamboost.common.hdf_pointer.Group.datasets",
                  "signature": "(self) -> set",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "set",
                    "description": null
                  },
                  "docstring": [],
                  "source": "@with_file_open(\"r\")\ndef datasets(self) -> set:\n    return {key for key in self.keys() if isinstance(self.obj[key], h5py.Dataset)}"
                },
                "extract_attrs": {
                  "name": "extract_attrs",
                  "path": "bamboost.common.hdf_pointer.Group.extract_attrs",
                  "signature": "(self, variant = 'all') -> dict",
                  "description": "Extract the attributes of all members of the group.",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "variant",
                      "annotation": "Literal",
                      "description": [
                        {
                          "kind": "text",
                          "value": "one of 'group', 'dataset', 'all'"
                        }
                      ],
                      "value": "'all'"
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "dict",
                    "description": null
                  },
                  "docstring": [],
                  "source": "@with_file_open(\"r\")\ndef extract_attrs(\n    self, variant: Literal[\"group\", \"dataset\", \"all\"] = \"all\"\n) -> dict:\n    \"\"\"Extract the attributes of all members of the group.\n\n    Args:\n        variant: one of 'group', 'dataset', 'all'\n    \"\"\"\n    if variant == \"group\":\n        keys = self.groups()\n    elif variant == \"dataset\":\n        keys = self.datasets()\n    elif variant == \"all\":\n        keys = self.keys()\n    else:\n        raise ValueError(\"variant must be one of 'group', 'dataset', 'all'\")\n\n    attrs = {}\n    for key in keys:\n        attrs[key] = dict(self.obj[key].attrs)\n    return attrs"
                },
                "_repr_html_": {
                  "name": "_repr_html_",
                  "path": "bamboost.common.hdf_pointer.Group._repr_html_",
                  "signature": "(self)",
                  "description": "Repr showing the content of the group.",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": null,
                    "description": null
                  },
                  "docstring": [],
                  "source": "@with_file_open(\"r\")\ndef _repr_html_(self):\n    \"\"\"Repr showing the content of the group.\"\"\"\n    html_string = pkgutil.get_data(\n        bamboost.__name__, \"html/hdf5_group.html\"\n    ).decode()\n    icon = pkgutil.get_data(bamboost.__name__, \"html/icon.txt\").decode()\n\n    attrs_html = \"\"\n    for key, val in self.attrs.items():\n        attrs_html += f\"\"\"\n        <tr>\n            <td>{key}</td>\n            <td>{val}</td>\n        </tr>\n        \"\"\"\n    groups_html = \"\"\n    for key in self.groups():\n        groups_html += f\"\"\"\n        <tr>\n            <td>{key}</td>\n            <td>{len(self.obj[key])}</td>\n        </tr>\n        \"\"\"\n    ds_html = \"\"\n    for key in self.datasets():\n        obj = self.obj[key]\n        ds_html += f\"\"\"\n        <tr>\n            <td>{key}</td>\n            <td>{obj.dtype}</td>\n            <td>{obj.shape}</td>\n        </tr>\n        \"\"\"\n    path = self.path_to_data\n    if not path.startswith(\"/\"):\n        path = f\"/{path}\"\n    return (\n        html_string.replace(\"$NAME\", path)\n        .replace(\"$UID\", self._file.simulation_uid)\n        .replace(\"$ICON\", icon)\n        .replace(\"$attrs\", attrs_html)\n        .replace(\"$groups\", groups_html)\n        .replace(\"$datasets\", ds_html)\n        .replace(\"$version\", bamboost.__version__)\n    )"
                }
              },
              "source": "class Group(BasePointer):\n    def __init__(self, file_handler: FileHandler, path_to_data: str) -> None:\n        super().__init__(file_handler, path_to_data)\n\n    def _ipython_key_completions_(self):\n        return self.keys()\n\n    def __iter__(self):\n        for key in self.keys():\n            yield self.__getitem__(key)\n\n    @with_file_open(\"r\")\n    def keys(self) -> set:\n        return set(self.obj.keys())\n\n    @with_file_open(\"r\")\n    def groups(self) -> set:\n        return {key for key in self.keys() if isinstance(self.obj[key], h5py.Group)}\n\n    @with_file_open(\"r\")\n    def datasets(self) -> set:\n        return {key for key in self.keys() if isinstance(self.obj[key], h5py.Dataset)}\n\n    @with_file_open(\"r\")\n    def extract_attrs(\n        self, variant: Literal[\"group\", \"dataset\", \"all\"] = \"all\"\n    ) -> dict:\n        \"\"\"Extract the attributes of all members of the group.\n\n        Args:\n            variant: one of 'group', 'dataset', 'all'\n        \"\"\"\n        if variant == \"group\":\n            keys = self.groups()\n        elif variant == \"dataset\":\n            keys = self.datasets()\n        elif variant == \"all\":\n            keys = self.keys()\n        else:\n            raise ValueError(\"variant must be one of 'group', 'dataset', 'all'\")\n\n        attrs = {}\n        for key in keys:\n            attrs[key] = dict(self.obj[key].attrs)\n        return attrs\n\n    @with_file_open(\"r\")\n    def _repr_html_(self):\n        \"\"\"Repr showing the content of the group.\"\"\"\n        html_string = pkgutil.get_data(\n            bamboost.__name__, \"html/hdf5_group.html\"\n        ).decode()\n        icon = pkgutil.get_data(bamboost.__name__, \"html/icon.txt\").decode()\n\n        attrs_html = \"\"\n        for key, val in self.attrs.items():\n            attrs_html += f\"\"\"\n            <tr>\n                <td>{key}</td>\n                <td>{val}</td>\n            </tr>\n            \"\"\"\n        groups_html = \"\"\n        for key in self.groups():\n            groups_html += f\"\"\"\n            <tr>\n                <td>{key}</td>\n                <td>{len(self.obj[key])}</td>\n            </tr>\n            \"\"\"\n        ds_html = \"\"\n        for key in self.datasets():\n            obj = self.obj[key]\n            ds_html += f\"\"\"\n            <tr>\n                <td>{key}</td>\n                <td>{obj.dtype}</td>\n                <td>{obj.shape}</td>\n            </tr>\n            \"\"\"\n        path = self.path_to_data\n        if not path.startswith(\"/\"):\n            path = f\"/{path}\"\n        return (\n            html_string.replace(\"$NAME\", path)\n            .replace(\"$UID\", self._file.simulation_uid)\n            .replace(\"$ICON\", icon)\n            .replace(\"$attrs\", attrs_html)\n            .replace(\"$groups\", groups_html)\n            .replace(\"$datasets\", ds_html)\n            .replace(\"$version\", bamboost.__version__)\n        )",
              "inherited_members": {
                "bamboost.common.hdf_pointer.BasePointer": [
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.new_pointer"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer._file"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.path_to_data"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.obj"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__str__"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__repr__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__getattr__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__getitem__"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.attrs"
                  }
                ]
              }
            },
            "MutableGroup": {
              "name": "MutableGroup",
              "path": "bamboost.common.hdf_pointer.MutableGroup",
              "description": "Used for the `userdata` group.",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "file_handler",
                  "annotation": "FileHandler",
                  "description": null,
                  "value": null
                },
                {
                  "name": "path_to_data",
                  "annotation": "str",
                  "description": null,
                  "value": null
                }
              ],
              "attributes": [],
              "docstring": [],
              "functions": {
                "__init__": {
                  "name": "__init__",
                  "path": "bamboost.common.hdf_pointer.MutableGroup.__init__",
                  "signature": "(self, file_handler, path_to_data) -> None",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "file_handler",
                      "annotation": "FileHandler",
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "path_to_data",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def __init__(self, file_handler: FileHandler, path_to_data: str) -> None:\n    super().__init__(file_handler, path_to_data)\n    # Create group if it doesn't exist\n    with self._file(\"a\", driver=\"mpio\"):\n        self._file.file_object.require_group(path_to_data)"
                },
                "_ipython_key_completions_": {
                  "name": "_ipython_key_completions_",
                  "path": "bamboost.common.hdf_pointer.MutableGroup._ipython_key_completions_",
                  "signature": "(self)",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": null,
                    "description": null
                  },
                  "docstring": [],
                  "source": "def _ipython_key_completions_(self):\n    return self.keys().union(set(self.attrs.keys()))"
                },
                "__getitem__": {
                  "name": "__getitem__",
                  "path": "bamboost.common.hdf_pointer.MutableGroup.__getitem__",
                  "signature": "(self, key) -> typing.Any",
                  "description": "Used to access datasets (:class:`~bamboost.common.hdf_pointer.Dataset`)\nor groups inside this group (:class:`~bamboost.common.hdf_pointer.MutableGroup`)",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "key",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "typing.Any",
                    "description": null
                  },
                  "docstring": [],
                  "source": "@with_file_open(\"r\")\ndef __getitem__(self, key) -> Any:\n    \"\"\"Used to access datasets (:class:`~bamboost.common.hdf_pointer.Dataset`)\n    or groups inside this group (:class:`~bamboost.common.hdf_pointer.MutableGroup`)\n    \"\"\"\n    try:\n        return super().__getitem__(key)\n    except KeyError:\n        pass\n\n    try:\n        return self.obj.attrs[key]\n    except KeyError:\n        pass\n\n    return super().__getitem__(key)"
                },
                "__setitem__": {
                  "name": "__setitem__",
                  "path": "bamboost.common.hdf_pointer.MutableGroup.__setitem__",
                  "signature": "(self, key, newvalue)",
                  "description": "Used to set an attribute.\nWill be written as an attribute to the group.",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "key",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "newvalue",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": null,
                    "description": null
                  },
                  "docstring": [],
                  "source": "def __setitem__(self, key, newvalue):\n    \"\"\"Used to set an attribute.\n    Will be written as an attribute to the group.\n    \"\"\"\n    if isinstance(newvalue, str) or not isinstance(newvalue, Iterable):\n        self.update_attrs({key: newvalue})\n    else:\n        self.add_dataset(key, np.array(newvalue))"
                },
                "__delitem__": {
                  "name": "__delitem__",
                  "path": "bamboost.common.hdf_pointer.MutableGroup.__delitem__",
                  "signature": "(self, key) -> None",
                  "description": "Deletes an item.",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "key",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "@with_file_open(\"a\")\ndef __delitem__(self, key) -> None:\n    \"\"\"Deletes an item.\"\"\"\n    if key in self.attrs.keys():\n        del self.obj.attrs[key]\n    else:\n        del self.obj[key]"
                },
                "update_attrs": {
                  "name": "update_attrs",
                  "path": "bamboost.common.hdf_pointer.MutableGroup.update_attrs",
                  "signature": "(self, attrs) -> None",
                  "description": "Update the attributes of the group.",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "attrs",
                      "annotation": "dict",
                      "description": [
                        {
                          "kind": "text",
                          "value": "the dictionary to write as attributes"
                        }
                      ]
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "@with_file_open(\"a\")\ndef update_attrs(self, attrs: dict) -> None:\n    \"\"\"Update the attributes of the group.\n\n    Args:\n        attrs: the dictionary to write as attributes\n    \"\"\"\n    self.obj.attrs.update(attrs)"
                },
                "add_dataset": {
                  "name": "add_dataset",
                  "path": "bamboost.common.hdf_pointer.MutableGroup.add_dataset",
                  "signature": "(self, name, vector, attrs = None, dtype = None) -> None",
                  "description": "Add a dataset to the group. Error is thrown if attempting to overwrite\nwith different shape than before. If same shape, data is overwritten\n(this is inherited from h5py -> require_dataset)",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "name",
                      "annotation": "str",
                      "description": [
                        {
                          "kind": "text",
                          "value": "Name for the dataset"
                        }
                      ]
                    },
                    {
                      "name": "vector",
                      "annotation": "np.ndarray",
                      "description": [
                        {
                          "kind": "text",
                          "value": "Data to write (max 2d)"
                        }
                      ]
                    },
                    {
                      "name": "attrs",
                      "annotation": "dict",
                      "description": [
                        {
                          "kind": "text",
                          "value": "Optional. Attributes of dataset."
                        }
                      ],
                      "value": "None"
                    },
                    {
                      "name": "dtype",
                      "annotation": "str",
                      "description": [
                        {
                          "kind": "text",
                          "value": "Optional. dtype of dataset. If not specified, uses dtype of inpyt array"
                        }
                      ],
                      "value": "None"
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def add_dataset(\n    self, name: str, vector: np.ndarray, attrs: dict = None, dtype: str = None\n) -> None:\n    \"\"\"Add a dataset to the group. Error is thrown if attempting to overwrite\n    with different shape than before. If same shape, data is overwritten\n    (this is inherited from h5py -> require_dataset)\n\n    Args:\n        name: Name for the dataset\n        vector: Data to write (max 2d)\n        attrs: Optional. Attributes of dataset.\n        dtype: Optional. dtype of dataset. If not specified, uses dtype of inpyt array\n    \"\"\"\n    if attrs is None:\n        attrs = {}\n    length_local = vector.shape[0]\n    length_p = np.array(self._file._comm.allgather(length_local))\n    length = np.sum(length_p)\n    dim = vector.shape[1:]\n    vec_shape = length, *dim\n\n    ranks = np.array([i for i in range(self._file._comm.size)])\n    idx_start = np.sum(length_p[ranks < self._file._comm.rank])\n    idx_end = idx_start + length_local\n\n    with self._file(\"a\", driver=\"mpio\"):\n        dataset = self.obj.require_dataset(\n            name, shape=vec_shape, dtype=dtype if dtype else vector.dtype\n        )\n        dataset[idx_start:idx_end] = vector\n        for key, item in attrs.items():\n            dataset.attrs[key] = item\n\n    log.info(f\"Written {name} as userdata to {self._file.file_name}...\")"
                },
                "require_group": {
                  "name": "require_group",
                  "path": "bamboost.common.hdf_pointer.MutableGroup.require_group",
                  "signature": "(self, name) -> bamboost.common.hdf_pointer.MutableGroup",
                  "description": "Add a new group to the current group. If exists, return existing.",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "name",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "bamboost.common.hdf_pointer.MutableGroup",
                    "description": "class:`~bamboost.hdf_pointer.Group`"
                  },
                  "docstring": [],
                  "source": "def require_group(self, name: str) -> MutableGroup:\n    \"\"\"Add a new group to the current group. If exists, return existing.\n\n    Returns:\n        :class:`~bamboost.hdf_pointer.Group`\n    \"\"\"\n    return MutableGroup(self._file, f\"{self.path_to_data}/{name}\")"
                }
              },
              "source": "class MutableGroup(Group):\n    \"\"\"Used for the `userdata` group.\"\"\"\n\n    def __init__(self, file_handler: FileHandler, path_to_data: str) -> None:\n        super().__init__(file_handler, path_to_data)\n        # Create group if it doesn't exist\n        with self._file(\"a\", driver=\"mpio\"):\n            self._file.file_object.require_group(path_to_data)\n\n    def _ipython_key_completions_(self):\n        return self.keys().union(set(self.attrs.keys()))\n\n    @with_file_open(\"r\")\n    def __getitem__(self, key) -> Any:\n        \"\"\"Used to access datasets (:class:`~bamboost.common.hdf_pointer.Dataset`)\n        or groups inside this group (:class:`~bamboost.common.hdf_pointer.MutableGroup`)\n        \"\"\"\n        try:\n            return super().__getitem__(key)\n        except KeyError:\n            pass\n\n        try:\n            return self.obj.attrs[key]\n        except KeyError:\n            pass\n\n        return super().__getitem__(key)\n\n    def __setitem__(self, key, newvalue):\n        \"\"\"Used to set an attribute.\n        Will be written as an attribute to the group.\n        \"\"\"\n        if isinstance(newvalue, str) or not isinstance(newvalue, Iterable):\n            self.update_attrs({key: newvalue})\n        else:\n            self.add_dataset(key, np.array(newvalue))\n\n    @with_file_open(\"a\")\n    def __delitem__(self, key) -> None:\n        \"\"\"Deletes an item.\"\"\"\n        if key in self.attrs.keys():\n            del self.obj.attrs[key]\n        else:\n            del self.obj[key]\n\n    @with_file_open(\"a\")\n    def update_attrs(self, attrs: dict) -> None:\n        \"\"\"Update the attributes of the group.\n\n        Args:\n            attrs: the dictionary to write as attributes\n        \"\"\"\n        self.obj.attrs.update(attrs)\n\n    def add_dataset(\n        self, name: str, vector: np.ndarray, attrs: dict = None, dtype: str = None\n    ) -> None:\n        \"\"\"Add a dataset to the group. Error is thrown if attempting to overwrite\n        with different shape than before. If same shape, data is overwritten\n        (this is inherited from h5py -> require_dataset)\n\n        Args:\n            name: Name for the dataset\n            vector: Data to write (max 2d)\n            attrs: Optional. Attributes of dataset.\n            dtype: Optional. dtype of dataset. If not specified, uses dtype of inpyt array\n        \"\"\"\n        if attrs is None:\n            attrs = {}\n        length_local = vector.shape[0]\n        length_p = np.array(self._file._comm.allgather(length_local))\n        length = np.sum(length_p)\n        dim = vector.shape[1:]\n        vec_shape = length, *dim\n\n        ranks = np.array([i for i in range(self._file._comm.size)])\n        idx_start = np.sum(length_p[ranks < self._file._comm.rank])\n        idx_end = idx_start + length_local\n\n        with self._file(\"a\", driver=\"mpio\"):\n            dataset = self.obj.require_dataset(\n                name, shape=vec_shape, dtype=dtype if dtype else vector.dtype\n            )\n            dataset[idx_start:idx_end] = vector\n            for key, item in attrs.items():\n                dataset.attrs[key] = item\n\n        log.info(f\"Written {name} as userdata to {self._file.file_name}...\")\n\n    def require_group(self, name: str) -> MutableGroup:\n        \"\"\"Add a new group to the current group. If exists, return existing.\n\n        Returns:\n            :class:`~bamboost.hdf_pointer.Group`\n        \"\"\"\n        return MutableGroup(self._file, f\"{self.path_to_data}/{name}\")",
              "inherited_members": {
                "bamboost.common.hdf_pointer.BasePointer": [
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.new_pointer"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer._file"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.path_to_data"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.obj"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__str__"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__repr__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__getattr__"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.attrs"
                  }
                ],
                "bamboost.common.hdf_pointer.Group": [
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.__iter__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.keys"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.groups"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.datasets"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group.extract_attrs"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.Group._repr_html_"
                  }
                ]
              }
            },
            "Dataset": {
              "name": "Dataset",
              "path": "bamboost.common.hdf_pointer.Dataset",
              "description": null,
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "file_handler",
                  "annotation": "FileHandler",
                  "description": null,
                  "value": null
                },
                {
                  "name": "path_to_data",
                  "annotation": "str",
                  "description": null,
                  "value": null
                }
              ],
              "attributes": [
                {
                  "name": "attrs",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "shape",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "dtype",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "docstring": [],
              "functions": {
                "__init__": {
                  "name": "__init__",
                  "path": "bamboost.common.hdf_pointer.Dataset.__init__",
                  "signature": "(self, file_handler, path_to_data) -> None",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "file_handler",
                      "annotation": "FileHandler",
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "path_to_data",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def __init__(self, file_handler: FileHandler, path_to_data: str) -> None:\n    super().__init__(file_handler, path_to_data)"
                },
                "__getitem__": {
                  "name": "__getitem__",
                  "path": "bamboost.common.hdf_pointer.Dataset.__getitem__",
                  "signature": "(self, slice)",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "slice",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": null,
                    "description": null
                  },
                  "docstring": [],
                  "source": "@with_file_open(\"r\")\ndef __getitem__(self, slice):\n    return self.obj[slice]"
                }
              },
              "source": "class Dataset(BasePointer):\n    def __init__(self, file_handler: FileHandler, path_to_data: str) -> None:\n        super().__init__(file_handler, path_to_data)\n\n    @with_file_open(\"r\")\n    def __getitem__(self, slice):\n        return self.obj[slice]\n\n    @property\n    @with_file_open()\n    def attrs(self):\n        return dict(self.obj.attrs)\n\n    @property\n    @with_file_open()\n    def shape(self):\n        return self.obj.shape\n\n    @property\n    @with_file_open()\n    def dtype(self):\n        return self.obj.dtype",
              "inherited_members": {
                "bamboost.common.hdf_pointer.BasePointer": [
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.new_pointer"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer._file"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.path_to_data"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.obj"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__str__"
                  },
                  {
                    "kind": "attribute",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__repr__"
                  },
                  {
                    "kind": "function",
                    "path": "bamboost.common.hdf_pointer.BasePointer.__getattr__"
                  }
                ]
              }
            }
          },
          "functions": {}
        },
        "utilities": {
          "name": "utilities",
          "path": "bamboost.common.utilities",
          "filepath": "/home/florez/work/code/bamboost/bamboost/common/utilities.py",
          "description": "Utility functions used by bamboost.",
          "docstring": [],
          "attributes": [
            {
              "name": "__all__",
              "annotation": null,
              "description": null,
              "value": "['flatten_dict', 'unflatten_dict', 'tree', 'h5_tree', 'show_differences', 'to_camel_case']"
            },
            {
              "name": "space",
              "annotation": null,
              "description": null,
              "value": "'    '"
            },
            {
              "name": "branch",
              "annotation": null,
              "description": null,
              "value": "'\u2502   '"
            },
            {
              "name": "tee",
              "annotation": null,
              "description": null,
              "value": "'\u251c\u2500\u2500 '"
            },
            {
              "name": "last",
              "annotation": null,
              "description": null,
              "value": "'\u2514\u2500\u2500 '"
            },
            {
              "name": "JobArguments",
              "annotation": null,
              "description": null,
              "value": "NamedTuple('JobArguments', [('db_path', Path), ('name', str), ('submit', bool)])"
            },
            {
              "name": "ScriptArguments",
              "annotation": null,
              "description": null,
              "value": "NamedTuple('ScriptArguments', [('simulation', str)])"
            }
          ],
          "modules": {},
          "classes": {},
          "functions": {
            "flatten_dict": {
              "name": "flatten_dict",
              "path": "bamboost.common.utilities.flatten_dict",
              "signature": "(dictionary, parent_key = '', seperator = '.')",
              "description": null,
              "parameters": [
                {
                  "name": "dictionary",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "parent_key",
                  "annotation": null,
                  "description": null,
                  "value": "''"
                },
                {
                  "name": "seperator",
                  "annotation": null,
                  "description": null,
                  "value": "'.'"
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def flatten_dict(dictionary, parent_key=\"\", seperator=\".\"):\n    items = []\n    for key, value in dictionary.items():\n        new_key = parent_key + seperator + key if parent_key else key\n        if isinstance(value, MutableMapping):\n            items.extend(flatten_dict(value, new_key, seperator=seperator).items())\n        else:\n            items.append((new_key, value))\n    return dict(items)"
            },
            "unflatten_dict": {
              "name": "unflatten_dict",
              "path": "bamboost.common.utilities.unflatten_dict",
              "signature": "(dictionary, seperator = '.')",
              "description": null,
              "parameters": [
                {
                  "name": "dictionary",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "seperator",
                  "annotation": null,
                  "description": null,
                  "value": "'.'"
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def unflatten_dict(dictionary, seperator=\".\"):\n    new_dict = dict()\n    for key, value in dictionary.items():\n        parts = key.split(seperator)\n        d = new_dict\n        for part in parts[:-1]:\n            if part not in d:\n                d[part] = dict()\n            d = d[part]\n        d[parts[-1]] = value\n    return new_dict"
            },
            "tree": {
              "name": "tree",
              "path": "bamboost.common.utilities.tree",
              "signature": "(dir_path, level = -1, limit_to_directories = False, length_limit = 1000)",
              "description": "Given a directory Path object print a visual tree structure",
              "parameters": [
                {
                  "name": "dir_path",
                  "annotation": "Path",
                  "description": null,
                  "value": null
                },
                {
                  "name": "level",
                  "annotation": "int",
                  "description": null,
                  "value": "-1"
                },
                {
                  "name": "limit_to_directories",
                  "annotation": "bool",
                  "description": null,
                  "value": "False"
                },
                {
                  "name": "length_limit",
                  "annotation": "int",
                  "description": null,
                  "value": "1000"
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def tree(\n    dir_path: Path,\n    level: int = -1,\n    limit_to_directories: bool = False,\n    length_limit: int = 1000,\n):\n    \"\"\"Given a directory Path object print a visual tree structure\"\"\"\n    dir_path = Path(dir_path)  # accept string coerceable to Path\n    files = 0\n    directories = 0\n    folder_symbol = \"\\U00002b57 \"\n\n    def inner(dir_path: Path, prefix: str = \"\", level=-1):\n        nonlocal files, directories\n        if not level:\n            return  # 0, stop iterating\n        if limit_to_directories:\n            contents = [d for d in dir_path.iterdir() if d.is_dir()]\n        else:\n            contents = list(dir_path.iterdir())\n        pointers = [tee] * (len(contents) - 1) + [last]\n        for pointer, path in zip(pointers, contents):\n            if path.is_dir():\n                yield prefix + pointer + \"\\U000025cc \" + path.name\n                directories += 1\n                extension = branch if pointer == tee else space\n                yield from inner(path, prefix=prefix + extension, level=level - 1)\n            elif not limit_to_directories:\n                yield prefix + pointer + path.name\n                files += 1\n\n    tree_string = \"\"\n    tree_string += (folder_symbol + dir_path.name) + \"\\n\"\n    iterator = inner(dir_path, level=level)\n    for line in islice(iterator, length_limit):\n        tree_string += (line) + \"\\n\"\n    if next(iterator, None):\n        tree_string += (f\"... length_limit, {length_limit}, reached, counted:\") + \"\\n\"\n    tree_string += (\n        f\"\\n{directories} directories\" + (f\", {files} files\" if files else \"\")\n    ) + \"\\n\"\n    return tree_string"
            },
            "h5_tree": {
              "name": "h5_tree",
              "path": "bamboost.common.utilities.h5_tree",
              "signature": "(val, pre = '')",
              "description": null,
              "parameters": [
                {
                  "name": "val",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "pre",
                  "annotation": null,
                  "description": null,
                  "value": "''"
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def h5_tree(val, pre=\"\"):\n    items = len(val)\n    for key, val in val.items():\n        items -= 1\n        if items == 0:\n            # the last item\n            if type(val) == h5py._hl.group.Group:\n                print(pre + \"\u2514\u2500\u2500 \" + key)\n                h5_tree(val, pre + \"    \")\n            else:\n                print(pre + \"\u2514\u2500\u2500 \" + key + \" (%d)\" % len(val))\n        else:\n            if type(val) == h5py._hl.group.Group:\n                print(pre + \"\u251c\u2500\u2500 \" + key)\n                h5_tree(val, pre + \"\u2502   \")\n            else:\n                print(pre + \"\u251c\u2500\u2500 \" + key + \" (%d)\" % len(val))"
            },
            "show_differences": {
              "name": "show_differences",
              "path": "bamboost.common.utilities.show_differences",
              "signature": "(df) -> pandas.DataFrame",
              "description": "This function takes a pandas DataFrame as input and returns a modified\nDataFrame that shows only the columns which have differences.\n\nThe function first creates a copy of the input DataFrame to work with. It\nthen iterates over each column in the DataFrame and tries to calculate the\nnumber of unique values in that column. If successful, it adds the column\nname and number of unique values to a list of good results. If there is an\nerror, it attempts to apply json.dumps to the column and then calculate the\nnumber of unique values again. If this is successful, it also adds the\ncolumn name and number of unique values to the list of good results. If\nthere is still an error, it adds the column name and the error to a list of\nerrors.\n\nAfter processing all columns, the function removes any columns that had\nerrors from the DataFrame. It then sets the index of the DataFrame to 'id'\nand filters out any columns that have only one unique value. The modified\nDataFrame is then returned.",
              "parameters": [
                {
                  "name": "df",
                  "annotation": "pd.DataFrame",
                  "description": [
                    {
                      "kind": "text",
                      "value": "The input DataFrame to analyze"
                    }
                  ]
                }
              ],
              "returns": {
                "name": "",
                "annotation": "pandas.DataFrame",
                "description": "pd.DataFrame"
              },
              "docstring": [],
              "source": "def show_differences(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"This function takes a pandas DataFrame as input and returns a modified\n    DataFrame that shows only the columns which have differences.\n\n    The function first creates a copy of the input DataFrame to work with. It\n    then iterates over each column in the DataFrame and tries to calculate the\n    number of unique values in that column. If successful, it adds the column\n    name and number of unique values to a list of good results. If there is an\n    error, it attempts to apply json.dumps to the column and then calculate the\n    number of unique values again. If this is successful, it also adds the\n    column name and number of unique values to the list of good results. If\n    there is still an error, it adds the column name and the error to a list of\n    errors.\n\n    After processing all columns, the function removes any columns that had\n    errors from the DataFrame. It then sets the index of the DataFrame to 'id'\n    and filters out any columns that have only one unique value. The modified\n    DataFrame is then returned.\n\n    Args:\n        df (pd.DataFrame): The input DataFrame to analyze\n\n    Returns:\n        pd.DataFrame\n    \"\"\"\n    import json\n\n    df_diff = df.copy()\n    cols_nunique_good = []\n    cols_nunique_error = []\n    for col in df_diff.columns:\n        try:\n            nunique = df_diff[col].nunique()\n            cols_nunique_good.append((col, nunique))\n        except Exception:\n            try:\n                df_diff[col] = df_diff[col].apply(json.dumps)\n                nunique = df_diff[col].nunique()\n                cols_nunique_good.append((col, nunique))\n            except TypeError as e:\n                cols_nunique_error.append((col, e))\n\n    df_diff = df_diff[\n        df_diff.columns[~df_diff.columns.isin([col for col, _ in cols_nunique_error])]\n    ]\n    try:\n        df_diff.set_index(\"id\", inplace=True)\n    except KeyError:\n        pass\n    df_diff = df_diff.loc[:, (df_diff.nunique() != 1)]\n    df_diff.dropna(axis=1, how=\"all\", inplace=True)\n    return df_diff"
            },
            "to_camel_case": {
              "name": "to_camel_case",
              "path": "bamboost.common.utilities.to_camel_case",
              "signature": "(s) -> str",
              "description": null,
              "parameters": [
                {
                  "name": "s",
                  "annotation": "str",
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": "str",
                "description": null
              },
              "docstring": [],
              "source": "def to_camel_case(s: str) -> str:\n    words = s.split()\n    camel_case = words[0].lower() + \"\".join([word.capitalize() for word in words[1:]])\n    return camel_case"
            },
            "parse_job_arguments": {
              "name": "parse_job_arguments",
              "path": "bamboost.common.utilities.parse_job_arguments",
              "signature": "() -> bamboost.common.utilities.JobArguments",
              "description": "Parse command-line arguments for submitting a job to a bamboost database.",
              "parameters": [],
              "returns": {
                "name": "JobArguments",
                "annotation": "bamboost.common.utilities.JobArguments",
                "description": "A named tuple containing the parsed arguments."
              },
              "docstring": [],
              "source": "def parse_job_arguments() -> JobArguments:\n    \"\"\"Parse command-line arguments for submitting a job to a bamboost database.\n\n    Returns:\n        JobArguments: A named tuple containing the parsed arguments.\n    \"\"\"\n    parser = ArgumentParser(description=\"Submit a job to a bamboost database\")\n\n    # Add the database path argument\n    parser.add_argument(\"db_path\", type=Path, help=\"Path to the bamboost database\")\n    # Add the name argument as optional\n    parser.add_argument(\"name\", type=str, nargs=\"?\", help=\"Name of the simulation\")\n    # Add the submit flag as optional\n    parser.add_argument(\"--submit\", \"-s\", help=\"Submit the job\", action=\"store_true\")\n\n    args = parser.parse_args()\n\n    return JobArguments(db_path=args.db_path, name=args.name, submit=args.submit)"
            },
            "parse_script_arguments": {
              "name": "parse_script_arguments",
              "path": "bamboost.common.utilities.parse_script_arguments",
              "signature": "() -> bamboost.common.utilities.ScriptArguments",
              "description": "Parse command-line arguments for a script using the bamboost system.",
              "parameters": [],
              "returns": {
                "name": "ScriptArguments",
                "annotation": "bamboost.common.utilities.ScriptArguments",
                "description": "A named tuple containing the parsed arguments."
              },
              "docstring": [],
              "source": "def parse_script_arguments() -> ScriptArguments:\n    \"\"\"Parse command-line arguments for a script using the bamboost system.\n\n    Returns:\n        ScriptArguments: A named tuple containing the parsed arguments.\n    \"\"\"\n    parser = ArgumentParser(description=\"Submit a job to a bamboost database\")\n\n    # Add the simulation UID argument\n    parser.add_argument(\n        \"--simulation\", type=str, help=\"UID of the simulation\", required=True\n    )\n\n    args = parser.parse_args()\n\n    return ScriptArguments(simulation=args.simulation)"
            }
          }
        },
        "file_handler": {
          "name": "file_handler",
          "path": "bamboost.common.file_handler",
          "filepath": "/home/florez/work/code/bamboost/bamboost/common/file_handler.py",
          "description": null,
          "docstring": [],
          "attributes": [
            {
              "name": "log",
              "annotation": null,
              "description": null,
              "value": "BAMBOOST_LOGGER.getChild(__name__.split('.')[-1])"
            },
            {
              "name": "__all__",
              "annotation": null,
              "description": null,
              "value": "['open_h5file', 'FileHandler', 'with_file_open', 'capture_key_error', 'HAS_MPIO', 'MPI_ACTIVE', 'FILE_MODE_HIRARCHY']"
            },
            {
              "name": "HAS_MPIO",
              "annotation": null,
              "description": null,
              "value": "'mpio' in h5py.registered_drivers()"
            },
            {
              "name": "MPI_ACTIVE",
              "annotation": null,
              "description": null,
              "value": "mpi"
            },
            {
              "name": "FILE_MODE_HIRARCHY",
              "annotation": null,
              "description": null,
              "value": "{'r': 1, 'r+': 2, 'a': 2, 'w': 3}"
            }
          ],
          "modules": {},
          "classes": {
            "FileHandler": {
              "name": "FileHandler",
              "path": "bamboost.common.file_handler.FileHandler",
              "description": "File handler for an hdf5 file with the purpose of handling opening and closing\nof the file. We use the concept of composition to include an object of this type\nin classes which need access to an hdf5 file (such as the hdf5pointer and Simulation.)",
              "parameters": [
                {
                  "name": "self",
                  "annotation": null,
                  "description": null,
                  "value": null
                },
                {
                  "name": "file_name",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "the path to the file"
                    }
                  ]
                },
                {
                  "name": "_comm",
                  "annotation": "mpi.MPI.Comm",
                  "description": null,
                  "value": "mpi.MPI.COMM_WORLD"
                }
              ],
              "attributes": [
                {
                  "name": "file_object",
                  "annotation": "h5py.File",
                  "description": "the h5py file object (accessible if open)",
                  "value": "None"
                },
                {
                  "name": "file_name",
                  "annotation": null,
                  "description": null,
                  "value": "file_name"
                },
                {
                  "name": "simulation_uid",
                  "annotation": null,
                  "description": null,
                  "value": "os.path.basename(file_name)"
                },
                {
                  "name": "_lock",
                  "annotation": null,
                  "description": "lock is kind of a stack. `open` increases the stack. `close` decreases\nthe stack. file_object is only closed if the stack is at 0. Ensures consecutive\nmethod calls works. Would be a problem if the file is closed after each\nsub-operation.",
                  "value": "0"
                },
                {
                  "name": "_mode",
                  "annotation": null,
                  "description": "file mode",
                  "value": "'r'"
                },
                {
                  "name": "_driver",
                  "annotation": null,
                  "description": "file driver",
                  "value": "None"
                },
                {
                  "name": "_comm",
                  "annotation": null,
                  "description": "MPI communicator",
                  "value": "_comm"
                }
              ],
              "docstring": [],
              "functions": {
                "__init__": {
                  "name": "__init__",
                  "path": "bamboost.common.file_handler.FileHandler.__init__",
                  "signature": "(self, file_name, _comm = mpi.MPI.COMM_WORLD) -> None",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "file_name",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "_comm",
                      "annotation": "mpi.MPI.Comm",
                      "description": null,
                      "value": "mpi.MPI.COMM_WORLD"
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def __init__(\n    self, file_name: str, _comm: mpi.MPI.Comm = mpi.MPI.COMM_WORLD\n) -> None:\n    self.file_object: h5py.File = None\n    self.file_name = file_name\n    self.simulation_uid = os.path.basename(file_name)\n    self._lock = 0\n    self._mode = \"r\"\n    self._driver = None\n    self._comm = _comm"
                },
                "__call__": {
                  "name": "__call__",
                  "path": "bamboost.common.file_handler.FileHandler.__call__",
                  "signature": "(self, mode = 'r', driver = None, comm = None) -> bamboost.common.file_handler.FileHandler",
                  "description": "Used to set the options for file opening.\nExample: `with sim._file('a', driver='mpio') as file:`",
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "mode",
                      "annotation": "str",
                      "description": null,
                      "value": "'r'"
                    },
                    {
                      "name": "driver",
                      "annotation": null,
                      "description": null,
                      "value": "None"
                    },
                    {
                      "name": "comm",
                      "annotation": null,
                      "description": null,
                      "value": "None"
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "bamboost.common.file_handler.FileHandler",
                    "description": null
                  },
                  "docstring": [],
                  "source": "def __call__(self, mode: str = \"r\", driver=None, comm=None) -> FileHandler:\n    \"\"\"Used to set the options for file opening.\n    Example: `with sim._file('a', driver='mpio') as file:`\n    \"\"\"\n    self._mode = mode\n    self._driver = driver\n    self._comm = comm if comm is not None else self._comm\n    return self"
                },
                "__getitem__": {
                  "name": "__getitem__",
                  "path": "bamboost.common.file_handler.FileHandler.__getitem__",
                  "signature": "(self, key) -> typing.Any",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "key",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "typing.Any",
                    "description": null
                  },
                  "docstring": [],
                  "source": "@capture_key_error\ndef __getitem__(self, key) -> Any:\n    return self.file_object[key]"
                },
                "__delitem__": {
                  "name": "__delitem__",
                  "path": "bamboost.common.file_handler.FileHandler.__delitem__",
                  "signature": "(self, key) -> None",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "key",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "None",
                    "description": null
                  },
                  "docstring": [],
                  "source": "@capture_key_error\ndef __delitem__(self, key) -> None:\n    del self.file_object[key]"
                },
                "__getattr__": {
                  "name": "__getattr__",
                  "path": "bamboost.common.file_handler.FileHandler.__getattr__",
                  "signature": "(self, __name) -> typing.Any",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "__name",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": "typing.Any",
                    "description": null
                  },
                  "docstring": [],
                  "source": "@capture_key_error\ndef __getattr__(self, __name: str) -> Any:\n    try:\n        return self.file_object.__getattribute__(__name)\n    except AttributeError:\n        return self.__getattribute__(__name)"
                },
                "__enter__": {
                  "name": "__enter__",
                  "path": "bamboost.common.file_handler.FileHandler.__enter__",
                  "signature": "(self)",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": null,
                    "description": null
                  },
                  "docstring": [],
                  "source": "def __enter__(self):\n    self.open(self._mode, self._driver, self._comm)\n    return self"
                },
                "__exit__": {
                  "name": "__exit__",
                  "path": "bamboost.common.file_handler.FileHandler.__exit__",
                  "signature": "(self, *args)",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "args",
                      "annotation": null,
                      "description": null,
                      "value": "()"
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": null,
                    "description": null
                  },
                  "docstring": [],
                  "source": "def __exit__(self, *args):\n    self.close()"
                },
                "open": {
                  "name": "open",
                  "path": "bamboost.common.file_handler.FileHandler.open",
                  "signature": "(self, mode = 'r', driver = None, comm = None)",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "mode",
                      "annotation": "str",
                      "description": null,
                      "value": "'r'"
                    },
                    {
                      "name": "driver",
                      "annotation": null,
                      "description": null,
                      "value": "None"
                    },
                    {
                      "name": "comm",
                      "annotation": null,
                      "description": null,
                      "value": "None"
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": null,
                    "description": null
                  },
                  "docstring": [],
                  "source": "def open(self, mode: str = \"r\", driver=None, comm=None):\n    if self._lock <= 0:\n        log.debug(f\"[{id(self)}] Open {self.file_name}\")\n        self.file_object = open_h5file(self.file_name, mode, driver, comm)\n\n    if FILE_MODE_HIRARCHY[self.file_object.mode] < FILE_MODE_HIRARCHY[mode]:\n        self.change_file_mode(mode, driver, comm)\n\n    log.debug(f\"[{id(self)}] Lock stack {self._lock}\")\n    self._lock += 1\n    return self.file_object"
                },
                "close": {
                  "name": "close",
                  "path": "bamboost.common.file_handler.FileHandler.close",
                  "signature": "(self)",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": null,
                    "description": null
                  },
                  "docstring": [],
                  "source": "def close(self):\n    self._lock -= 1\n    if self._lock == 0:\n        log.debug(f\"[{id(self)}] Close {self.file_name}\")\n        self.file_object.close()\n    log.debug(f\"[{id(self)}] Lock stack {self._lock}\")"
                },
                "change_file_mode": {
                  "name": "change_file_mode",
                  "path": "bamboost.common.file_handler.FileHandler.change_file_mode",
                  "signature": "(self, mode, driver = None, comm = None)",
                  "description": null,
                  "parameters": [
                    {
                      "name": "self",
                      "annotation": null,
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "mode",
                      "annotation": "str",
                      "description": null,
                      "value": null
                    },
                    {
                      "name": "driver",
                      "annotation": null,
                      "description": null,
                      "value": "None"
                    },
                    {
                      "name": "comm",
                      "annotation": null,
                      "description": null,
                      "value": "None"
                    }
                  ],
                  "returns": {
                    "name": "",
                    "annotation": null,
                    "description": null
                  },
                  "docstring": [],
                  "source": "def change_file_mode(self, mode: str, driver=None, comm=None):\n    log.info(\n        f\"Forced closing and reopening to change file mode [{self.file_name}].\"\n    )\n    self.file_object.close()\n    self.file_object = open_h5file(self.file_name, mode, driver, comm)"
                }
              },
              "source": "class FileHandler:\n    \"\"\"File handler for an hdf5 file with the purpose of handling opening and closing\n    of the file. We use the concept of composition to include an object of this type\n    in classes which need access to an hdf5 file (such as the hdf5pointer and Simulation.)\n\n    Args:\n        file_name: the path to the file\n\n    Attributes:\n        file_object: the h5py file object (accessible if open)\n        _lock: lock is kind of a stack. `open` increases the stack. `close` decreases\n            the stack. file_object is only closed if the stack is at 0. Ensures consecutive\n            method calls works. Would be a problem if the file is closed after each\n            sub-operation.\n        _mode: file mode\n        _driver: file driver\n        _comm: MPI communicator\n    \"\"\"\n\n    def __init__(\n        self, file_name: str, _comm: mpi.MPI.Comm = mpi.MPI.COMM_WORLD\n    ) -> None:\n        self.file_object: h5py.File = None\n        self.file_name = file_name\n        self.simulation_uid = os.path.basename(file_name)\n        self._lock = 0\n        self._mode = \"r\"\n        self._driver = None\n        self._comm = _comm\n\n    def __call__(self, mode: str = \"r\", driver=None, comm=None) -> FileHandler:\n        \"\"\"Used to set the options for file opening.\n        Example: `with sim._file('a', driver='mpio') as file:`\n        \"\"\"\n        self._mode = mode\n        self._driver = driver\n        self._comm = comm if comm is not None else self._comm\n        return self\n\n    @capture_key_error\n    def __getitem__(self, key) -> Any:\n        return self.file_object[key]\n\n    @capture_key_error\n    def __delitem__(self, key) -> None:\n        del self.file_object[key]\n\n    @capture_key_error\n    def __getattr__(self, __name: str) -> Any:\n        try:\n            return self.file_object.__getattribute__(__name)\n        except AttributeError:\n            return self.__getattribute__(__name)\n\n    def __enter__(self):\n        self.open(self._mode, self._driver, self._comm)\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def open(self, mode: str = \"r\", driver=None, comm=None):\n        if self._lock <= 0:\n            log.debug(f\"[{id(self)}] Open {self.file_name}\")\n            self.file_object = open_h5file(self.file_name, mode, driver, comm)\n\n        if FILE_MODE_HIRARCHY[self.file_object.mode] < FILE_MODE_HIRARCHY[mode]:\n            self.change_file_mode(mode, driver, comm)\n\n        log.debug(f\"[{id(self)}] Lock stack {self._lock}\")\n        self._lock += 1\n        return self.file_object\n\n    def close(self):\n        self._lock -= 1\n        if self._lock == 0:\n            log.debug(f\"[{id(self)}] Close {self.file_name}\")\n            self.file_object.close()\n        log.debug(f\"[{id(self)}] Lock stack {self._lock}\")\n\n    def change_file_mode(self, mode: str, driver=None, comm=None):\n        log.info(\n            f\"Forced closing and reopening to change file mode [{self.file_name}].\"\n        )\n        self.file_object.close()\n        self.file_object = open_h5file(self.file_name, mode, driver, comm)",
              "inherited_members": {}
            }
          },
          "functions": {
            "open_h5file": {
              "name": "open_h5file",
              "path": "bamboost.common.file_handler.open_h5file",
              "signature": "(file, mode, driver = None, comm = None)",
              "description": "Open h5 file. Waiting if file is not available.",
              "parameters": [
                {
                  "name": "file",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "File to open"
                    }
                  ]
                },
                {
                  "name": "mode",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "'r', 'a', 'w', ..."
                    }
                  ]
                },
                {
                  "name": "driver",
                  "annotation": "str",
                  "description": [
                    {
                      "kind": "text",
                      "value": "driver for h5.File"
                    }
                  ],
                  "value": "None"
                },
                {
                  "name": "comm",
                  "annotation": null,
                  "description": [
                    {
                      "kind": "text",
                      "value": "MPI communicator"
                    }
                  ],
                  "value": "None"
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def open_h5file(\n    file: str,\n    mode: Literal[\"mpio\"] | Type[None],\n    driver: bool | Type[None] = None,\n    comm=None,\n):\n    \"\"\"Open h5 file. Waiting if file is not available.\n\n    Args:\n        file (str): File to open\n        mode (str): 'r', 'a', 'w', ...\n        driver (str): driver for h5.File\n        comm: MPI communicator\n    \"\"\"\n    while True:\n        try:\n            if driver == \"mpio\" and MPI_ACTIVE and mpi.MPI_ON:\n                return h5py.File(file, mode, driver=driver, comm=comm)\n            else:\n                return h5py.File(file, mode)\n\n        except BlockingIOError:\n            log.warning(f\"file locked --> {file}\")\n            time.sleep(0.2)"
            },
            "with_file_open": {
              "name": "with_file_open",
              "path": "bamboost.common.file_handler.with_file_open",
              "signature": "(mode = 'r', driver = None, comm = None)",
              "description": "Open the file (`self._file`) before function\nClose the file after the function call\n\nWorks on classes containing the member `_file` of type :class:`~bamboost.common.file_handler.FileHandler`",
              "parameters": [
                {
                  "name": "mode",
                  "annotation": "str",
                  "description": null,
                  "value": "'r'"
                },
                {
                  "name": "driver",
                  "annotation": null,
                  "description": null,
                  "value": "None"
                },
                {
                  "name": "comm",
                  "annotation": null,
                  "description": null,
                  "value": "None"
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def with_file_open(mode: str = \"r\", driver=None, comm=None):\n    \"\"\"Open the file (`self._file`) before function\n    Close the file after the function call\n\n    Works on classes containing the member `_file` of type :class:`~bamboost.common.file_handler.FileHandler`\n    \"\"\"\n\n    def decorator(method):\n        @wraps(method)\n        def wrapper(self, *args, **kwargs):\n            with self._file(mode, driver, comm):\n                return method(self, *args, **kwargs)\n\n        return wrapper\n\n    return decorator"
            },
            "capture_key_error": {
              "name": "capture_key_error",
              "path": "bamboost.common.file_handler.capture_key_error",
              "signature": "(method)",
              "description": null,
              "parameters": [
                {
                  "name": "method",
                  "annotation": null,
                  "description": null,
                  "value": null
                }
              ],
              "returns": {
                "name": "",
                "annotation": null,
                "description": null
              },
              "docstring": [],
              "source": "def capture_key_error(method):\n    @wraps(method)\n    def inner(self, *args, **kwargs):\n        try:\n            return method(self, *args, **kwargs)\n        except KeyError as e:\n            e.add_note(f\"[file: {self.file_name}]\")\n            raise e\n\n    return inner"
            }
          }
        }
      },
      "classes": {},
      "functions": {}
    }
  },
  "classes": {},
  "functions": {
    "add_stream_handler": {
      "name": "add_stream_handler",
      "path": "bamboost.add_stream_handler",
      "signature": "(logger) -> None",
      "description": null,
      "parameters": [
        {
          "name": "logger",
          "annotation": "logging.Logger",
          "description": null,
          "value": null
        }
      ],
      "returns": {
        "name": "",
        "annotation": "None",
        "description": null
      },
      "docstring": [],
      "source": "def add_stream_handler(logger: logging.Logger) -> None:\n    stream_handler = logging.StreamHandler()\n    formatter = logging.Formatter(\n        \"[%(asctime)s] %(name)s: %(levelname)s - %(message)s\",\n        style=\"%\",\n        datefmt=\"%Y-%m-%d %H:%M:%S\",\n    )\n    stream_handler.setFormatter(formatter)\n    logger.addHandler(stream_handler)"
    },
    "set_log_level": {
      "name": "set_log_level",
      "path": "bamboost.set_log_level",
      "signature": "(level) -> None",
      "description": null,
      "parameters": [
        {
          "name": "level",
          "annotation": "Literal",
          "description": null,
          "value": null
        }
      ],
      "returns": {
        "name": "",
        "annotation": "None",
        "description": null
      },
      "docstring": [],
      "source": "def set_log_level(\n    level: Literal[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"],\n) -> None:\n    BAMBOOST_LOGGER.setLevel(level)"
    }
  },
  "version": "0.8.1"
}