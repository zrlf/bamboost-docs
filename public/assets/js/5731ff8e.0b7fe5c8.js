"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5837],{3017:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>d,default:()=>p,frontMatter:()=>r,metadata:()=>u,toc:()=>f});var s=t(5893),i=t(1151),a=t(8856),o=t(8213),l=t(859);const r={title:"Simulation Writer",hide_table_of_contents:!1},d=void 0,u={id:"reference/simulation_writer",title:"Simulation Writer",description:"Manager",source:"@site/docs/reference/simulation_writer.md",sourceDirName:"reference",slug:"/reference/simulation_writer",permalink:"/bamboost-docs/docs/reference/simulation_writer",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{title:"Simulation Writer",hide_table_of_contents:!1},sidebar:"refSidebar",previous:{title:"Simulation",permalink:"/bamboost-docs/docs/reference/simulation"}},c={},f=[{value:"Manager",id:"manager",level:2}];function m(e){const n={h2:"h2",...(0,i.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h2,{id:"manager",children:"Manager"}),"\n",(0,s.jsx)(a.n,{cls:l.Hi}),"\n",(0,s.jsx)(o.o,{})]})}function p(e={}){const{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(m,{...e})}):m(e)}},8856:(e,n,t)=>{t.d(n,{n:()=>f});var s=t(859),i=t(6911),a=t(7294),o=t(6010),l=t(5893);const r=e=>{let{name:n,signature:t,sourceIsVisible:s}=e;return(0,l.jsx)("div",{className:(0,o.Z)("signature",s&&"sourceIsVisible"),children:(0,l.jsxs)(i.Z,{language:"py",children:[n," ",t]})})},d=e=>{let{source_code:n,starting_line_number:t,sourceIsVisible:s}=e;return(0,l.jsx)(l.Fragment,{children:s&&(0,l.jsx)("div",{className:"source-code-div",children:(0,l.jsx)(i.Z,{language:"py",showLineNumbers:!0,startingLineNumber:t,children:n})})})},u=e=>{let{sourceIsVisible:n,setSourceIsVisible:t}=e;return(0,l.jsx)("button",{className:"sourceButton",onClick:()=>t((e=>!e)),children:n?(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)("i",{className:"fa-solid fa-chevron-down icon"})," source code"]}):(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)("i",{className:"fa-solid fa-chevron-right icon"})," source code"]})})},c=e=>{let{cls:n}=e;const t=n.constructor.source.code,s=n.constructor.source.lines[0],i=n.constructor.signature,o=n.name,[c,f]=(0,a.useState)(!1);return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)("div",{style:{position:"relative"},children:(0,l.jsx)(u,{sourceIsVisible:c,setSourceIsVisible:f})}),(0,l.jsx)(r,{name:o,signature:i,sourceIsVisible:c}),(0,l.jsx)(d,{source_code:t,starting_line_number:s,sourceIsVisible:c})]})},f=e=>{let{cls:n}=e;const t=n.methods;return(0,l.jsxs)("div",{children:[(0,l.jsx)("p",{children:s.docstring}),(0,l.jsx)(c,{cls:n}),(0,l.jsx)("div",{className:"methods",children:Object.keys(t).map((e=>(e=>{const n=e.name,t=e.obj,[s,i]=(0,a.useState)(!1),[o,c]=(0,a.useState)(!0);return(0,l.jsxs)("div",{className:"method",children:[(0,l.jsxs)("div",{className:"method-title",children:[(0,l.jsx)("div",{onClick:()=>c(!o),children:(0,l.jsx)("i",{className:"fa-solid fa-circle-notch icon"})}),(0,l.jsx)("h3",{id:n,style:{display:"inline-block"},children:(0,l.jsx)("span",{children:n})}),(0,l.jsx)(u,{sourceIsVisible:s,setSourceIsVisible:i})]}),(0,l.jsx)(r,{name:n,signature:t.signature,sourceIsVisible:s}),(0,l.jsx)(d,{source_code:t.source.code,starting_line_number:t.source.lines[0],sourceIsVisible:s}),o&&(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)("p",{children:t.docstring}),(0,l.jsxs)("div",{className:"parameters",children:[(0,l.jsx)("b",{children:"Parameters:"}),(0,l.jsx)("ul",{children:Object.keys(t.arguments).map(((e,n)=>(0,l.jsxs)("li",{children:[(0,l.jsx)("b",{children:e})," : ",(0,l.jsx)("i",{children:t.arguments[e].annotation}),(0,l.jsx)("p",{className:"parameter-description",children:t.arguments[e].description})]},`args_${n}`)))})]}),(0,l.jsxs)("div",{className:"parameters",children:[(0,l.jsx)("b",{children:"Returns:"}),(0,l.jsxs)("ul",{children:[(0,l.jsx)("i",{children:t.returns.annotation}),(0,l.jsx)("p",{className:"parameter-description",children:t.returns.description})]})]})]})]})})({name:e,obj:t[e]})))})]})}},8213:(e,n,t)=>{t.d(n,{o:()=>r});var s=t(7294),i=t(745),a=t(3935),o=t(5893);const l=e=>{let{headings:n,activeId:t}=e;return(0,o.jsx)("ul",{className:"custom-toc",children:n.map((e=>(0,o.jsxs)("li",{className:e.id===t?"active":"",children:[" ",(0,o.jsx)("a",{href:`#${e.id}`,onClick:n=>{n.preventDefault(),document.querySelector(`#${e.id}`).scrollIntoView({behavior:"smooth"})},children:e.title}),e.items.length>0&&(0,o.jsx)("ul",{children:e.items.map((e=>(0,o.jsxs)("li",{className:e.id===t?"active":"",children:[" ",(0,o.jsx)("a",{href:`#${e.id}`,onClick:n=>{n.preventDefault(),document.querySelector(`#${e.id}`).scrollIntoView({behavior:"smooth"})},children:e.title})]},e.id)))})]},e.id)))})},r=()=>{const[e,n]=(0,s.useState)(),{nestedHeadings:t}=(()=>{const[e,n]=(0,s.useState)([]);return(0,s.useEffect)((()=>{const e=(e=>{const n=[];return e.forEach(((e,t)=>{const{innerText:s,id:i}=e;"H2"===e.nodeName?n.push({id:i,title:s,items:[]}):"H3"===e.nodeName&&n.length>0&&n[n.length-1].items.push({id:i,title:s})})),n})(Array.from(document.querySelectorAll("h2, h3")));n(e)}),[]),{nestedHeadings:e}})(),[r,d]=(0,s.useState)(null);return(e=>{const n=(0,s.useRef)({});(0,s.useEffect)((()=>{const t=new IntersectionObserver((t=>{n.current=t.reduce(((e,n)=>(e[n.target.id]=n,e)),n.current);const i=[];Object.keys(n.current).forEach((e=>{const t=n.current[e];t.isIntersecting&&i.push(t)}));const a=e=>s.findIndex((n=>n.id===e));if(1===i.length)e(i[0].target.id);else if(i.length>1){const n=i.sort(((e,n)=>a(e.target.id)>a(n.target.id)));e(n[0].target.id)}}),{rootMargin:"0px 0px -40% 0px"}),s=Array.from(document.querySelectorAll("h2, h3"));return s.forEach((e=>t.observe(e))),()=>t.disconnect()}),[e])})(n),(0,s.useEffect)((()=>{const n=document.querySelector(".table-of-contents");n&&!r&&d((0,i.createRoot)(n)),n&&r&&setTimeout((()=>{(0,a.flushSync)((()=>{r.render((0,o.jsx)(l,{headings:t,activeId:e}))}))}),0)}),[t,e]),null}},859:e=>{e.exports=JSON.parse('{"dK":{"name":"Manager","docstring":"View of database. ","variables":{"FIX_DF":"","fromUID":": bamboost.manager.ManagerFromUID","fromName":": bamboost.manager.ManagerFromName","path":"","comm":"","UID":"","all_uids":": set","df":": pandas.core.frame.DataFrame","data_info":": pandas.core.frame.DataFrame"},"methods":{"__getitem__":{"docstring":"Returns the simulation in the specified row of the dataframe. ","signature":"(self, key: Union[str, int]) -> bamboost.simulation.Simulation","returns":{"annotation":"<class \'bamboost.simulation.Simulation\'>","description":":class:`~bamboost.reader.Simulation`"},"arguments":{"self":{"default":null,"annotation":null,"description":null},"key":{"default":null,"annotation":"typing.Union[str, int]","description":null}},"source":{"code":"    def __getitem__(self, key: Union[str, int]) -> Simulation:\\n        \\"\\"\\"Returns the simulation in the specified row of the dataframe.\\n\\n        Args:\\n            row (`str`): return the simulation with the specified uid\\n            row (int): return the simulation with index specified by row\\n        Returns:\\n            :class:`~bamboost.reader.Simulation`\\n        \\"\\"\\"\\n        if isinstance(key, str):\\n            return self.sim(key)\\n        else:\\n            return self.sim(self.df.loc[key, \\"id\\"])\\n","lines":[121,133]}},"__len__":{"docstring":"None ","signature":"(self) -> int","returns":{"annotation":"<class \'int\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def __len__(self) -> int:\\n        return len(self.all_uids)\\n","lines":[148,149]}},"__iter__":{"docstring":"None ","signature":"(self) -> list","returns":{"annotation":"<class \'list\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def __iter__(self) -> list:\\n        for sim in self.sims():\\n            yield sim\\n","lines":[151,153]}},"get_view":{"docstring":"View of the database and its parametric space. ","signature":"(self) -> pandas.core.frame.DataFrame","returns":{"annotation":"<class \'pandas.core.frame.DataFrame\'>","description":":class:`pd.DataFrame`"},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def get_view(self) -> pd.DataFrame:\\n        \\"\\"\\"View of the database and its parametric space.\\n\\n        Returns:\\n            :class:`pd.DataFrame`\\n        \\"\\"\\"\\n        all_uids = self.all_uids\\n        data = list()\\n\\n        for uid in all_uids:\\n            h5file_for_uid = os.path.join(self.path, uid, f\\"{uid}.h5\\")\\n            with open_h5file(h5file_for_uid, \\"r\\") as f:\\n                tmp_dict = dict()\\n                if \\"parameters\\" in f.keys():\\n                    tmp_dict.update(f[\\"parameters\\"].attrs)\\n                if \\"additionals\\" in f.keys():\\n                    tmp_dict.update({\\"additionals\\": f[\\"additionals\\"].attrs})\\n                tmp_dict.update(f.attrs)\\n                data.append(tmp_dict)\\n\\n        df = pd.DataFrame.from_records(data)\\n        if df.empty:\\n            return df\\n\\n        # Sort dataframe columns\\n        self._dataframe = df[\\n            [\\"id\\", \\"notes\\", \\"status\\", *df.columns.difference([\\"id\\", \\"notes\\", \\"status\\"])]\\n        ]\\n        return self._dataframe\\n","lines":[210,238]}},"sim":{"docstring":"Get an existing simulation with uid. Same as accessing with `db[uid]` directly. ","signature":"(self, uid, return_writer: bool = False) -> bamboost.simulation.Simulation","returns":{"annotation":"<class \'bamboost.simulation.Simulation\'>","description":":class:`~bamboost.simulation.Simulation`"},"arguments":{"self":{"default":null,"annotation":null,"description":null},"uid":{"default":null,"annotation":null,"description":"unique identifier"},"return_writer":{"default":"False","annotation":"<class \'bool\'>","description":"if true, return `SimulationWriter`, otherwise return `Simulation`"}},"source":{"code":"    def sim(self, uid, return_writer: bool = False) -> Simulation:\\n        \\"\\"\\"Get an existing simulation with uid. Same as accessing with `db[uid]` directly.\\n\\n        Args:\\n            uid (`str`): unique identifier\\n            return_writer: if true, return `SimulationWriter`, otherwise\\n                return `Simulation`\\n        Returns:\\n            :class:`~bamboost.simulation.Simulation`\\n        \\"\\"\\"\\n        if uid not in self.all_uids:\\n            raise KeyError(\\"The simulation id is not valid.\\")\\n        if return_writer:\\n            return SimulationWriter(uid, self.path, self.comm)\\n        return Simulation(uid, self.path, self.comm)\\n","lines":[263,277]}},"sims":{"docstring":"Get all simulations in a list. Optionally, get all simulations matching the given selection using pandas.","signature":"(\\n    self,\\n    select: pandas.core.series.Series = None,\\n    sort: str = None,\\n    reverse: bool = False,\\n    exclude: set = None,\\n    return_writer: bool = False\\n) -> list","returns":{"annotation":"<class \'list\'>","description":"A list of `:class:~bamboost.simulation.Simulation` objects"},"arguments":{"self":{"default":null,"annotation":null,"description":null},"select":{"default":"None","annotation":"<class \'pandas.core.series.Series\'>","description":"pandas boolean series"},"sort":{"default":"None","annotation":"<class \'str\'>","description":"Optionally sort the list with this keyword"},"reverse":{"default":"False","annotation":"<class \'bool\'>","description":"swap sort direction"},"exclude":{"default":"None","annotation":"<class \'set\'>","description":"sims to exclude"},"return_writer":{"default":"False","annotation":"<class \'bool\'>","description":"if true, return `SimulationWriter`, otherwise return `Simulation`"}},"source":{"code":"    def sims(\\n        self,\\n        select: pd.Series = None,\\n        sort: str = None,\\n        reverse: bool = False,\\n        exclude: set = None,\\n        return_writer: bool = False,\\n    ) -> list:\\n        \\"\\"\\"Get all simulations in a list. Optionally, get all simulations matching the\\n        given selection using pandas.\\n\\n        Args:\\n            select (`pd.Series`): pandas boolean series\\n            sort (`str`): Optionally sort the list with this keyword\\n            reverse (`bool`): swap sort direction\\n            exclude (`list[str]`): sims to exclude\\n            return_writer: if true, return `SimulationWriter`, otherwise\\n                return `Simulation`\\n        Returns:\\n            A list of `:class:~bamboost.simulation.Simulation` objects\\n        \\"\\"\\"\\n        if select is not None:\\n            id_list = self.df[select][\\"id\\"].values\\n        else:\\n            id_list = self.all_uids\\n        if exclude is not None:\\n            exclude = list([exclude]) if isinstance(exclude, str) else exclude\\n            id_list = [id for id in id_list if id not in exclude]\\n\\n        existing_sims = [self.sim(uid, return_writer) for uid in id_list]\\n\\n        if sort is None:\\n            return existing_sims\\n        else:\\n            return sorted(\\n                existing_sims, key=lambda s: s.parameters[sort], reverse=reverse\\n            )\\n","lines":[279,315]}},"create_simulation":{"docstring":"Get a writer object for a new simulation. This is written for paralell use as it is likely that this may be used in an executable, creating multiple runs for a parametric space, which may be run in paralell.","signature":"(\\n    self,\\n    uid: str = None,\\n    parameters: dict = None,\\n    skip_duplicate_check: bool = False\\n) -> bamboost.simulation_writer.SimulationWriter","returns":{"annotation":"<class \'bamboost.simulation_writer.SimulationWriter\'>","description":"sim (:class:`~bamboost.simulation.SimulationWriter`)"},"arguments":{"self":{"default":null,"annotation":null,"description":null},"uid":{"default":"None","annotation":"<class \'str\'>","description":"The name/uid for the simulation. If not specified, a random id will be assigned."},"parameters":{"default":"None","annotation":"<class \'dict\'>","description":"Parameter dictionary. If provided, the parameters will be checked against the existing sims for duplication. Otherwise, they may be specified later with :func:`~bamboost.simulation.SimulationWriter.add_parameters`."},"skip_duplicate_check":{"default":"False","annotation":"<class \'bool\'>","description":"if True, the duplicate check is skipped."}},"source":{"code":"    def create_simulation(\\n        self,\\n        uid: str = None,\\n        parameters: dict = None,\\n        skip_duplicate_check: bool = False,\\n    ) -> SimulationWriter:\\n        \\"\\"\\"Get a writer object for a new simulation. This is written for paralell use\\n        as it is likely that this may be used in an executable, creating multiple runs\\n        for a parametric space, which may be run in paralell.\\n\\n        Args:\\n            uid (`str`): The name/uid for the simulation. If not specified, a random id\\n                will be assigned.\\n            parameters (`dict`): Parameter dictionary. If provided, the parameters will be\\n                checked against the existing sims for duplication. Otherwise, they may be\\n                specified later with :func:`~bamboost.simulation.SimulationWriter.add_parameters`.\\n            skip_duplicate_check (`bool`): if True, the duplicate check is skipped.\\n        Returns:\\n            sim (:class:`~bamboost.simulation.SimulationWriter`)\\n        \\"\\"\\"\\n        if parameters and not skip_duplicate_check:\\n            go_on, uid = self._check_duplicate(parameters, uid)\\n            if not go_on:\\n                print(\\"Aborting by user desire...\\")\\n                return None\\n\\n        if self.comm.rank == 0:\\n            if not uid:\\n                uid = uuid.uuid4().hex[:8]  # Assign random unique identifier\\n        uid = self.comm.bcast(uid, root=0)\\n\\n        # Create directory and h5 file\\n        if self.comm.rank == 0:\\n            os.makedirs(os.path.join(self.path, uid), exist_ok=True)\\n            path_to_h5_file = os.path.join(self.path, uid, f\\"{uid}.h5\\")\\n            if os.path.exists(path_to_h5_file):\\n                os.remove(path_to_h5_file)\\n            h5py.File(path_to_h5_file, \\"a\\").close()  # create file\\n\\n        new_sim = SimulationWriter(uid, self.path, self.comm)\\n        new_sim.initialize()  # sets metadata and status\\n        if parameters is None:\\n            parameters = dict()\\n        new_sim.add_parameters(parameters)\\n        return new_sim\\n","lines":[317,361]}},"remove":{"docstring":"CAUTION, DELETING DATA. Remove the data of a simulation. ","signature":"(self, uid: str) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"uid":{"default":null,"annotation":"<class \'str\'>","description":"uid"}},"source":{"code":"    def remove(self, uid: str) -> None:\\n        \\"\\"\\"CAUTION, DELETING DATA. Remove the data of a simulation.\\n\\n        Args:\\n            uid (`str`): uid\\n        \\"\\"\\"\\n        shutil.rmtree(os.path.join(self.path, uid))\\n","lines":[363,369]}},"global_fields_in_all":{"docstring":"Get a list of all global fields in all simulations. ","signature":"(self) -> list","returns":{"annotation":"<class \'list\'>","description":"List of global fields"},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def global_fields_in_all(self) -> list:\\n        \\"\\"\\"Get a list of all global fields in all simulations.\\n\\n        Returns:\\n            List of global fields\\n        \\"\\"\\"\\n        fields = set()\\n        for sim in self:\\n            try:\\n                fields.update(sim.globals.columns)\\n            except KeyError:\\n                continue\\n\\n        return fields\\n","lines":[455,468]}},"get_parameters":{"docstring":"Get the parameters used in this database. ","signature":"(self) -> dict","returns":{"annotation":"<class \'dict\'>","description":"Dictionary of parameters with it\'s count, range, and type. Sorted by count."},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def get_parameters(self) -> dict:\\n        \\"\\"\\"Get the parameters used in this database.\\n\\n        Returns:\\n            Dictionary of parameters with it\'s count, range, and type. Sorted by count.\\n        \\"\\"\\"\\n        parameters = dict()\\n        for sim in self:\\n            for key, val in sim.parameters.items():\\n                if key not in parameters:\\n                    range = (val, val) if isinstance(val, numbers.Number) else None\\n                    parameters[key] = {\\"range\\": range, \\"count\\": 1, \\"type\\": type(val)}\\n                else:\\n                    if isinstance(val, numbers.Number):\\n                        parameters[key][\\"range\\"] = (\\n                            min(parameters[key][\\"range\\"][0], val),\\n                            max(parameters[key][\\"range\\"][1], val),\\n                        )\\n                    parameters[key][\\"count\\"] += 1\\n                    parameters[key][\\"type\\"] = type(val)\\n        return dict(\\n            sorted(parameters.items(), key=lambda x: x[1][\\"count\\"], reverse=True)\\n        )\\n","lines":[470,492]}}},"constructor":{"signature":"(\\n    path: str = None,\\n    comm: mpi4py.MPI.Comm = <mpi4py.MPI.Intracomm object>,\\n    uid: str = None,\\n    create_if_not_exist: bool = True\\n)","arguments":{"self":{"default":null,"annotation":null,"description":null},"path":{"default":"None","annotation":"<class \'str\'>","description":"path to the directory of the database. If doesn\'t exist, a new database will be created."},"comm":{"default":"<mpi4py.MPI.Intracomm object at 0x7f5d2e297a50>","annotation":"<class \'mpi4py.MPI.Comm\'>","description":"MPI communicator"},"uid":{"default":"None","annotation":"<class \'str\'>","description":"UID of the database"},"create_if_not_exist":{"default":"True","annotation":"<class \'bool\'>","description":null}},"source":{"code":"    def __init__(\\n        self,\\n        path: str = None,\\n        comm: MPI.Comm = MPI.COMM_WORLD,\\n        uid: str = None,\\n        create_if_not_exist: bool = True,\\n    ):\\n        if uid is not None:\\n            path = index.get_path(uid.upper())\\n        self.path = path\\n        self.comm = comm\\n\\n        # check if path exists\\n        if not os.path.isdir(path):\\n            if not create_if_not_exist:\\n                raise NotADirectoryError(\\"Specified path is not a valid path.\\")\\n            log.info(f\\"Created new database ({path})\\")\\n            self._make_new(path)\\n        self.UID = self._retrieve_uid()\\n        # self._store_uid_in_index()\\n        self._all_uids = self._get_uids()\\n        self._dataframe: pd.DataFrame = None\\n        self._meta_folder = os.path.join(path, \\".database\\")\\n","lines":[97,119]}}},"uL":{"name":"Simulation","docstring":"A single dataset/simulation. Used to write to it, read from it or append. ","variables":{"uid":"","path_database":"","path":"","h5file":"","xdmffile":"","meshes":"","data":"","userdata":"","links":"","parameters":"","metadata":"","mesh":"","globals":": pandas.core.frame.DataFrame","data_info":": \'pd.Dataframe\'","git":": dict"},"methods":{"__getitem__":{"docstring":"Direct access to HDF5 file. ","signature":"(self, key) -> bamboost.common.hdf_pointer.BasePointer","returns":{"annotation":"<class \'bamboost.common.hdf_pointer.BasePointer\'>","description":":class:`~bamboost.common.file_handler.BasePointer`"},"arguments":{"self":{"default":null,"annotation":null,"description":null},"key":{"default":null,"annotation":null,"description":null}},"source":{"code":"    @with_file_open()\\n    def __getitem__(self, key) -> hdf_pointer.BasePointer:\\n        \\"\\"\\"Direct access to HDF5 file.\\n\\n        Returns:\\n            :class:`~bamboost.common.file_handler.BasePointer`\\n        \\"\\"\\"\\n        return hdf_pointer.BasePointer.new_pointer(self._file, key)\\n","lines":[123,130]}},"show_files":{"docstring":"Show the file tree of the simulation directory. ","signature":"(\\n    self,\\n    level=-1,\\n    limit_to_directories=False,\\n    length_limit=1000,\\n    printit=True\\n) -> str","returns":{"annotation":"<class \'str\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"level":{"default":"-1","annotation":null,"description":"how deep to print the tree"},"limit_to_directories":{"default":"False","annotation":null,"description":"only print directories"},"length_limit":{"default":"1000","annotation":null,"description":"cutoff"},"printit":{"default":"True","annotation":null,"description":null}},"source":{"code":"    def show_files(\\n        self, level=-1, limit_to_directories=False, length_limit=1000, printit=True\\n    ) -> str:\\n        \\"\\"\\"Show the file tree of the simulation directory.\\n\\n        Args:\\n            level: how deep to print the tree\\n            limit_to_directories: only print directories\\n            length_limit: cutoff\\n        \\"\\"\\"\\n        tree_string = utilities.tree(\\n            self.path, level, limit_to_directories, length_limit\\n        )\\n        if printit:\\n            print(tree_string)\\n        else:\\n            return tree_string\\n","lines":[210,226]}},"open_in_file_explorer":{"docstring":"Open the simulation directory. Uses `xdg-open` on linux systems. ","signature":"(self) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def open_in_file_explorer(self) -> None:\\n        \\"\\"\\"Open the simulation directory. Uses `xdg-open` on linux systems.\\"\\"\\"\\n        if os.name == \\"nt\\":  # should work on Windows\\n            os.startfile(self.path)\\n        else:\\n            subprocess.run([\\"xdg-open\\", self.path])\\n","lines":[228,233]}},"get_full_uid":{"docstring":"Returns the full uid of the simulation (including the one of the database) ","signature":"(self) -> str","returns":{"annotation":"<class \'str\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def get_full_uid(self) -> str:\\n        \\"\\"\\"Returns the full uid of the simulation (including the one of the database)\\"\\"\\"\\n        database_uid = index.get_uid_from_path(self.path_database)\\n        return f\\"{database_uid}:{self.uid}\\"\\n","lines":[235,238]}},"change_status":{"docstring":"Change status of simulation. ","signature":"(self, status: str) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"status":{"default":null,"annotation":"<class \'str\'>","description":"new status"}},"source":{"code":"    @with_file_open(\\"a\\")\\n    def change_status(self, status: str) -> None:\\n        \\"\\"\\"Change status of simulation.\\n\\n        Args:\\n            status (str): new status\\n        \\"\\"\\"\\n        if self._prank == 0:\\n            self._file.attrs[\\"status\\"] = status\\n","lines":[240,248]}},"update_metadata":{"docstring":"Update the metadata attributes. ","signature":"(self, update_dict: dict) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"update_dict":{"default":null,"annotation":"<class \'dict\'>","description":"dictionary to push"}},"source":{"code":"    def update_metadata(self, update_dict: dict) -> None:\\n        \\"\\"\\"Update the metadata attributes.\\n\\n        Args:\\n            update_dict: dictionary to push\\n        \\"\\"\\"\\n        with self._file(\\"a\\") as file:\\n            file.attrs.update(update_dict)\\n","lines":[250,257]}},"update_parameters":{"docstring":"Update the parameters dictionary. ","signature":"(self, update_dict: dict) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"update_dict":{"default":null,"annotation":"<class \'dict\'>","description":"dictionary to push"}},"source":{"code":"    def update_parameters(self, update_dict: dict) -> None:\\n        \\"\\"\\"Update the parameters dictionary.\\n\\n        Args:\\n            update_dict: dictionary to push\\n        \\"\\"\\"\\n        if self._prank == 0:\\n            with self._file(\\"a\\") as file:\\n                file[\\"parameters\\"].attrs.update(update_dict)\\n","lines":[259,267]}},"create_xdmf_file":{"docstring":"Create the xdmf file to read in paraview. ","signature":"(self, fields: list = None, nb_steps: int = None) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"fields":{"default":"None","annotation":"<class \'list\'>","description":"fields for which to write timeseries information, if not specified, all fields in data are written."},"nb_steps":{"default":"None","annotation":"<class \'int\'>","description":"number of steps the simulation has"}},"source":{"code":"    def create_xdmf_file(self, fields: list = None, nb_steps: int = None) -> None:\\n        \\"\\"\\"Create the xdmf file to read in paraview.\\n\\n        Args:\\n            fields (list[str]): fields for which to write timeseries information,\\n                if not specified, all fields in data are written.\\n            nb_steps (int): number of steps the simulation has\\n        \\"\\"\\"\\n\\n        if self._comm.rank == 0:\\n            with self._file(\\"r\\") as f:\\n                if not fields:\\n                    fields = list(f[\\"data\\"].keys())\\n\\n                if not nb_steps:\\n                    grp_name = list(f[\\"data\\"].keys())[0]\\n                    nb_steps = list(f[f\\"data/{grp_name}\\"].keys())\\n                    nb_steps = max([int(step) for step in nb_steps])\\n\\n            xdmf_writer = XDMFWriter(self.xdmffile, self.h5file)\\n            xdmf_writer.write_points_cells(\\n                f\\"{self._mesh_location}/{self._default_mesh}/geometry\\",\\n                f\\"{self._mesh_location}/{self._default_mesh}/topology\\",\\n            )\\n\\n            xdmf_writer.add_timeseries(nb_steps + 1, fields)\\n            xdmf_writer.write_file()\\n","lines":[269,295]}},"create_batch_script":{"docstring":"Create a batch job and put it into the folder. ","signature":"(\\n    self,\\n    commands: list = None,\\n    nnodes=1,\\n    ntasks=4,\\n    ncpus=1,\\n    time=\'04:00:00\',\\n    mem_per_cpu=2048,\\n    tmp=8000,\\n    euler=True\\n) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"commands":{"default":"None","annotation":"<class \'list\'>","description":"A list of strings being the user defined commands to run"},"nnodes":{"default":"1","annotation":null,"description":"nb of nodes (default=1)"},"ntasks":{"default":"4","annotation":null,"description":"nb of tasks (default=4)"},"ncpus":{"default":"1","annotation":null,"description":"nb of cpus per task (default=1)"},"time":{"default":"04:00:00","annotation":null,"description":"requested time (default=4 hours)"},"mem_per_cpu":{"default":"2048","annotation":null,"description":"memory (default=2048)"},"tmp":{"default":"8000","annotation":null,"description":"temporary storage, set None to exclude option (default=8000)"},"euler":{"default":"True","annotation":null,"description":"If false, a local bash script will be written"}},"source":{"code":"    def create_batch_script(\\n        self,\\n        commands: list = None,\\n        nnodes=1,\\n        ntasks=4,\\n        ncpus=1,\\n        time=\\"04:00:00\\",\\n        mem_per_cpu=2048,\\n        tmp=8000,\\n        euler=True,\\n    ) -> None:\\n        \\"\\"\\"Create a batch job and put it into the folder.\\n\\n        Args:\\n            commands: A list of strings being the user defined commands to run\\n            nnodes: nb of nodes (default=1)\\n            ntasks: nb of tasks (default=4)\\n            ncpus: nb of cpus per task (default=1)\\n            time: requested time (default=4 hours)\\n            mem_per_cpu: memory (default=2048)\\n            tmp: temporary storage, set None to exclude option (default=8000)\\n            euler: If false, a local bash script will be written\\n        \\"\\"\\"\\n        job = Job()\\n        if not commands:\\n            if hasattr(self, \\"executable\\"):\\n                if \\".py\\" in self.executable:\\n                    command = (\\n                        f\\"{{MPI}} python3 {os.path.join(self.path, self.executable)} \\"\\n                        f\\"--path {self.path_database} --uid {self.uid}\\"\\n                    )\\n                    commands = [command]\\n            else:\\n                raise AttributeError(\\n                    \\"\\"\\"Either you must specify an executable or have it \\n                                     copied before with `copy_executable`!\\"\\"\\"\\n                )\\n\\n        if euler:\\n            job.create_sbatch_script(\\n                commands,\\n                path=os.path.abspath(self.path_database),\\n                uid=self.uid,\\n                nnodes=nnodes,\\n                ntasks=ntasks,\\n                ncpus=ncpus,\\n                time=time,\\n                mem_per_cpu=mem_per_cpu,\\n                tmp=tmp,\\n            )\\n        else:\\n            job.create_bash_script_local(\\n                commands,\\n                path=os.path.abspath(self.path_database),\\n                uid=self.uid,\\n                ntasks=ntasks,\\n            )\\n        with self._file(\\"a\\") as file:\\n            file.attrs.update({\\"submitted\\": False})\\n","lines":[297,355]}},"submit":{"docstring":"Submit the job for this simulation. ","signature":"(self) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def submit(self) -> None:\\n        \\"\\"\\"Submit the job for this simulation.\\"\\"\\"\\n        batch_script = os.path.abspath(os.path.join(self.path, f\\"sbatch_{self.uid}.sh\\"))\\n        subprocess.Popen([\\"sbatch\\", f\\"{batch_script}\\"])\\n        print(f\\"Simulation {self.uid} submitted!\\")\\n\\n        with self._file(\\"a\\") as file:\\n            file.attrs.update({\\"submitted\\": True})\\n","lines":[357,364]}},"change_note":{"docstring":"None ","signature":"(self, note) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"note":{"default":null,"annotation":null,"description":null}},"source":{"code":"    @with_file_open(\\"a\\")\\n    def change_note(self, note) -> None:\\n        self._file.attrs[\\"notes\\"] = note\\n","lines":[366,368]}},"open":{"docstring":"Use this as a context manager in a `with` statement. Purpose: keeping the file open to directly access/edit something in the HDF5 file of this simulation.","signature":"(\\n    self,\\n    mode: str = \'r\',\\n    driver=None,\\n    comm=None\\n) -> bamboost.common.file_handler.FileHandler","returns":{"annotation":"<class \'bamboost.common.file_handler.FileHandler\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"mode":{"default":"r","annotation":"<class \'str\'>","description":"file mode (see h5py docs)"},"driver":{"default":"None","annotation":null,"description":"file driver (see h5py docs)"},"comm":{"default":"None","annotation":null,"description":"mpi communicator"}},"source":{"code":"    def open(self, mode: str = \\"r\\", driver=None, comm=None) -> FileHandler:\\n        \\"\\"\\"Use this as a context manager in a `with` statement.\\n        Purpose: keeping the file open to directly access/edit something in the\\n        HDF5 file of this simulation.\\n\\n        Args:\\n            mode (`str`): file mode (see h5py docs)\\n            driver (`str`): file driver (see h5py docs)\\n            comm (`str`): mpi communicator\\n        \\"\\"\\"\\n        return self._file(mode, driver, comm)\\n","lines":[373,383]}},"get_mesh":{"docstring":"Return coordinates and connectivity. Currently returns numpy arrays. ","signature":"(self, mesh_name: str = None) -> Tuple[numpy.ndarray, numpy.ndarray]","returns":{"annotation":"typing.Tuple[numpy.ndarray, numpy.ndarray]","description":"Tuple of np.arrays (coordinates, connectivity)"},"arguments":{"self":{"default":null,"annotation":null,"description":null},"mesh_name":{"default":"None","annotation":"<class \'str\'>","description":"optional, name of mesh to read (default = mesh)"}},"source":{"code":"    @with_file_open(\\"r\\")\\n    def get_mesh(self, mesh_name: str = None) -> Tuple[np.ndarray, np.ndarray]:\\n        \\"\\"\\"Return coordinates and connectivity. Currently returns numpy arrays.\\n\\n        Args:\\n            mesh_name (`str`): optional, name of mesh to read (default = mesh)\\n        Returns:\\n            Tuple of np.arrays (coordinates, connectivity)\\n        \\"\\"\\"\\n        if mesh_name is None:\\n            mesh_name = self._default_mesh\\n\\n        mesh = self.meshes[mesh_name]\\n        return mesh.coordinates, mesh.connectivity\\n","lines":[394,407]}},"get_data_interpolator":{"docstring":"Get Linear interpolator for data field at step. Uses the linked mesh. ","signature":"(self, field: str, step: int)","returns":{"annotation":"<class \'inspect._empty\'>","description":":class:`scipy.interpolate.LinearNDInterpolator`"},"arguments":{"self":{"default":null,"annotation":null,"description":null},"field":{"default":null,"annotation":"<class \'str\'>","description":null},"step":{"default":null,"annotation":"<class \'int\'>","description":"step"}},"source":{"code":"    def get_data_interpolator(self, field: str, step: int):\\n        \\"\\"\\"Get Linear interpolator for data field at step. Uses the linked mesh.\\n\\n        Args:\\n            name (`str`): name of the data field\\n            step (`int`): step\\n        Returns:\\n            :class:`scipy.interpolate.LinearNDInterpolator`\\n        \\"\\"\\"\\n        from scipy.interpolate import LinearNDInterpolator\\n\\n        return LinearNDInterpolator(\\n            self.data[field].mesh.coordinates, self.data[field].at_step(step)\\n        )\\n","lines":[457,470]}},"show_h5tree":{"docstring":"Print the tree inside the h5 file. ","signature":"(self) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    @with_file_open()\\n    def show_h5tree(self) -> None:\\n        \\"\\"\\"Print the tree inside the h5 file.\\"\\"\\"\\n        # print(\'\\\\U00002B57 \' + os.path.basename(self.h5file))\\n        print(\\"\\\\U0001F43C \\" + os.path.basename(self.h5file))\\n        utilities.h5_tree(self._file.file_object)\\n","lines":[472,477]}}},"constructor":{"signature":"(\\n    uid: str,\\n    path: str,\\n    comm: mpi4py.MPI.Comm = <mpi4py.MPI.Intracomm object>\\n)","arguments":{"self":{"default":null,"annotation":null,"description":null},"uid":{"default":null,"annotation":"<class \'str\'>","description":"unique identifier"},"path":{"default":null,"annotation":"<class \'str\'>","description":"path to parent/database folder"},"comm":{"default":"<mpi4py.MPI.Intracomm object at 0x7f5d2e297a50>","annotation":"<class \'mpi4py.MPI.Comm\'>","description":"MPI communicator (default=MPI.COMM_WORLD)"}},"source":{"code":"    def __init__(self, uid: str, path: str, comm: MPI.Comm = MPI.COMM_WORLD):\\n        self.uid = uid\\n        self.path_database = os.path.abspath(path)\\n        self.path = os.path.abspath(os.path.join(path, uid))\\n        self.h5file = os.path.join(self.path, f\\"{self.uid}.h5\\")\\n        self.xdmffile = os.path.join(self.path, f\\"{self.uid}.xdmf\\")\\n        os.makedirs(self.path, exist_ok=True)\\n\\n        # MPI information\\n        self._comm = comm\\n        self._psize = self._comm.size\\n        self._prank = self._comm.rank\\n        self._ranks = np.array([i for i in range(self._psize)])\\n\\n        self._file = FileHandler(self.h5file)\\n\\n        # Initialize groups to meshes, data and userdata. Create groups.\\n        self.meshes = MeshGroup(self._file)\\n        self.data = DataGroup(self._file, self.meshes)\\n        self.userdata = hdf_pointer.MutableGroup(self._file, \\"/userdata\\")\\n        self.links = Links(self._file)\\n","lines":[90,110]}}},"Hi":{"name":"SimulationWriter","docstring":"The SimulationWriter is the writer object for a single simulation. It inherits all reading methods from :class:`Simulation`.","variables":{"step":"","uid":"","path_database":"","path":"","h5file":"","xdmffile":"","meshes":"","data":"","userdata":"","links":"","parameters":"","metadata":"","mesh":"","globals":": pandas.core.frame.DataFrame","data_info":": \'pd.Dataframe\'","git":": dict"},"methods":{"initialize":{"docstring":"Create a new file for this simlation. This deletes an existing h5 file of the simulation and creates an empty new one","signature":"(self) -> bamboost.simulation_writer.SimulationWriter","returns":{"annotation":"<class \'bamboost.simulation_writer.SimulationWriter\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def initialize(self) -> SimulationWriter:\\n        \\"\\"\\"Create a new file for this simlation.\\n        This deletes an existing h5 file of the simulation and creates an empty new one\\n        \\"\\"\\"\\n        self.step = 0\\n        self.add_metadata()\\n        self.change_status(\\"Initiated\\")\\n\\n        return self\\n","lines":[54,62]}},"add_metadata":{"docstring":"Add metadata to h5 file. ","signature":"(self) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def add_metadata(self) -> None:\\n        \\"\\"\\"Add metadata to h5 file.\\"\\"\\"\\n        nb_proc = self._comm.Get_size()\\n        if self._prank == 0:\\n            with self._file(\\"a\\"):\\n                self._file.attrs[\\"time_stamp\\"] = str(\\n                    datetime.datetime.now().replace(microsecond=0)\\n                )\\n                self._file.attrs[\\"id\\"] = self.uid\\n                self._file.attrs[\\"processors\\"] = nb_proc\\n                self._file.attrs[\\"notes\\"] = self._file.attrs.get(\\"notes\\", \\"\\")\\n","lines":[64,74]}},"add_parameters":{"docstring":"Add parameters to simulation. ","signature":"(self, parameters: dict) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"parameters":{"default":null,"annotation":"<class \'dict\'>","description":"Dictionary with parameters."}},"source":{"code":"    def add_parameters(self, parameters: dict) -> None:\\n        \\"\\"\\"Add parameters to simulation.\\n\\n        Args:\\n            parameters: Dictionary with parameters.\\n        \\"\\"\\"\\n        if self._prank == 0:\\n            with self._file(\\"a\\"):\\n                # flatten parameters\\n                parameters = flatten_dict(parameters)\\n\\n                if \\"parameters\\" in self._file.keys():\\n                    del self._file[\\"parameters\\"]\\n                grp = self._file.create_group(\\"/parameters\\")\\n                for key, val in parameters.items():\\n                    if isinstance(val, np.ndarray):\\n                        grp.create_dataset(key, data=val)\\n                    elif val is not None:\\n                        grp.attrs[key] = val\\n                    else:\\n                        pass\\n","lines":[76,96]}},"add_mesh":{"docstring":"Add the mesh to file. Currently only 2d meshes. ","signature":"(\\n    self,\\n    coordinates: numpy.ndarray,\\n    connectivity: numpy.ndarray,\\n    mesh_name: str = None\\n) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"coordinates":{"default":null,"annotation":"<class \'numpy.ndarray\'>","description":"Coordinates as array (nb_nodes, dim)"},"connectivity":{"default":null,"annotation":"<class \'numpy.ndarray\'>","description":"Connectivity matrix (nb_cells, nb nodes per cell)"},"mesh_name":{"default":"None","annotation":"<class \'str\'>","description":"name for mesh (default = `mesh`)"}},"source":{"code":"    def add_mesh(\\n        self, coordinates: np.ndarray, connectivity: np.ndarray, mesh_name: str = None\\n    ) -> None:\\n        \\"\\"\\"Add the mesh to file. Currently only 2d meshes.\\n\\n        Args:\\n            coordinates: Coordinates as array (nb_nodes, dim)\\n            connectivity: Connectivity matrix (nb_cells, nb nodes per cell)\\n            mesh_name: name for mesh (default = `mesh`)\\n        \\"\\"\\"\\n        if mesh_name is None:\\n            mesh_name = self._default_mesh\\n        # self._mesh_location = \'Mesh/0/mesh/\'\\n        mesh_location = f\\"{self._mesh_location}/{mesh_name}/\\"\\n\\n        nb_nodes_local = coordinates.shape[0]\\n        nb_cells_local = connectivity.shape[0]\\n\\n        # gather total mesh\\n        nb_nodes_p = np.array(self._comm.allgather(nb_nodes_local))\\n        nb_cells_p = np.array(self._comm.allgather(nb_cells_local))\\n        nb_nodes, nb_cells = np.sum(nb_nodes_p), np.sum(nb_cells_p)\\n\\n        # shape of datasets\\n        coord_shape = (\\n            (nb_nodes, coordinates.shape[1]) if coordinates.ndim > 1 else (nb_nodes,)\\n        )\\n        conn_shape = (\\n            (nb_cells, connectivity.shape[1]) if connectivity.ndim > 1 else (nb_cells,)\\n        )\\n\\n        # global indices nodes\\n        idx_start = np.sum(nb_nodes_p[self._ranks < self._prank])\\n        idx_end = idx_start + nb_nodes_local\\n\\n        # global indices cells\\n        idx_start_cells = np.sum(nb_cells_p[self._ranks < self._prank])\\n        idx_end_cells = idx_start_cells + nb_cells_local\\n        connectivity = connectivity + idx_start\\n\\n        with self._file(\\"a\\", driver=\\"mpio\\", comm=self._comm) as f:\\n            if mesh_location in self._file.file_object:\\n                del self._file.file_object[mesh_location]\\n            grp = f.require_group(mesh_location)\\n            coord = grp.require_dataset(\\"geometry\\", shape=coord_shape, dtype=\\"f\\")\\n            conn = grp.require_dataset(\\"topology\\", shape=conn_shape, dtype=\\"i\\")\\n\\n            coord[idx_start:idx_end] = coordinates\\n            conn[idx_start_cells:idx_end_cells] = connectivity\\n\\n            coord.flush()\\n            conn.flush()\\n","lines":[98,149]}},"add_field":{"docstring":"Add a dataset to the file. The data is stored at `data/`. ","signature":"(\\n    self,\\n    name: str,\\n    vector: <built-in function array>,\\n    time: float = None,\\n    mesh: str = None\\n) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"name":{"default":null,"annotation":"<class \'str\'>","description":"Name for the dataset"},"vector":{"default":null,"annotation":"<built-in function array>","description":"Dataset"},"time":{"default":"None","annotation":"<class \'float\'>","description":"Optional. time"},"mesh":{"default":"None","annotation":"<class \'str\'>","description":"Optional. Linked mesh for this data"}},"source":{"code":"    def add_field(\\n        self, name: str, vector: np.array, time: float = None, mesh: str = None\\n    ) -> None:\\n        \\"\\"\\"Add a dataset to the file. The data is stored at `data/`.\\n\\n        Args:\\n            name: Name for the dataset\\n            vector: Dataset\\n            time: Optional. time\\n            mesh: Optional. Linked mesh for this data\\n        \\"\\"\\"\\n        if mesh is None:\\n            mesh = self._default_mesh\\n\\n        # Get dimension of vector\\n        if vector.ndim <= 1:\\n            vector = vector.reshape((-1, 1))\\n        dim = vector.shape[1]\\n\\n        if time is None:\\n            time = self.step\\n\\n        length_local = vector.shape[0]\\n        length_p = np.array(self._comm.allgather(length_local))\\n        length = np.sum(length_p)\\n\\n        # global indices\\n        idx_start = np.sum(length_p[self._ranks < self._prank])\\n        idx_end = idx_start + length_local\\n\\n        # open file\\n        with self._file(\\"a\\", driver=\\"mpio\\", comm=self._comm) as f:\\n            data = f.require_group(\\n                \\"data\\"\\n            )  # Require group data to store all point data in\\n            grp = data.require_group(name)\\n            vec = grp.require_dataset(str(self.step), shape=(length, dim), dtype=\\"f\\")\\n            vec[idx_start:idx_end, :] = vector\\n\\n            vec.attrs[\\"t\\"] = time  # add time as attribute to dataset\\n            vec.attrs[\\"mesh\\"] = mesh  # add link to mesh as attribute\\n            vec.flush()\\n","lines":[151,192]}},"add_global_field":{"docstring":"Add a gobal field. These are stored at `gloals/` as an array in a single dataset.","signature":"(self, name: str, value: float) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"name":{"default":null,"annotation":"<class \'str\'>","description":"Name for the data"},"value":{"default":null,"annotation":"<class \'float\'>","description":"Data"}},"source":{"code":"    def add_global_field(self, name: str, value: float) -> None:\\n        \\"\\"\\"Add a gobal field. These are stored at `gloals/` as an array in a\\n        single dataset.\\n\\n        Args:\\n            name: Name for the data\\n            value: Data\\n        \\"\\"\\"\\n        if self._prank == 0:\\n            with self._file(\\"a\\") as f:\\n                grp = f.require_group(\\"globals\\")\\n                if name not in grp.keys():\\n                    vec = grp.create_dataset(\\n                        name, shape=(1,), dtype=\\"f\\", chunks=True, maxshape=(None,)\\n                    )\\n                    vec[0] = value\\n                else:\\n                    vec = grp[name]\\n                    vec.resize((self.step + 1,))\\n                    vec[-1] = value\\n                vec.flush()\\n","lines":[194,214]}},"add_additional":{"docstring":"Add an additional file stored elsewhere or in database directory. ","signature":"(self, name: str, file: str) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"name":{"default":null,"annotation":"<class \'str\'>","description":"Name of data"},"file":{"default":null,"annotation":"<class \'str\'>","description":"filename of file"}},"source":{"code":"    def add_additional(self, name: str, file: str) -> None:\\n        \\"\\"\\"Add an additional file stored elsewhere or in database directory.\\n\\n        Args:\\n            name: Name of data\\n            file: filename of file\\n        \\"\\"\\"\\n        if self._prank == 0:\\n            with self._file(\\"a\\") as f:\\n                grp = f.require_group(\\"additionals\\")\\n                grp.attrs.update({name: file})\\n","lines":[216,226]}},"finish_step":{"docstring":"Finish step. Adds 1 to the step counter. ","signature":"(self) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def finish_step(self) -> None:\\n        \\"\\"\\"Finish step. Adds 1 to the step counter.\\"\\"\\"\\n        self.step += 1\\n","lines":[228,230]}},"finish_sim":{"docstring":"None ","signature":"(self, status: str = \'Finished\') -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"status":{"default":"Finished","annotation":"<class \'str\'>","description":null}},"source":{"code":"    def finish_sim(self, status: str = \\"Finished\\") -> None:\\n        if self._prank == 0:\\n            self.change_status(status)\\n","lines":[232,234]}},"register_git_attributes":{"docstring":"Register git information for given repo. ","signature":"(self, repo_path: str = \'./\') -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"repo_path":{"default":"./","annotation":"<class \'str\'>","description":"path to git repository"}},"source":{"code":"    def register_git_attributes(self, repo_path: str = \\"./\\") -> None:\\n        \\"\\"\\"Register git information for given repo.\\n\\n        Args:\\n            repo_path (`str`): path to git repository\\n        \\"\\"\\"\\n        if self._prank == 0:\\n            repo_path = os.path.abspath(repo_path)\\n            # store current working directory\\n            cwd = os.getcwd()\\n\\n            # switch directory to git repo\\n            os.chdir(repo_path)\\n            git_string = GitStateGetter().create_git_string()\\n\\n            # switch working directory back\\n            os.chdir(cwd)\\n\\n            with self._file(\\"a\\") as f:\\n                grp = f.require_group(\\"git\\")\\n                repo_name = os.path.split(repo_path)[1]\\n                print(f\\"Adding repo {repo_name}\\")\\n                if repo_name in grp.keys():\\n                    del grp[repo_name]\\n                grp.create_dataset(repo_name, data=git_string)\\n","lines":[236,260]}},"copy_executable":{"docstring":"WILL BE REMOVED. USE COPY_FILE. Copy an executable to directory for reproducability.","signature":"(self, script_path: str) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"script_path":{"default":null,"annotation":"<class \'str\'>","description":"path to script"}},"source":{"code":"    def copy_executable(self, script_path: str) -> None:\\n        \\"\\"\\"WILL BE REMOVED. USE COPY_FILE.\\n        Copy an executable to directory for reproducability.\\n\\n        Args:\\n            script_path: path to script\\n        \\"\\"\\"\\n        shutil.copy(script_path, self.path)\\n        self.executable = os.path.split(script_path)[1]\\n","lines":[262,270]}},"copy_file":{"docstring":"Copy a file to the datafolder. ","signature":"(self, source: Union[str, list], destination: str = \'\') -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"source":{"default":null,"annotation":"typing.Union[str, list]","description":"path to file, or list of files"},"destination":{"default":"","annotation":"<class \'str\'>","description":"destination (will create intermediatory directories)"}},"source":{"code":"    def copy_file(self, source: Union[str, list], destination: str = \\"\\") -> None:\\n        \\"\\"\\"Copy a file to the datafolder.\\n\\n        Args:\\n            source: path to file, or list of files\\n            destination: destination (will create intermediatory directories)\\n        \\"\\"\\"\\n        if isinstance(source, list):\\n            for item in source:\\n                self.copy_file(item, destination)\\n            return\\n\\n        destination = os.path.join(self.path, destination)\\n\\n        if os.path.isdir(source):\\n            shutil.copytree(\\n                source,\\n                os.path.join(destination, os.path.basename(source)),\\n                dirs_exist_ok=True,\\n            )\\n        elif os.path.isfile(source):\\n            os.makedirs(destination, exist_ok=True)\\n            shutil.copy(source, destination)\\n        else:\\n            raise FileNotFoundError\\n","lines":[272,296]}},"__getitem__":{"docstring":"Direct access to HDF5 file. ","signature":"(self, key) -> bamboost.common.hdf_pointer.BasePointer","returns":{"annotation":"<class \'bamboost.common.hdf_pointer.BasePointer\'>","description":":class:`~bamboost.common.file_handler.BasePointer`"},"arguments":{"self":{"default":null,"annotation":null,"description":null},"key":{"default":null,"annotation":null,"description":null}},"source":{"code":"    @with_file_open()\\n    def __getitem__(self, key) -> hdf_pointer.BasePointer:\\n        \\"\\"\\"Direct access to HDF5 file.\\n\\n        Returns:\\n            :class:`~bamboost.common.file_handler.BasePointer`\\n        \\"\\"\\"\\n        return hdf_pointer.BasePointer.new_pointer(self._file, key)\\n","lines":[123,130]}},"show_files":{"docstring":"Show the file tree of the simulation directory. ","signature":"(\\n    self,\\n    level=-1,\\n    limit_to_directories=False,\\n    length_limit=1000,\\n    printit=True\\n) -> str","returns":{"annotation":"<class \'str\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"level":{"default":"-1","annotation":null,"description":"how deep to print the tree"},"limit_to_directories":{"default":"False","annotation":null,"description":"only print directories"},"length_limit":{"default":"1000","annotation":null,"description":"cutoff"},"printit":{"default":"True","annotation":null,"description":null}},"source":{"code":"    def show_files(\\n        self, level=-1, limit_to_directories=False, length_limit=1000, printit=True\\n    ) -> str:\\n        \\"\\"\\"Show the file tree of the simulation directory.\\n\\n        Args:\\n            level: how deep to print the tree\\n            limit_to_directories: only print directories\\n            length_limit: cutoff\\n        \\"\\"\\"\\n        tree_string = utilities.tree(\\n            self.path, level, limit_to_directories, length_limit\\n        )\\n        if printit:\\n            print(tree_string)\\n        else:\\n            return tree_string\\n","lines":[210,226]}},"open_in_file_explorer":{"docstring":"Open the simulation directory. Uses `xdg-open` on linux systems. ","signature":"(self) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def open_in_file_explorer(self) -> None:\\n        \\"\\"\\"Open the simulation directory. Uses `xdg-open` on linux systems.\\"\\"\\"\\n        if os.name == \\"nt\\":  # should work on Windows\\n            os.startfile(self.path)\\n        else:\\n            subprocess.run([\\"xdg-open\\", self.path])\\n","lines":[228,233]}},"get_full_uid":{"docstring":"Returns the full uid of the simulation (including the one of the database) ","signature":"(self) -> str","returns":{"annotation":"<class \'str\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def get_full_uid(self) -> str:\\n        \\"\\"\\"Returns the full uid of the simulation (including the one of the database)\\"\\"\\"\\n        database_uid = index.get_uid_from_path(self.path_database)\\n        return f\\"{database_uid}:{self.uid}\\"\\n","lines":[235,238]}},"change_status":{"docstring":"Change status of simulation. ","signature":"(self, status: str) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"status":{"default":null,"annotation":"<class \'str\'>","description":"new status"}},"source":{"code":"    @with_file_open(\\"a\\")\\n    def change_status(self, status: str) -> None:\\n        \\"\\"\\"Change status of simulation.\\n\\n        Args:\\n            status (str): new status\\n        \\"\\"\\"\\n        if self._prank == 0:\\n            self._file.attrs[\\"status\\"] = status\\n","lines":[240,248]}},"update_metadata":{"docstring":"Update the metadata attributes. ","signature":"(self, update_dict: dict) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"update_dict":{"default":null,"annotation":"<class \'dict\'>","description":"dictionary to push"}},"source":{"code":"    def update_metadata(self, update_dict: dict) -> None:\\n        \\"\\"\\"Update the metadata attributes.\\n\\n        Args:\\n            update_dict: dictionary to push\\n        \\"\\"\\"\\n        with self._file(\\"a\\") as file:\\n            file.attrs.update(update_dict)\\n","lines":[250,257]}},"update_parameters":{"docstring":"Update the parameters dictionary. ","signature":"(self, update_dict: dict) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"update_dict":{"default":null,"annotation":"<class \'dict\'>","description":"dictionary to push"}},"source":{"code":"    def update_parameters(self, update_dict: dict) -> None:\\n        \\"\\"\\"Update the parameters dictionary.\\n\\n        Args:\\n            update_dict: dictionary to push\\n        \\"\\"\\"\\n        if self._prank == 0:\\n            with self._file(\\"a\\") as file:\\n                file[\\"parameters\\"].attrs.update(update_dict)\\n","lines":[259,267]}},"create_xdmf_file":{"docstring":"Create the xdmf file to read in paraview. ","signature":"(self, fields: list = None, nb_steps: int = None) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"fields":{"default":"None","annotation":"<class \'list\'>","description":"fields for which to write timeseries information, if not specified, all fields in data are written."},"nb_steps":{"default":"None","annotation":"<class \'int\'>","description":"number of steps the simulation has"}},"source":{"code":"    def create_xdmf_file(self, fields: list = None, nb_steps: int = None) -> None:\\n        \\"\\"\\"Create the xdmf file to read in paraview.\\n\\n        Args:\\n            fields (list[str]): fields for which to write timeseries information,\\n                if not specified, all fields in data are written.\\n            nb_steps (int): number of steps the simulation has\\n        \\"\\"\\"\\n\\n        if self._comm.rank == 0:\\n            with self._file(\\"r\\") as f:\\n                if not fields:\\n                    fields = list(f[\\"data\\"].keys())\\n\\n                if not nb_steps:\\n                    grp_name = list(f[\\"data\\"].keys())[0]\\n                    nb_steps = list(f[f\\"data/{grp_name}\\"].keys())\\n                    nb_steps = max([int(step) for step in nb_steps])\\n\\n            xdmf_writer = XDMFWriter(self.xdmffile, self.h5file)\\n            xdmf_writer.write_points_cells(\\n                f\\"{self._mesh_location}/{self._default_mesh}/geometry\\",\\n                f\\"{self._mesh_location}/{self._default_mesh}/topology\\",\\n            )\\n\\n            xdmf_writer.add_timeseries(nb_steps + 1, fields)\\n            xdmf_writer.write_file()\\n","lines":[269,295]}},"create_batch_script":{"docstring":"Create a batch job and put it into the folder. ","signature":"(\\n    self,\\n    commands: list = None,\\n    nnodes=1,\\n    ntasks=4,\\n    ncpus=1,\\n    time=\'04:00:00\',\\n    mem_per_cpu=2048,\\n    tmp=8000,\\n    euler=True\\n) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"commands":{"default":"None","annotation":"<class \'list\'>","description":"A list of strings being the user defined commands to run"},"nnodes":{"default":"1","annotation":null,"description":"nb of nodes (default=1)"},"ntasks":{"default":"4","annotation":null,"description":"nb of tasks (default=4)"},"ncpus":{"default":"1","annotation":null,"description":"nb of cpus per task (default=1)"},"time":{"default":"04:00:00","annotation":null,"description":"requested time (default=4 hours)"},"mem_per_cpu":{"default":"2048","annotation":null,"description":"memory (default=2048)"},"tmp":{"default":"8000","annotation":null,"description":"temporary storage, set None to exclude option (default=8000)"},"euler":{"default":"True","annotation":null,"description":"If false, a local bash script will be written"}},"source":{"code":"    def create_batch_script(\\n        self,\\n        commands: list = None,\\n        nnodes=1,\\n        ntasks=4,\\n        ncpus=1,\\n        time=\\"04:00:00\\",\\n        mem_per_cpu=2048,\\n        tmp=8000,\\n        euler=True,\\n    ) -> None:\\n        \\"\\"\\"Create a batch job and put it into the folder.\\n\\n        Args:\\n            commands: A list of strings being the user defined commands to run\\n            nnodes: nb of nodes (default=1)\\n            ntasks: nb of tasks (default=4)\\n            ncpus: nb of cpus per task (default=1)\\n            time: requested time (default=4 hours)\\n            mem_per_cpu: memory (default=2048)\\n            tmp: temporary storage, set None to exclude option (default=8000)\\n            euler: If false, a local bash script will be written\\n        \\"\\"\\"\\n        job = Job()\\n        if not commands:\\n            if hasattr(self, \\"executable\\"):\\n                if \\".py\\" in self.executable:\\n                    command = (\\n                        f\\"{{MPI}} python3 {os.path.join(self.path, self.executable)} \\"\\n                        f\\"--path {self.path_database} --uid {self.uid}\\"\\n                    )\\n                    commands = [command]\\n            else:\\n                raise AttributeError(\\n                    \\"\\"\\"Either you must specify an executable or have it \\n                                     copied before with `copy_executable`!\\"\\"\\"\\n                )\\n\\n        if euler:\\n            job.create_sbatch_script(\\n                commands,\\n                path=os.path.abspath(self.path_database),\\n                uid=self.uid,\\n                nnodes=nnodes,\\n                ntasks=ntasks,\\n                ncpus=ncpus,\\n                time=time,\\n                mem_per_cpu=mem_per_cpu,\\n                tmp=tmp,\\n            )\\n        else:\\n            job.create_bash_script_local(\\n                commands,\\n                path=os.path.abspath(self.path_database),\\n                uid=self.uid,\\n                ntasks=ntasks,\\n            )\\n        with self._file(\\"a\\") as file:\\n            file.attrs.update({\\"submitted\\": False})\\n","lines":[297,355]}},"submit":{"docstring":"Submit the job for this simulation. ","signature":"(self) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def submit(self) -> None:\\n        \\"\\"\\"Submit the job for this simulation.\\"\\"\\"\\n        batch_script = os.path.abspath(os.path.join(self.path, f\\"sbatch_{self.uid}.sh\\"))\\n        subprocess.Popen([\\"sbatch\\", f\\"{batch_script}\\"])\\n        print(f\\"Simulation {self.uid} submitted!\\")\\n\\n        with self._file(\\"a\\") as file:\\n            file.attrs.update({\\"submitted\\": True})\\n","lines":[357,364]}},"change_note":{"docstring":"None ","signature":"(self, note) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"note":{"default":null,"annotation":null,"description":null}},"source":{"code":"    @with_file_open(\\"a\\")\\n    def change_note(self, note) -> None:\\n        self._file.attrs[\\"notes\\"] = note\\n","lines":[366,368]}},"open":{"docstring":"Use this as a context manager in a `with` statement. Purpose: keeping the file open to directly access/edit something in the HDF5 file of this simulation.","signature":"(\\n    self,\\n    mode: str = \'r\',\\n    driver=None,\\n    comm=None\\n) -> bamboost.common.file_handler.FileHandler","returns":{"annotation":"<class \'bamboost.common.file_handler.FileHandler\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"mode":{"default":"r","annotation":"<class \'str\'>","description":"file mode (see h5py docs)"},"driver":{"default":"None","annotation":null,"description":"file driver (see h5py docs)"},"comm":{"default":"None","annotation":null,"description":"mpi communicator"}},"source":{"code":"    def open(self, mode: str = \\"r\\", driver=None, comm=None) -> FileHandler:\\n        \\"\\"\\"Use this as a context manager in a `with` statement.\\n        Purpose: keeping the file open to directly access/edit something in the\\n        HDF5 file of this simulation.\\n\\n        Args:\\n            mode (`str`): file mode (see h5py docs)\\n            driver (`str`): file driver (see h5py docs)\\n            comm (`str`): mpi communicator\\n        \\"\\"\\"\\n        return self._file(mode, driver, comm)\\n","lines":[373,383]}},"get_mesh":{"docstring":"Return coordinates and connectivity. Currently returns numpy arrays. ","signature":"(self, mesh_name: str = None) -> Tuple[numpy.ndarray, numpy.ndarray]","returns":{"annotation":"typing.Tuple[numpy.ndarray, numpy.ndarray]","description":"Tuple of np.arrays (coordinates, connectivity)"},"arguments":{"self":{"default":null,"annotation":null,"description":null},"mesh_name":{"default":"None","annotation":"<class \'str\'>","description":"optional, name of mesh to read (default = mesh)"}},"source":{"code":"    @with_file_open(\\"r\\")\\n    def get_mesh(self, mesh_name: str = None) -> Tuple[np.ndarray, np.ndarray]:\\n        \\"\\"\\"Return coordinates and connectivity. Currently returns numpy arrays.\\n\\n        Args:\\n            mesh_name (`str`): optional, name of mesh to read (default = mesh)\\n        Returns:\\n            Tuple of np.arrays (coordinates, connectivity)\\n        \\"\\"\\"\\n        if mesh_name is None:\\n            mesh_name = self._default_mesh\\n\\n        mesh = self.meshes[mesh_name]\\n        return mesh.coordinates, mesh.connectivity\\n","lines":[394,407]}},"get_data_interpolator":{"docstring":"Get Linear interpolator for data field at step. Uses the linked mesh. ","signature":"(self, field: str, step: int)","returns":{"annotation":"<class \'inspect._empty\'>","description":":class:`scipy.interpolate.LinearNDInterpolator`"},"arguments":{"self":{"default":null,"annotation":null,"description":null},"field":{"default":null,"annotation":"<class \'str\'>","description":null},"step":{"default":null,"annotation":"<class \'int\'>","description":"step"}},"source":{"code":"    def get_data_interpolator(self, field: str, step: int):\\n        \\"\\"\\"Get Linear interpolator for data field at step. Uses the linked mesh.\\n\\n        Args:\\n            name (`str`): name of the data field\\n            step (`int`): step\\n        Returns:\\n            :class:`scipy.interpolate.LinearNDInterpolator`\\n        \\"\\"\\"\\n        from scipy.interpolate import LinearNDInterpolator\\n\\n        return LinearNDInterpolator(\\n            self.data[field].mesh.coordinates, self.data[field].at_step(step)\\n        )\\n","lines":[457,470]}},"show_h5tree":{"docstring":"Print the tree inside the h5 file. ","signature":"(self) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    @with_file_open()\\n    def show_h5tree(self) -> None:\\n        \\"\\"\\"Print the tree inside the h5 file.\\"\\"\\"\\n        # print(\'\\\\U00002B57 \' + os.path.basename(self.h5file))\\n        print(\\"\\\\U0001F43C \\" + os.path.basename(self.h5file))\\n        utilities.h5_tree(self._file.file_object)\\n","lines":[472,477]}}},"constructor":{"signature":"(\\n    uid: str,\\n    path: str,\\n    comm: mpi4py.MPI.Comm = <mpi4py.MPI.Intracomm object>\\n)","arguments":{"self":{"default":null,"annotation":null,"description":null},"uid":{"default":null,"annotation":"<class \'str\'>","description":"The identifier of the simulation"},"path":{"default":null,"annotation":"<class \'str\'>","description":"The (parent) database path"},"comm":{"default":"<mpi4py.MPI.Intracomm object at 0x7f5d2e297a50>","annotation":"<class \'mpi4py.MPI.Comm\'>","description":"An MPI communicator (Default: `MPI.COMM_WORLD`)"}},"source":{"code":"    def __init__(self, uid: str, path: str, comm: MPI.Comm = MPI.COMM_WORLD):\\n        super().__init__(uid, path, comm)\\n        self.step = 0\\n","lines":[40,42]}}}}')}}]);