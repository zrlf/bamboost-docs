"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[2957],{7152:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>d,default:()=>m,frontMatter:()=>r,metadata:()=>u,toc:()=>f});var s=t(5893),i=t(1151),a=t(2055),o=t(8213),l=t(3607);const r={title:"git_utility"},d=void 0,u={id:"autoDocs/common/git_utility",title:"git_utility",description:"TOP",source:"@site/docs/autoDocs/common/git_utility.md",sourceDirName:"autoDocs/common",slug:"/autoDocs/common/git_utility",permalink:"/bamboost-docs/docs/autoDocs/common/git_utility",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{title:"git_utility"},sidebar:"autoDocsSidebar",previous:{title:"file_handler",permalink:"/bamboost-docs/docs/autoDocs/common/file_handler"},next:{title:"hdf_pointer",permalink:"/bamboost-docs/docs/autoDocs/common/hdf_pointer"}},c={},f=[{value:"TOP",id:"top",level:2},{value:"GitStateGetter",id:"gitstategetter",level:2}];function p(e){const n={h2:"h2",...(0,i.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h2,{id:"top",children:"TOP"}),"\n",(0,s.jsx)(a.s,{data:l,moduleFullName:"bamboost.common.git_utility"}),"\n",(0,s.jsx)(n.h2,{id:"gitstategetter",children:"GitStateGetter"}),"\n",(0,s.jsx)(a.n,{data:l,classFullName:"bamboost.common.git_utility.GitStateGetter"}),"\n",(0,s.jsx)(o.o,{})]})}function m(e={}){const{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(p,{...e})}):p(e)}},2055:(e,n,t)=>{t.d(n,{n:()=>m,s:()=>_});var s=t(6911),i=t(7294),a=t(6010),o=t(9960),l=t(5893);const r=e=>{const n=e.name,t=e.obj,[s,o]=(0,i.useState)(!1),[r,f]=(0,i.useState)(!0);return(0,l.jsxs)("div",{className:(0,a.Z)(!e.isNotMethod&&"method"),children:[(0,l.jsxs)("div",{className:"method-title",children:[(0,l.jsx)("div",{onClick:()=>f(!r),children:(0,l.jsx)(l.Fragment,{children:!e.isNotMethod&&(t.props.isClassMethod?(0,l.jsx)("i",{className:"fa-solid fa-c icon"}):(0,l.jsx)("i",{className:"fa-solid fa-m icon"}))})}),(0,l.jsx)("h3",{id:n,style:{display:"inline-block"},children:(0,l.jsx)("span",{children:n})}),(0,l.jsx)(c,{sourceIsVisible:s,setSourceIsVisible:o})]}),(0,l.jsx)(d,{name:n,signature:t.signature,sourceIsVisible:s}),(0,l.jsx)(u,{source_code:t.source.code,starting_line_number:t.source.lines[0],sourceIsVisible:s}),r&&(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)("p",{children:t.docstring}),(0,l.jsxs)("div",{className:"parameters",children:[(0,l.jsx)("b",{children:"Parameters:"}),(0,l.jsx)("ul",{children:Object.entries(t.arguments).map(((e,n)=>{let[t,s]=e;return(0,l.jsxs)("li",{children:[(0,l.jsx)("b",{children:t})," : ",(0,l.jsx)("i",{children:s.annotation}),(0,l.jsx)("p",{className:"parameter-description",children:s.description})]},`args_${n}`)}))})]}),(0,l.jsxs)("div",{className:"parameters",children:[(0,l.jsx)("b",{children:"Returns:"}),(0,l.jsxs)("ul",{children:[(0,l.jsx)("i",{children:t.returns.annotation}),(0,l.jsx)("p",{className:"parameter-description",children:t.returns.description})]})]})]})]})},d=e=>{let{name:n,signature:t,sourceIsVisible:i}=e;return(0,l.jsx)("div",{className:(0,a.Z)("signature",i&&"sourceIsVisible"),children:(0,l.jsxs)(s.Z,{language:"py",children:[n," ",t]})})},u=e=>{let{source_code:n,starting_line_number:t,sourceIsVisible:i}=e;return(0,l.jsx)(l.Fragment,{children:i&&(0,l.jsx)("div",{className:"source-code-div",children:(0,l.jsx)(s.Z,{language:"py",showLineNumbers:!0,startingLineNumber:t,children:n})})})},c=e=>{let{sourceIsVisible:n,setSourceIsVisible:t}=e;return(0,l.jsx)("button",{className:"sourceButton",onClick:()=>t((e=>!e)),children:n?(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)("i",{className:"fa-solid fa-chevron-down icon"})," source code"]}):(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)("i",{className:"fa-solid fa-chevron-right icon"})," source code"]})})},f=e=>{let{cls:n}=e;const t=n.constructor.source.code,s=n.constructor.source.lines[0],a=n.constructor.signature,o=n.name,[r,f]=(0,i.useState)(!1);return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)("div",{style:{position:"relative"},children:(0,l.jsx)(c,{sourceIsVisible:r,setSourceIsVisible:f})}),(0,l.jsx)(d,{name:o,signature:a,sourceIsVisible:r}),(0,l.jsx)(u,{source_code:t,starting_line_number:s,sourceIsVisible:r})]})},p=e=>{let{cls:n}=e;const t=Object.entries(n.inherits_from).map(((e,n)=>{let[t,s]=e;return{name:t,link:`/docs/autoDocs/${t.split(".").slice(1).join("/")}`,inheritedMember:s.map((e=>({type:e[0],name:e[1],link:`/docs/autoDocs/${t.split(".").slice(1).join("/")}#${e[1]}`})))}}));return console.log(t[0].link),(0,l.jsx)(l.Fragment,{children:t.map(((e,n)=>(0,l.jsxs)("li",{children:[(0,l.jsx)(o.Z,{to:e.link,children:e.name}),(0,l.jsx)("div",{className:"inherited-members-grid",children:e.inheritedMember.map(((e,n)=>(0,l.jsx)(o.Z,{className:"grid-item",to:e.link,children:e.name},`inherited_${n}`)))})]},`parent_${n}`)))})},m=e=>{let{data:n,classFullName:t,directCls:s}=e;let i={};i=s||(e=>{const t=e.split(".");let s=n;for(let n=1;n<t.length-1;n++)s=s.submodules[t[n]];return s=s.classes[t[t.length-1]],s})(t);const a=i.methods;return(0,l.jsxs)("div",{children:[(0,l.jsx)("p",{children:i.docstring}),(0,l.jsx)(f,{cls:i}),Object.keys(i.inherits_from).length>0&&(0,l.jsxs)("div",{children:[(0,l.jsx)("b",{children:"Inherits from:"}),(0,l.jsx)("ul",{children:(0,l.jsx)(p,{cls:i})})]}),(0,l.jsxs)("div",{className:"parameters",children:[(0,l.jsx)("b",{children:"Variables:"}),(0,l.jsx)("ul",{children:Object.keys(i.variables).map(((e,n)=>(0,l.jsxs)("li",{children:[(0,l.jsx)("b",{children:e})," : ",(0,l.jsx)("i",{children:i.variables[e].annotation}),(0,l.jsx)("p",{className:"parameter-description",children:i.variables[e].description})]},`variable_${n}`)))})]}),(0,l.jsx)("div",{className:"methods",children:Object.keys(a).map((e=>r({name:e,obj:a[e]})))})]})},_=e=>{let{data:n,moduleFullName:t}=e;const s=(e=>{const t=e.split(".");let s=n;for(let n=1;n<t.length-1;n++)s=s.submodules[t[n]];return s=s.submodules[t[t.length-1]],s})(t),i=(s.classes,s.functions),a=s.docstring;return(0,l.jsxs)("div",{children:["None"!=a&&(0,l.jsx)("p",{children:a}),(0,l.jsx)("div",{className:"functions",children:Object.entries(i).map(((e,n)=>{let[t,s]=e;return(0,l.jsx)("div",{children:(0,l.jsx)(r,{name:t,obj:s,isNotMethod:!0})},`function_${n}`)}))})]})}},8213:(e,n,t)=>{t.d(n,{o:()=>r});var s=t(7294),i=t(745),a=t(3935),o=t(5893);const l=e=>{let{headings:n,activeId:t}=e;return(0,o.jsx)("ul",{className:"custom-toc",children:n.map((e=>(0,o.jsxs)("li",{className:e.id===t?"active":"",children:[" ",(0,o.jsx)("a",{href:`#${e.id}`,onClick:n=>{n.preventDefault(),document.querySelector(`#${e.id}`).scrollIntoView({behavior:"smooth"})},children:e.title}),e.items.length>0&&(0,o.jsx)("ul",{children:e.items.map((e=>(0,o.jsxs)("li",{className:e.id===t?"active":"",children:[" ",(0,o.jsx)("a",{href:`#${e.id}`,onClick:n=>{n.preventDefault(),document.querySelector(`#${e.id}`).scrollIntoView({behavior:"smooth"})},children:e.title})]},e.id)))})]},e.id)))})},r=()=>{const[e,n]=(0,s.useState)(),{nestedHeadings:t}=(()=>{const[e,n]=(0,s.useState)([]);return(0,s.useEffect)((()=>{const e=(e=>{const n=[];return e.forEach(((e,t)=>{const{innerText:s,id:i}=e;"H2"===e.nodeName?n.push({id:i,title:s,items:[]}):"H3"===e.nodeName&&n.length>0&&n[n.length-1].items.push({id:i,title:s})})),n})(Array.from(document.querySelectorAll("h2, h3")));n(e)}),[]),{nestedHeadings:e}})(),[r,d]=(0,s.useState)(null);return(e=>{const n=(0,s.useRef)({});(0,s.useEffect)((()=>{const t=new IntersectionObserver((t=>{n.current=t.reduce(((e,n)=>(e[n.target.id]=n,e)),n.current);const i=[];Object.keys(n.current).forEach((e=>{const t=n.current[e];t.isIntersecting&&i.push(t)}));const a=e=>s.findIndex((n=>n.id===e));if(1===i.length)e(i[0].target.id);else if(i.length>1){const n=i.sort(((e,n)=>a(e.target.id)>a(n.target.id)));e(n[0].target.id)}}),{rootMargin:"0px 0px -40% 0px"}),s=Array.from(document.querySelectorAll("h2, h3"));return s.forEach((e=>t.observe(e))),()=>t.disconnect()}),[e])})(n),(0,s.useEffect)((()=>{const n=document.querySelector(".table-of-contents");n&&!r&&d((0,i.createRoot)(n)),n&&r&&setTimeout((()=>{(0,a.flushSync)((()=>{r.render((0,o.jsx)(l,{headings:t,activeId:e}))}))}),0)}),[t,e]),null}},3607:e=>{e.exports=JSON.parse('{"name":"bamboost","docstring":"None","classes":{},"functions":{"set_log_level":{"docstring":"None ","signature":"(level: int = 30)","returns":{"annotation":"<class \'inspect._empty\'>","description":null},"arguments":{"level":{"default":"30","annotation":"<class \'int\'>","description":null}},"source":{"code":"def set_log_level(level: int = 30):\\n    for handler in logging.root.handlers[:]:\\n        logging.root.removeHandler(handler)\\n    logging.basicConfig(level=os.environ.get(\\"LOGLEVEL\\", level))\\n","lines":[14,17]},"props":{"isClassMethod":false}}},"submodules":{"accessors":{"name":"bamboost.accessors","docstring":"None","classes":{},"functions":{},"submodules":{"meshes":{"name":"bamboost.accessors.meshes","docstring":"None","classes":{"MeshGroup":{"name":"MeshGroup","docstring":"Pointer to a location in an hdf5 file. The constructor takes a :class:`~.file_handler.FileHandler` and the in-file path to the object. The base class represents a generic group in the file","methods":{"__getitem__":{"docstring":"None ","signature":"(self, key) -> bamboost.accessors.meshes.Mesh","returns":{"annotation":"<class \'bamboost.accessors.meshes.Mesh\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"key":{"default":null,"annotation":null,"description":null}},"source":{"code":"    @with_file_open(\\"r\\")\\n    def __getitem__(self, key) -> Mesh:\\n        return Mesh(self._file, f\\"{self.path_to_data}/{key}\\")\\n","lines":[36,38]},"props":{"isClassMethod":false}}},"variables":{},"inherits_from":{"bamboost.common.hdf_pointer":[["function","new_pointer"],["variable","path_to_data"],["variable","obj"],["variable","attrs"]]},"constructor":{"signature":"(\\n    file_handler: bamboost.common.file_handler.FileHandler,\\n    path_to_data: str = \'/Mesh/0\',\\n    _default_mesh: str = \'mesh\',\\n    **kwargs\\n)","arguments":{"self":{"default":null,"annotation":null,"description":null},"file_handler":{"default":null,"annotation":"<class \'bamboost.common.file_handler.FileHandler\'>","description":"file this belongs to"},"path_to_data":{"default":"/Mesh/0","annotation":"<class \'str\'>","description":"infile path to object"},"_default_mesh":{"default":"mesh","annotation":"<class \'str\'>","description":null},"kwargs":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def __init__(\\n        self,\\n        file_handler: FileHandler,\\n        path_to_data: str = \\"/Mesh/0\\",\\n        _default_mesh: str = \\"mesh\\",\\n        **kwargs,\\n    ) -> None:\\n        super().__init__(file_handler, path_to_data, **kwargs)\\n        self._default_mesh = _default_mesh\\n","lines":[26,34]}}},"Mesh":{"name":"Mesh","docstring":"Pointer to a location in an hdf5 file. The constructor takes a :class:`~.file_handler.FileHandler` and the in-file path to the object. The base class represents a generic group in the file","methods":{"get_tuple":{"docstring":"None ","signature":"(self) -> Tuple[numpy.ndarray, numpy.ndarray]","returns":{"annotation":"typing.Tuple[numpy.ndarray, numpy.ndarray]","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    @with_file_open(\\"r\\")\\n    def get_tuple(self) -> Tuple[np.ndarray, np.ndarray]:\\n        return (self.coordinates, self.connectivity)\\n","lines":[55,57]},"props":{"isClassMethod":false}}},"variables":{"coordinates":{"annotation":"","description":null},"connectivity":{"annotation":"","description":null}},"inherits_from":{"bamboost.common.hdf_pointer":[["function","new_pointer"],["variable","path_to_data"],["variable","obj"],["function","__getitem__"],["variable","attrs"]]},"constructor":{"signature":"(\\n    file_handler: bamboost.common.file_handler.FileHandler,\\n    path_to_data: str\\n)","arguments":{"self":{"default":null,"annotation":null,"description":null},"file_handler":{"default":null,"annotation":"<class \'bamboost.common.file_handler.FileHandler\'>","description":"file this belongs to"},"path_to_data":{"default":null,"annotation":"<class \'str\'>","description":"infile path to object"}},"source":{"code":"    def __init__(self, file_handler: FileHandler, path_to_data: str) -> None:\\n        super().__init__(file_handler, path_to_data)\\n","lines":[42,43]}}}},"functions":{},"submodules":{}},"fielddata":{"name":"bamboost.accessors.fielddata","docstring":"None","classes":{"DataGroup":{"name":"DataGroup","docstring":"This pointer points to the data directory. Item accessor returns the individual data fields. `meshes` is passed to here for access of linked meshes.","methods":{"__getitem__":{"docstring":"None ","signature":"(self, key) -> bamboost.accessors.fielddata.FieldData","returns":{"annotation":"<class \'bamboost.accessors.fielddata.FieldData\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"key":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def __getitem__(self, key) -> FieldData:\\n        return FieldData(self._file, f\\"{self.path_to_data}/{key}\\", meshes=self.meshes)\\n","lines":[47,48]},"props":{"isClassMethod":false}},"__iter__":{"docstring":"None ","signature":"(self) -> bamboost.accessors.fielddata.FieldData","returns":{"annotation":"<class \'bamboost.accessors.fielddata.FieldData\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def __iter__(self) -> FieldData:\\n        for key in self.keys():\\n            yield self.__getitem__(key)\\n","lines":[50,52]},"props":{"isClassMethod":false}}},"variables":{"meshes":{"annotation":"","description":null},"info":{"annotation":": \'pd.Dataframe\'","description":"View the data stored. "}},"inherits_from":{"bamboost.common.hdf_pointer":[["function","new_pointer"],["variable","path_to_data"],["variable","obj"],["variable","attrs"]]},"constructor":{"signature":"(\\n    file_handler: bamboost.common.file_handler.FileHandler,\\n    meshes: bamboost.accessors.meshes.MeshGroup,\\n    path_to_data: str = \'/data\',\\n    **kwargs\\n)","arguments":{"self":{"default":null,"annotation":null,"description":null},"file_handler":{"default":null,"annotation":"<class \'bamboost.common.file_handler.FileHandler\'>","description":null},"meshes":{"default":null,"annotation":"<class \'bamboost.accessors.meshes.MeshGroup\'>","description":null},"path_to_data":{"default":"/data","annotation":"<class \'str\'>","description":null},"kwargs":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def __init__(\\n        self,\\n        file_handler: FileHandler,\\n        meshes: MeshGroup,\\n        path_to_data: str = \\"/data\\",\\n        **kwargs,\\n    ) -> None:\\n        super().__init__(file_handler, path_to_data, **kwargs)\\n        self.meshes = meshes\\n","lines":[37,45]}}},"FieldData":{"name":"FieldData","docstring":"This pointer points to a specific data field. `meshes` is passed to here for access of linked meshes.","methods":{"__getitem__":{"docstring":"None ","signature":"(self, key) -> numpy.ndarray","returns":{"annotation":"<class \'numpy.ndarray\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"key":{"default":null,"annotation":null,"description":null}},"source":{"code":"    @with_file_open(\\"r\\")\\n    def __getitem__(self, key) -> np.ndarray:\\n        return self._get_full_data()[key]\\n","lines":[92,94]},"props":{"isClassMethod":false}},"__len__":{"docstring":"None ","signature":"(self) -> int","returns":{"annotation":"<class \'int\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    @with_file_open(\\"r\\")\\n    def __len__(self) -> int:\\n        non_field_keys = set({self._vds_key, self._times_key})\\n        return len(self.keys() - non_field_keys)\\n","lines":[103,106]},"props":{"isClassMethod":false}},"at_step":{"docstring":"Direct access to data at step. Does not require the virtual dataset. ","signature":"(self, *steps: int) -> numpy.ndarray","returns":{"annotation":"<class \'numpy.ndarray\'>","description":":class:`np.ndarray`"},"arguments":{"self":{"default":null,"annotation":null,"description":null},"steps":{"default":null,"annotation":"<class \'int\'>","description":null}},"source":{"code":"    @with_file_open()\\n    def at_step(self, *steps: int) -> np.ndarray:\\n        \\"\\"\\"Direct access to data at step. Does not require the virtual dataset.\\n\\n        Args:\\n            step0, step1, ...: step to extract (can be multiple)\\n        Returns:\\n            :class:`np.ndarray`\\n        \\"\\"\\"\\n        data = list()\\n        for step in steps:\\n            if step < 0:\\n                step = len(self) + step\\n            data.append(self.obj[str(step)][()])\\n        if len(data) <= 1:\\n            return data[0]\\n        else:\\n            return data\\n","lines":[121,138]},"props":{"isClassMethod":false}},"regenerate_virtual_datasets":{"docstring":"Regenerate virtual dataset. Call this if the data has changed, thus the virtual datasets need to be updated to cover the actual data.","signature":"(self) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def regenerate_virtual_datasets(self) -> None:\\n        \\"\\"\\"Regenerate virtual dataset. Call this if the data has changed, thus the\\n        virtual datasets need to be updated to cover the actual data.\\n        \\"\\"\\"\\n        self._create_times()\\n        self._create_vds()\\n","lines":[179,184]},"props":{"isClassMethod":false}}},"variables":{"meshes":{"annotation":"","description":null},"shape":{"annotation":": tuple","description":null},"dtype":{"annotation":": type","description":null},"times":{"annotation":": numpy.ndarray","description":"Return the array of timestamps. "},"mesh":{"annotation":": bamboost.accessors.meshes.Mesh","description":"Return the linked mesh. Currently returns the linked mesh of first step only. "},"coordinates":{"annotation":": numpy.ndarray","description":"Wrapper for mesh.coordinates "},"connectivity":{"annotation":": numpy.ndarray","description":"Wrapper for mesh.connectivity "},"msh":{"annotation":": Tuple[numpy.ndarray, numpy.ndarray]","description":"Wrapper to get mesh as tuple "}},"inherits_from":{"bamboost.common.hdf_pointer":[["function","new_pointer"],["variable","path_to_data"],["variable","obj"],["variable","attrs"]]},"constructor":{"signature":"(\\n    file_handler: bamboost.common.file_handler.FileHandler,\\n    path_to_data: str,\\n    meshes: bamboost.accessors.meshes.MeshGroup\\n)","arguments":{"self":{"default":null,"annotation":null,"description":null},"file_handler":{"default":null,"annotation":"<class \'bamboost.common.file_handler.FileHandler\'>","description":null},"path_to_data":{"default":null,"annotation":"<class \'str\'>","description":null},"meshes":{"default":null,"annotation":"<class \'bamboost.accessors.meshes.MeshGroup\'>","description":null}},"source":{"code":"    def __init__(\\n        self, file_handler: FileHandler, path_to_data: str, meshes: MeshGroup\\n    ) -> None:\\n        super().__init__(file_handler, path_to_data)\\n        self.meshes = meshes\\n        self._name = path_to_data.split(\\"/\\")[-1]\\n","lines":[85,90]}}}},"functions":{},"submodules":{}}}},"common":{"name":"bamboost.common","docstring":"None","classes":{},"functions":{},"submodules":{"file_handler":{"name":"bamboost.common.file_handler","docstring":"None","classes":{"FileHandler":{"name":"FileHandler","docstring":"File handler for an hdf5 file with the purpose of handling opening and closing of the file. We use the concept of composition to include an object of this type in classes which need access to an hdf5 file (such as the hdf5pointer and Simulation.)","methods":{"__getitem__":{"docstring":"None ","signature":"(self, key) -> Any","returns":{"annotation":"typing.Any","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"key":{"default":null,"annotation":null,"description":null}},"source":{"code":"    @capture_key_error\\n    def __getitem__(self, key) -> Any:\\n        return self.file_object[key]\\n","lines":[127,129]},"props":{"isClassMethod":false}},"open":{"docstring":"None ","signature":"(self, mode: str = \'r\', driver=None, comm=None)","returns":{"annotation":"<class \'inspect._empty\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"mode":{"default":"r","annotation":"<class \'str\'>","description":null},"driver":{"default":"None","annotation":null,"description":null},"comm":{"default":"None","annotation":null,"description":null}},"source":{"code":"    def open(self, mode: str = \\"r\\", driver=None, comm=None):\\n        if self._lock == 0:\\n            log.debug(f\\"[{id(self)}] Open {self.file_name}\\")\\n            self.file_object = open_h5file(self.file_name, mode, driver, comm)\\n\\n        if FILE_MODE_HIRARCHY[self.file_object.mode] < FILE_MODE_HIRARCHY[mode]:\\n            self.change_file_mode(mode, driver, comm)\\n\\n        log.debug(f\\"[{id(self)}] Lock stack {self._lock}\\")\\n        self._lock += 1\\n        return self.file_object\\n","lines":[149,159]},"props":{"isClassMethod":false}},"close":{"docstring":"None ","signature":"(self)","returns":{"annotation":"<class \'inspect._empty\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def close(self):\\n        self._lock -= 1\\n        if self._lock == 0:\\n            log.debug(f\\"[{id(self)}] Close {self.file_name}\\")\\n            self.file_object.close()\\n        log.debug(f\\"[{id(self)}] Lock stack {self._lock}\\")\\n","lines":[161,166]},"props":{"isClassMethod":false}},"change_file_mode":{"docstring":"None ","signature":"(self, mode: str, driver=None, comm=None)","returns":{"annotation":"<class \'inspect._empty\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"mode":{"default":null,"annotation":"<class \'str\'>","description":null},"driver":{"default":"None","annotation":null,"description":null},"comm":{"default":"None","annotation":null,"description":null}},"source":{"code":"    def change_file_mode(self, mode: str, driver=None, comm=None):\\n        log.info(\\n            f\\"Forced closing and reopening to change file mode [{self.file_name}].\\"\\n        )\\n        self.file_object.close()\\n        self.file_object = open_h5file(self.file_name, mode, driver, comm)\\n","lines":[168,173]},"props":{"isClassMethod":false}}},"variables":{"file_object":{"annotation":": h5py._debian_h5py_serial._hl.files.File","description":null},"file_name":{"annotation":"","description":null},"simulation_uid":{"annotation":"","description":null}},"inherits_from":{},"constructor":{"signature":"(\\n    file_name: str,\\n    _comm: mpi4py.MPI.Comm = <mpi4py.MPI.Intracomm object>\\n)","arguments":{"self":{"default":null,"annotation":null,"description":null},"file_name":{"default":null,"annotation":"<class \'str\'>","description":"the path to the file"},"_comm":{"default":"<mpi4py.MPI.Intracomm object at 0x7f5a10a12130>","annotation":"<class \'mpi4py.MPI.Comm\'>","description":"MPI communicator"}},"source":{"code":"    def __init__(self, file_name: str, _comm: MPI.Comm = MPI.COMM_WORLD) -> None:\\n        self.file_object: h5py.File = None\\n        self.file_name = file_name\\n        self.simulation_uid = os.path.basename(file_name)\\n        self._lock = 0\\n        self._mode = \\"r\\"\\n        self._driver = None\\n        self._comm = _comm\\n","lines":[109,116]}}}},"functions":{"open_h5file":{"docstring":"Open h5 file. Waiting if file is not available. ","signature":"(file: str, mode, driver=None, comm=None)","returns":{"annotation":"<class \'inspect._empty\'>","description":null},"arguments":{"file":{"default":null,"annotation":"<class \'str\'>","description":"File to open"},"mode":{"default":null,"annotation":null,"description":"\'r\', \'a\', \'w\', ..."},"driver":{"default":"None","annotation":null,"description":"driver for h5.File"},"comm":{"default":"None","annotation":null,"description":"MPI communicator"}},"source":{"code":"def open_h5file(file: str, mode, driver=None, comm=None):\\n    \\"\\"\\"Open h5 file. Waiting if file is not available.\\n\\n    Args:\\n        file (str): File to open\\n        mode (str): \'r\', \'a\', \'w\', ...\\n        driver (str): driver for h5.File\\n        comm: MPI communicator\\n    \\"\\"\\"\\n    while True:\\n        try:\\n            if driver == \\"mpio\\" and HAS_MPIO and MPI_ACTIVE:\\n                return h5py.File(file, mode, driver=driver, comm=comm)\\n            else:\\n                return h5py.File(file, mode)\\n\\n        except OSError:\\n            log.warning(f\\"File {file} not accessible, waiting\\")\\n            time.sleep(1)\\n","lines":[38,56]},"props":{"isClassMethod":false}},"with_file_open":{"docstring":"Open the file (`self._file`) before function Close the file after the function call  Works on classes containing the member `_file` of type :class:`~bamboost.common.file_handler.FileHandler`","signature":"(mode: str = \'r\', driver=None, comm=None)","returns":{"annotation":"<class \'inspect._empty\'>","description":null},"arguments":{"mode":{"default":"r","annotation":"<class \'str\'>","description":null},"driver":{"default":"None","annotation":null,"description":null},"comm":{"default":"None","annotation":null,"description":null}},"source":{"code":"def with_file_open(mode: str = \\"r\\", driver=None, comm=None):\\n    \\"\\"\\"Open the file (`self._file`) before function\\n    Close the file after the function call\\n\\n    Works on classes containing the member `_file` of type :class:`~bamboost.common.file_handler.FileHandler`\\n    \\"\\"\\"\\n\\n    def decorator(method):\\n        @wraps(method)\\n        def wrapper(self, *args, **kwargs):\\n            with self._file(mode, driver, comm):\\n                return method(self, *args, **kwargs)\\n\\n        return wrapper\\n\\n    return decorator\\n","lines":[59,74]},"props":{"isClassMethod":false}},"capture_key_error":{"docstring":"None ","signature":"(method)","returns":{"annotation":"<class \'inspect._empty\'>","description":null},"arguments":{"method":{"default":null,"annotation":null,"description":null}},"source":{"code":"def capture_key_error(method):\\n    @wraps(method)\\n    def inner(self, *args, **kwargs):\\n        try:\\n            return method(self, *args, **kwargs)\\n        except KeyError as e:\\n            raise KeyError(\\n                f\'[uid: {self.simulation_uid.split(\\".\\")[0]}] content not in file: {self.file_name}\'\\n            ) from e\\n\\n    return inner\\n","lines":[77,87]},"props":{"isClassMethod":false}}},"submodules":{}},"job":{"name":"bamboost.common.job","docstring":"None","classes":{"Job":{"name":"Job","docstring":"None ","methods":{"create_sbatch_script":{"docstring":"Write sbatch script for new simulation. ","signature":"(\\n    self,\\n    commands: list,\\n    path: str,\\n    uid: str = None,\\n    nnodes: int = 1,\\n    ntasks: int = 4,\\n    ncpus: int = 1,\\n    time: str = \'04:00:00\',\\n    mem_per_cpu: int = 2048,\\n    tmp: int = 8000\\n) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"commands":{"default":null,"annotation":"<class \'list\'>","description":null},"path":{"default":null,"annotation":"<class \'str\'>","description":null},"uid":{"default":"None","annotation":"<class \'str\'>","description":null},"nnodes":{"default":"1","annotation":"<class \'int\'>","description":null},"ntasks":{"default":"4","annotation":"<class \'int\'>","description":null},"ncpus":{"default":"1","annotation":"<class \'int\'>","description":null},"time":{"default":"04:00:00","annotation":"<class \'str\'>","description":null},"mem_per_cpu":{"default":"2048","annotation":"<class \'int\'>","description":null},"tmp":{"default":"8000","annotation":"<class \'int\'>","description":null}},"source":{"code":"    def create_sbatch_script(\\n        self,\\n        commands: list,\\n        path: str,\\n        uid: str = None,\\n        nnodes: int = 1,\\n        ntasks: int = 4,\\n        ncpus: int = 1,\\n        time: str = \\"04:00:00\\",\\n        mem_per_cpu: int = 2048,\\n        tmp: int = 8000,\\n    ) -> None:\\n        \\"\\"\\"Write sbatch script for new simulation.\\"\\"\\"\\n        nb_tasks_per_node = int(ntasks / nnodes)\\n\\n        # define how mpirun is called\\n        mpicommand = \\"\\"\\n        if ntasks > 1:\\n            mpicommand = \\"mpirun \\"\\n\\n        script = f\\"#!/bin/bash\\\\n\\\\n\\"\\n\\n        # sbatch commands\\n        script += f\\"#SBATCH --ntasks={ntasks}\\\\n\\"\\n        if ntasks > 1:\\n            script += f\\"#SBATCH --nodes={nnodes}\\\\n\\"\\n            script += f\\"#SBATCH --cpus-per-task={ncpus}\\\\n\\"\\n            script += f\\"#SBATCH --ntasks-per-node={nb_tasks_per_node}\\\\n\\"\\n        script += f\\"#SBATCH --time={time}\\\\n\\"\\n        script += f\\"#SBATCH --job-name={uid}\\\\n\\"\\n        script += f\\"#SBATCH --mem-per-cpu={mem_per_cpu}\\\\n\\"\\n        if tmp:\\n            script += f\\"#SBATCH --tmp={tmp}\\\\n\\"\\n        script += f\\"#SBATCH --output={os.path.join(path, uid)}/{uid}.out\\\\n\\"\\n\\n        # user defined commands\\n        script += \\"\\\\n\\"\\n        for cmd in commands:\\n            script += cmd.format(MPI=mpicommand) + \\"\\\\n\\"\\n\\n        # write to submission file\\n        with open(\\n            os.path.join(os.path.join(path, uid), f\\"sbatch_{uid}.sh\\"), \\"w\\"\\n        ) as file:\\n            file.write(script)\\n","lines":[20,64]},"props":{"isClassMethod":false}},"create_bash_script_local":{"docstring":"Write bash script for local execution. ","signature":"(self, commands: list, path: str, uid: str, ntasks: int = 4)","returns":{"annotation":"<class \'inspect._empty\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"commands":{"default":null,"annotation":"<class \'list\'>","description":null},"path":{"default":null,"annotation":"<class \'str\'>","description":null},"uid":{"default":null,"annotation":"<class \'str\'>","description":null},"ntasks":{"default":"4","annotation":"<class \'int\'>","description":null}},"source":{"code":"    def create_bash_script_local(\\n        self, commands: list, path: str, uid: str, ntasks: int = 4\\n    ):\\n        \\"\\"\\"Write bash script for local execution.\\"\\"\\"\\n\\n        # define how mpirun is called\\n        mpicommand = \\"\\"\\n        if ntasks > 1:\\n            mpicommand = f\\"mpirun -n {ntasks}\\"\\n\\n        script = f\\"#!/bin/bash\\\\n\\\\n\\"\\n\\n        # user defined commands\\n        for cmd in commands:\\n            script += cmd.format(MPI=mpicommand) + \\"\\\\n\\"\\n\\n        with open(os.path.join(os.path.join(path, uid), f\\"{uid}.sh\\"), \\"w\\") as file:\\n            file.write(script)\\n","lines":[66,83]},"props":{"isClassMethod":false}}},"variables":{},"inherits_from":{},"constructor":{"signature":"()","arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def __init__(self):\\n        pass\\n","lines":[17,18]}}}},"functions":{},"submodules":{}},"utilities":{"name":"bamboost.common.utilities","docstring":"Utility functions used by bamboost.","classes":{},"functions":{"flatten_dict":{"docstring":"None ","signature":"(dictionary, parent_key=\'\', seperator=\'.\')","returns":{"annotation":"<class \'inspect._empty\'>","description":null},"arguments":{"dictionary":{"default":null,"annotation":null,"description":null},"parent_key":{"default":"","annotation":null,"description":null},"seperator":{"default":".","annotation":null,"description":null}},"source":{"code":"def flatten_dict(dictionary, parent_key=\\"\\", seperator=\\".\\"):\\n    items = []\\n    for key, value in dictionary.items():\\n        new_key = parent_key + seperator + key if parent_key else key\\n        if isinstance(value, MutableMapping):\\n            items.extend(flatten_dict(value, new_key, seperator=seperator).items())\\n        else:\\n            items.append((new_key, value))\\n    return dict(items)\\n","lines":[27,35]},"props":{"isClassMethod":false}},"unflatten_dict":{"docstring":"None ","signature":"(dictionary, seperator=\'.\')","returns":{"annotation":"<class \'inspect._empty\'>","description":null},"arguments":{"dictionary":{"default":null,"annotation":null,"description":null},"seperator":{"default":".","annotation":null,"description":null}},"source":{"code":"def unflatten_dict(dictionary, seperator=\\".\\"):\\n    new_dict = dict()\\n    for key, value in dictionary.items():\\n        parts = key.split(seperator)\\n        d = new_dict\\n        for part in parts[:-1]:\\n            if part not in d:\\n                d[part] = dict()\\n            d = d[part]\\n        d[parts[-1]] = value\\n    return new_dict\\n","lines":[38,48]},"props":{"isClassMethod":false}},"tree":{"docstring":"Given a directory Path object print a visual tree structure ","signature":"(\\n    dir_path: pathlib.Path,\\n    level: int = -1,\\n    limit_to_directories: bool = False,\\n    length_limit: int = 1000\\n)","returns":{"annotation":"<class \'inspect._empty\'>","description":null},"arguments":{"dir_path":{"default":null,"annotation":"<class \'pathlib.Path\'>","description":null},"level":{"default":"-1","annotation":"<class \'int\'>","description":null},"limit_to_directories":{"default":"False","annotation":"<class \'bool\'>","description":null},"length_limit":{"default":"1000","annotation":"<class \'int\'>","description":null}},"source":{"code":"def tree(\\n    dir_path: Path,\\n    level: int = -1,\\n    limit_to_directories: bool = False,\\n    length_limit: int = 1000,\\n):\\n    \\"\\"\\"Given a directory Path object print a visual tree structure\\"\\"\\"\\n    dir_path = Path(dir_path)  # accept string coerceable to Path\\n    files = 0\\n    directories = 0\\n    folder_symbol = \\"\\\\U00002B57 \\"\\n\\n    def inner(dir_path: Path, prefix: str = \\"\\", level=-1):\\n        nonlocal files, directories\\n        if not level:\\n            return  # 0, stop iterating\\n        if limit_to_directories:\\n            contents = [d for d in dir_path.iterdir() if d.is_dir()]\\n        else:\\n            contents = list(dir_path.iterdir())\\n        pointers = [tee] * (len(contents) - 1) + [last]\\n        for pointer, path in zip(pointers, contents):\\n            if path.is_dir():\\n                yield prefix + pointer + \\"\\\\U000025CC \\" + path.name\\n                directories += 1\\n                extension = branch if pointer == tee else space\\n                yield from inner(path, prefix=prefix + extension, level=level - 1)\\n            elif not limit_to_directories:\\n                yield prefix + pointer + path.name\\n                files += 1\\n\\n    tree_string = \\"\\"\\n    tree_string += (folder_symbol + dir_path.name) + \\"\\\\n\\"\\n    iterator = inner(dir_path, level=level)\\n    for line in islice(iterator, length_limit):\\n        tree_string += (line) + \\"\\\\n\\"\\n    if next(iterator, None):\\n        tree_string += (f\\"... length_limit, {length_limit}, reached, counted:\\") + \\"\\\\n\\"\\n    tree_string += (\\n        f\\"\\\\n{directories} directories\\" + (f\\", {files} files\\" if files else \\"\\")\\n    ) + \\"\\\\n\\"\\n    return tree_string\\n","lines":[52,93]},"props":{"isClassMethod":false}},"h5_tree":{"docstring":"None ","signature":"(val, pre=\'\')","returns":{"annotation":"<class \'inspect._empty\'>","description":null},"arguments":{"val":{"default":null,"annotation":null,"description":null},"pre":{"default":"","annotation":null,"description":null}},"source":{"code":"def h5_tree(val, pre=\\"\\"):\\n    items = len(val)\\n    for key, val in val.items():\\n        items -= 1\\n        if items == 0:\\n            # the last item\\n            if type(val) == h5py._hl.group.Group:\\n                print(pre + \\"\u2514\u2500\u2500 \\" + key)\\n                h5_tree(val, pre + \\"    \\")\\n            else:\\n                print(pre + \\"\u2514\u2500\u2500 \\" + key + \\" (%d)\\" % len(val))\\n        else:\\n            if type(val) == h5py._hl.group.Group:\\n                print(pre + \\"\u251c\u2500\u2500 \\" + key)\\n                h5_tree(val, pre + \\"\u2502   \\")\\n            else:\\n                print(pre + \\"\u251c\u2500\u2500 \\" + key + \\" (%d)\\" % len(val))\\n","lines":[96,112]},"props":{"isClassMethod":false}}},"submodules":{}},"git_utility":{"name":"bamboost.common.git_utility","docstring":"None","classes":{"GitStateGetter":{"name":"GitStateGetter","docstring":"None ","methods":{"create_git_string":{"docstring":"None ","signature":"(self) -> str","returns":{"annotation":"<class \'str\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def create_git_string(self) -> str:\\n        self.string = \\"\\"\\n\\n        self.string += \\"\\\\n\\"\\n        self.string += \\"----- REMOTE ------ \\\\n\\"\\n        self.string += self._git_command(\\"git remote -v\\")\\n\\n        self.string += \\"\\\\n\\"\\n        self.string += \\"----- BRANCH ------ \\\\n\\"\\n        self.string += self._git_command(\\"git branch -v\\")\\n\\n        self.string += \\"\\\\n\\"\\n        self.string += \\"----- LAST COMMIT ------ \\\\n\\"\\n        self.string += self._git_command(\\"git rev-parse HEAD\\")\\n\\n        self.string += \\"\\\\n\\"\\n        self.string += \\"----- STATUS ------ \\\\n\\"\\n        self.string += self._git_command(\\"git status\\")\\n\\n        self.string += \\"\\\\n\\"\\n        self.string += \\"----- DIFFERENCE ------ \\\\n\\"\\n        self.string += self._git_command(\\"git diff HEAD\\")\\n\\n        return self.string\\n","lines":[30,53]},"props":{"isClassMethod":false}}},"variables":{},"inherits_from":{},"constructor":{"signature":"()","arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def __init__(self) -> None:\\n        pass\\n","lines":[16,17]}}}},"functions":{},"submodules":{}},"hdf_pointer":{"name":"bamboost.common.hdf_pointer","docstring":"None","classes":{"BasePointer":{"name":"BasePointer","docstring":"Pointer to a location in an hdf5 file. The constructor takes a :class:`~.file_handler.FileHandler` and the in-file path to the object. The base class represents a generic group in the file","methods":{"new_pointer":{"docstring":"Returns a new pointer object. ","signature":"(\\n    cls,\\n    file_handler: bamboost.common.file_handler.FileHandler,\\n    path_to_data: str\\n) -> bamboost.common.hdf_pointer.BasePointer","returns":{"annotation":"<class \'bamboost.common.hdf_pointer.BasePointer\'>","description":null},"arguments":{"cls":{"default":null,"annotation":null,"description":null},"file_handler":{"default":null,"annotation":"<class \'bamboost.common.file_handler.FileHandler\'>","description":null},"path_to_data":{"default":null,"annotation":"<class \'str\'>","description":null}},"source":{"code":"    @classmethod\\n    def new_pointer(cls, file_handler: FileHandler, path_to_data: str) -> BasePointer:\\n        \\"\\"\\"Returns a new pointer object.\\"\\"\\"\\n        with file_handler(\\"r\\") as f:\\n            obj = f.file_object[path_to_data]\\n            if isinstance(obj, h5py.Group):\\n                if issubclass(cls, Group):\\n                    return cls(file_handler, path_to_data)\\n                else:\\n                    return Group(file_handler, path_to_data)\\n            elif isinstance(obj, h5py.Dataset):\\n                return Dataset(file_handler, path_to_data)\\n            else:\\n                return BasePointer(file_handler, path_to_data)\\n","lines":[39,52]},"props":{"isClassMethod":true}},"__getitem__":{"docstring":"None ","signature":"(self, key)","returns":{"annotation":"<class \'inspect._empty\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"key":{"default":null,"annotation":null,"description":null}},"source":{"code":"    @with_file_open(\\"r\\")\\n    def __getitem__(self, key):\\n        new_path = f\\"{self.path_to_data}/{key}\\"\\n        return self.new_pointer(self._file, new_path)\\n","lines":[82,85]},"props":{"isClassMethod":false}}},"variables":{"path_to_data":{"annotation":"","description":null},"obj":{"annotation":"","description":"The object this BasePointer points to. File needs to be open for access. "},"attrs":{"annotation":"","description":null}},"inherits_from":{},"constructor":{"signature":"(\\n    file_handler: bamboost.common.file_handler.FileHandler,\\n    path_to_data: str\\n)","arguments":{"self":{"default":null,"annotation":null,"description":null},"file_handler":{"default":null,"annotation":"<class \'bamboost.common.file_handler.FileHandler\'>","description":"file this belongs to"},"path_to_data":{"default":null,"annotation":"<class \'str\'>","description":"infile path to object"}},"source":{"code":"    def __init__(self, file_handler: FileHandler, path_to_data: str) -> None:\\n        self._file = file_handler\\n        self.path_to_data = path_to_data\\n","lines":[54,56]}}},"Group":{"name":"Group","docstring":"Pointer to a location in an hdf5 file. The constructor takes a :class:`~.file_handler.FileHandler` and the in-file path to the object. The base class represents a generic group in the file","methods":{"__iter__":{"docstring":"None ","signature":"(self)","returns":{"annotation":"<class \'inspect._empty\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def __iter__(self):\\n        for key in self.keys():\\n            yield self.__getitem__(key)\\n","lines":[100,102]},"props":{"isClassMethod":false}},"keys":{"docstring":"None ","signature":"(self) -> set","returns":{"annotation":"<class \'set\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    @with_file_open(\\"r\\")\\n    def keys(self) -> set:\\n        return set(self.obj.keys())\\n","lines":[104,106]},"props":{"isClassMethod":false}},"groups":{"docstring":"None ","signature":"(self) -> set","returns":{"annotation":"<class \'set\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    @with_file_open(\\"r\\")\\n    def groups(self) -> set:\\n        return {key for key in self.keys() if isinstance(self.obj[key], h5py.Group)}\\n","lines":[108,110]},"props":{"isClassMethod":false}},"datasets":{"docstring":"None ","signature":"(self) -> set","returns":{"annotation":"<class \'set\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    @with_file_open(\\"r\\")\\n    def datasets(self) -> set:\\n        return {key for key in self.keys() if isinstance(self.obj[key], h5py.Dataset)}\\n","lines":[112,114]},"props":{"isClassMethod":false}}},"variables":{},"inherits_from":{"bamboost.common.hdf_pointer":[["function","new_pointer"],["variable","path_to_data"],["variable","obj"],["function","__getitem__"],["variable","attrs"]]},"constructor":{"signature":"(\\n    file_handler: bamboost.common.file_handler.FileHandler,\\n    path_to_data: str\\n)","arguments":{"self":{"default":null,"annotation":null,"description":null},"file_handler":{"default":null,"annotation":"<class \'bamboost.common.file_handler.FileHandler\'>","description":"file this belongs to"},"path_to_data":{"default":null,"annotation":"<class \'str\'>","description":"infile path to object"}},"source":{"code":"    def __init__(self, file_handler: FileHandler, path_to_data: str) -> None:\\n        super().__init__(file_handler, path_to_data)\\n","lines":[94,95]}}},"MutableGroup":{"name":"MutableGroup","docstring":"Used for the `userdata` group. ","methods":{"__getitem__":{"docstring":"Used to access datasets (:class:`~bamboost.common.hdf_pointer.Dataset`) or groups inside this group (:class:`~bamboost.common.hdf_pointer.MutableGroup`)","signature":"(self, key) -> Any","returns":{"annotation":"typing.Any","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"key":{"default":null,"annotation":null,"description":null}},"source":{"code":"    @with_file_open(\\"r\\")\\n    def __getitem__(self, key) -> Any:\\n        \\"\\"\\"Used to access datasets (:class:`~bamboost.common.hdf_pointer.Dataset`)\\n        or groups inside this group (:class:`~bamboost.common.hdf_pointer.MutableGroup`)\\n        \\"\\"\\"\\n        try:\\n            return super().__getitem__(key)\\n        except KeyError:\\n            pass\\n\\n        try:\\n            return self.obj.attrs[key]\\n        except KeyError:\\n            pass\\n\\n        return super().__getitem__(key)\\n","lines":[176,191]},"props":{"isClassMethod":false}},"__setitem__":{"docstring":"Used to set an attribute. Will be written as an attribute to the group.","signature":"(self, key, newvalue)","returns":{"annotation":"<class \'inspect._empty\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"key":{"default":null,"annotation":null,"description":null},"newvalue":{"default":null,"annotation":null,"description":null}},"source":{"code":"    @with_file_open(\\"a\\")\\n    def __setitem__(self, key, newvalue):\\n        \\"\\"\\"Used to set an attribute.\\n        Will be written as an attribute to the group.\\n        \\"\\"\\"\\n        if isinstance(newvalue, (int, float, bytes, str)):\\n            self.update_attrs({key: newvalue})\\n        elif isinstance(newvalue, (list, np.ndarray, tuple)):\\n            self.add_dataset(key, np.array(newvalue))\\n        else:\\n            raise TypeError(\\"New value has unsupported type.\\")\\n","lines":[193,203]},"props":{"isClassMethod":false}},"update_attrs":{"docstring":"Update the attributes of the group. ","signature":"(self, attrs: dict) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"attrs":{"default":null,"annotation":"<class \'dict\'>","description":"the dictionary to write as attributes"}},"source":{"code":"    @with_file_open(\\"a\\")\\n    def update_attrs(self, attrs: dict) -> None:\\n        \\"\\"\\"Update the attributes of the group.\\n\\n        Args:\\n            attrs: the dictionary to write as attributes\\n        \\"\\"\\"\\n        self.obj.attrs.update(attrs)\\n","lines":[213,220]},"props":{"isClassMethod":false}},"add_dataset":{"docstring":"Add a dataset to the group. Error is thrown if attempting to overwrite with different shape than before. If same shape, data is overwritten (this is inherited from h5py -> require_dataset)","signature":"(self, name: str, vector: numpy.ndarray, attrs: dict = None) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"name":{"default":null,"annotation":"<class \'str\'>","description":"Name for the dataset"},"vector":{"default":null,"annotation":"<class \'numpy.ndarray\'>","description":"Data to write (max 2d)"},"attrs":{"default":"None","annotation":"<class \'dict\'>","description":"Optional. Attributes of dataset."}},"source":{"code":"    def add_dataset(self, name: str, vector: np.ndarray, attrs: dict = None) -> None:\\n        \\"\\"\\"Add a dataset to the group. Error is thrown if attempting to overwrite\\n        with different shape than before. If same shape, data is overwritten\\n        (this is inherited from h5py -> require_dataset)\\n\\n        Args:\\n            name: Name for the dataset\\n            vector: Data to write (max 2d)\\n            attrs: Optional. Attributes of dataset.\\n        \\"\\"\\"\\n        if attrs is None:\\n            attrs = {}\\n        length_local = vector.shape[0]\\n        length_p = np.array(self._file._comm.allgather(length_local))\\n        length = np.sum(length_p)\\n        dim = vector.shape[1:]\\n        vec_shape = length, *dim\\n\\n        ranks = np.array([i for i in range(self._file._comm.size)])\\n        idx_start = np.sum(length_p[ranks < self._file._comm.rank])\\n        idx_end = idx_start + length_local\\n\\n        with self._file(\\"a\\", driver=\\"mpio\\"):\\n            dataset = self.obj.require_dataset(name, shape=vec_shape, dtype=\\"f\\")\\n            dataset[idx_start:idx_end] = vector\\n            for key, item in attrs.items():\\n                dataset.attrs[key] = item\\n            dataset.flush()\\n\\n        log.info(f\\"Written {name} as userdata to {self._file.file_name}...\\")\\n","lines":[222,251]},"props":{"isClassMethod":false}},"require_group":{"docstring":"Add a new group to the current group. If exists, return existing. ","signature":"(self, name: str) -> bamboost.common.hdf_pointer.Group","returns":{"annotation":"<class \'bamboost.common.hdf_pointer.Group\'>","description":":class:`~bamboost.hdf_pointer.Group`"},"arguments":{"self":{"default":null,"annotation":null,"description":null},"name":{"default":null,"annotation":"<class \'str\'>","description":null}},"source":{"code":"    @with_file_open(\\"a\\")\\n    def require_group(self, name: str) -> Group:\\n        \\"\\"\\"Add a new group to the current group. If exists, return existing.\\n\\n        Returns:\\n            :class:`~bamboost.hdf_pointer.Group`\\n        \\"\\"\\"\\n        return MutableGroup(self._file, f\\"{self.path_to_data}/{name}\\")\\n","lines":[253,260]},"props":{"isClassMethod":false}}},"variables":{},"inherits_from":{"bamboost.common.hdf_pointer":[["function","new_pointer"],["variable","path_to_data"],["variable","obj"],["variable","attrs"]]},"constructor":{"signature":"(\\n    file_handler: bamboost.common.file_handler.FileHandler,\\n    path_to_data: str\\n)","arguments":{"self":{"default":null,"annotation":null,"description":null},"file_handler":{"default":null,"annotation":"<class \'bamboost.common.file_handler.FileHandler\'>","description":null},"path_to_data":{"default":null,"annotation":"<class \'str\'>","description":null}},"source":{"code":"    def __init__(self, file_handler: FileHandler, path_to_data: str) -> None:\\n        super().__init__(file_handler, path_to_data)\\n        # Create group if it doesn\'t exist\\n        with self._file(\\"a\\", driver=\\"mpio\\"):\\n            self._file.file_object.require_group(path_to_data)\\n","lines":[167,171]}}},"Dataset":{"name":"Dataset","docstring":"Pointer to a location in an hdf5 file. The constructor takes a :class:`~.file_handler.FileHandler` and the in-file path to the object. The base class represents a generic group in the file","methods":{"__getitem__":{"docstring":"None ","signature":"(self, slice)","returns":{"annotation":"<class \'inspect._empty\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"slice":{"default":null,"annotation":null,"description":null}},"source":{"code":"    @with_file_open(\\"r\\")\\n    def __getitem__(self, slice):\\n        return self.obj[slice]\\n","lines":[267,269]},"props":{"isClassMethod":false}}},"variables":{"attrs":{"annotation":"","description":null},"shape":{"annotation":"","description":null},"dtype":{"annotation":"","description":null}},"inherits_from":{"bamboost.common.hdf_pointer":[["function","new_pointer"],["variable","path_to_data"],["variable","obj"]]},"constructor":{"signature":"(\\n    file_handler: bamboost.common.file_handler.FileHandler,\\n    path_to_data: str\\n)","arguments":{"self":{"default":null,"annotation":null,"description":null},"file_handler":{"default":null,"annotation":"<class \'bamboost.common.file_handler.FileHandler\'>","description":"file this belongs to"},"path_to_data":{"default":null,"annotation":"<class \'str\'>","description":"infile path to object"}},"source":{"code":"    def __init__(self, file_handler: FileHandler, path_to_data: str) -> None:\\n        super().__init__(file_handler, path_to_data)\\n","lines":[264,265]}}}},"functions":{},"submodules":{}}}},"index":{"name":"bamboost.index","docstring":"Module to manage the database index and its ID\'s.","classes":{},"functions":{"get_index_dict":{"docstring":"Returns a dictionary of all known databases. ","signature":"() -> dict","returns":{"annotation":"<class \'dict\'>","description":null},"arguments":{},"source":{"code":"def get_index_dict() -> dict:\\n    \\"\\"\\"Returns a dictionary of all known databases.\\"\\"\\"\\n    with open(DATABASE_INDEX, \\"r\\") as file:\\n        try:\\n            return json.loads(file.read())\\n        except json.JSONDecodeError:\\n            return {}\\n","lines":[44,50]},"props":{"isClassMethod":false}},"_write_index_dict":{"docstring":"Write the database index. ","signature":"(index: dict) -> None","returns":{"annotation":"None","description":null},"arguments":{"index":{"default":null,"annotation":"<class \'dict\'>","description":null}},"source":{"code":"def _write_index_dict(index: dict) -> None:\\n    \\"\\"\\"Write the database index.\\"\\"\\"\\n    with open(DATABASE_INDEX, \\"w+\\") as file:\\n        file.write(json.dumps(index, indent=4))\\n","lines":[53,56]},"props":{"isClassMethod":false}},"get_known_paths":{"docstring":"None ","signature":"() -> list","returns":{"annotation":"<class \'list\'>","description":null},"arguments":{},"source":{"code":"def get_known_paths() -> list:\\n    with open(KNOWN_PATHS, \\"r\\") as file:\\n        return json.loads(file.read())\\n","lines":[59,61]},"props":{"isClassMethod":false}},"_find_posix":{"docstring":"Find function using system `find` on linux. ","signature":"(uid, root_dir) -> list","returns":{"annotation":"<class \'list\'>","description":null},"arguments":{"uid":{"default":null,"annotation":null,"description":null},"root_dir":{"default":null,"annotation":null,"description":null}},"source":{"code":"def _find_posix(uid, root_dir) -> list:\\n    \\"\\"\\"Find function using system `find` on linux.\\"\\"\\"\\n    completed_process = subprocess.run(\\n        [\\"find\\", root_dir, \\"-iname\\", uid2(uid), \\"-not\\", \\"-path\\", \\"*/\\\\.git/*\\"],\\n        capture_output=True,\\n    )\\n    paths_found = completed_process.stdout.decode(\\"utf-8\\").splitlines()\\n    return paths_found\\n","lines":[64,71]},"props":{"isClassMethod":false}},"_find_python":{"docstring":"Some find function for Windows or other if `find` is not working. TODO: to be implemented","signature":"(uid, root_dir) -> list","returns":{"annotation":"<class \'list\'>","description":null},"arguments":{"uid":{"default":null,"annotation":null,"description":null},"root_dir":{"default":null,"annotation":null,"description":null}},"source":{"code":"def _find_python(uid, root_dir) -> list:\\n    \\"\\"\\"Some find function for Windows or other if `find` is not working.\\n\\n    TODO: to be implemented\\n    \\"\\"\\"\\n    pass\\n","lines":[74,79]},"props":{"isClassMethod":false}},"uid2":{"docstring":"None ","signature":"(uid) -> str","returns":{"annotation":"<class \'str\'>","description":null},"arguments":{"uid":{"default":null,"annotation":null,"description":null}},"source":{"code":"def uid2(uid) -> str:\\n    return f\\"{PREFIX}{uid}\\"\\n","lines":[82,83]},"props":{"isClassMethod":false}},"get_uid_from_path":{"docstring":"Returns the UID found in the specified path. ","signature":"(path: str) -> str","returns":{"annotation":"<class \'str\'>","description":null},"arguments":{"path":{"default":null,"annotation":"<class \'str\'>","description":null}},"source":{"code":"def get_uid_from_path(path: str) -> str:\\n    \\"\\"\\"Returns the UID found in the specified path.\\"\\"\\"\\n    for file in os.listdir(path):\\n        if file.startswith(\\".BAMBOOST\\"):\\n            return file.split(\\"-\\")[1]\\n    raise FileNotFoundError(\\"No UID file found at specified path.\\")\\n","lines":[86,91]},"props":{"isClassMethod":false}},"_check_path":{"docstring":"Check if path is going to the correct database ","signature":"(uid: str, path: str) -> bool","returns":{"annotation":"<class \'bool\'>","description":null},"arguments":{"uid":{"default":null,"annotation":"<class \'str\'>","description":null},"path":{"default":null,"annotation":"<class \'str\'>","description":null}},"source":{"code":"def _check_path(uid: str, path: str) -> bool:\\n    \\"\\"\\"Check if path is going to the correct database\\"\\"\\"\\n    if not os.path.exists(path):\\n        return False\\n    if f\\"{PREFIX}{uid}\\" in os.listdir(path):\\n        return True\\n    return False\\n","lines":[94,100]},"props":{"isClassMethod":false}},"record_database":{"docstring":"Record a database in `database_index.json` ","signature":"(uid: str, path: str) -> None","returns":{"annotation":"None","description":null},"arguments":{"uid":{"default":null,"annotation":"<class \'str\'>","description":"the uid of the database"},"path":{"default":null,"annotation":"<class \'str\'>","description":"the path of the database"}},"source":{"code":"def record_database(uid: str, path: str) -> None:\\n    \\"\\"\\"Record a database in `database_index.json`\\n\\n    Args:\\n        uid: the uid of the database\\n        path: the path of the database\\n    \\"\\"\\"\\n    index = get_index_dict()\\n    index[uid] = path\\n    _write_index_dict(index)\\n","lines":[103,112]},"props":{"isClassMethod":false}},"get_path":{"docstring":"Find the path of a database specified by its UID. ","signature":"(uid: str) -> str","returns":{"annotation":"<class \'str\'>","description":null},"arguments":{"uid":{"default":null,"annotation":"<class \'str\'>","description":"the UID of the database"}},"source":{"code":"def get_path(uid: str) -> str:\\n    \\"\\"\\"Find the path of a database specified by its UID.\\n\\n    Args:\\n        uid: the UID of the database\\n    \\"\\"\\"\\n    # check in index\\n    index = get_index_dict()\\n    if uid in index.keys():\\n        path = index[uid]\\n        if _check_path(uid, path):\\n            return path\\n        else:\\n            del index[uid]\\n            _write_index_dict(index)\\n\\n    # check known paths\\n    known_paths = get_known_paths()\\n    for path in known_paths:\\n        res = find(uid, root_dir=path)\\n        if res:\\n            path = os.path.dirname(res[0])\\n            record_database(uid, path)\\n            return path\\n\\n    # check home\\n    res = find(uid, HOME)\\n    if res:\\n        path = os.path.dirname(res[0])\\n        record_database(uid, path)\\n        return path\\n\\n    raise FileNotFoundError(f\\"Database {uid} not found on system.\\")\\n","lines":[115,147]},"props":{"isClassMethod":false}},"find":{"docstring":"Find the database with UID under given root_dir. ","signature":"(uid, root_dir) -> list","returns":{"annotation":"<class \'list\'>","description":null},"arguments":{"uid":{"default":null,"annotation":null,"description":"UID to search for"},"root_dir":{"default":null,"annotation":null,"description":"root directory for search"}},"source":{"code":"def find(uid, root_dir) -> list:\\n    \\"\\"\\"Find the database with UID under given root_dir.\\n\\n    Args:\\n        uid: UID to search for\\n        root_dir: root directory for search\\n    \\"\\"\\"\\n    if os.name == \\"posix\\":\\n        paths = _find_posix(uid, root_dir)\\n    else:\\n        paths = _find_python(uid, root_dir)\\n    if len(paths) > 1:\\n        log.warning(f\\"Multiple paths found for UID {uid}:\\\\n{paths}\\")\\n    return paths\\n","lines":[150,163]},"props":{"isClassMethod":false}},"clean":{"docstring":"Clean the database index from wrong paths. ","signature":"() -> None","returns":{"annotation":"None","description":null},"arguments":{},"source":{"code":"def clean() -> None:\\n    \\"\\"\\"Clean the database index from wrong paths.\\"\\"\\"\\n    index = get_index_dict()\\n    clean_index = {uid: path for uid, path in index.items() if _check_path(uid, path)}\\n    _write_index_dict(clean_index)\\n","lines":[166,170]},"props":{"isClassMethod":false}},"create_index":{"docstring":"Create database index from known paths. ","signature":"() -> None","returns":{"annotation":"None","description":null},"arguments":{},"source":{"code":"def create_index() -> None:\\n    \\"\\"\\"Create database index from known paths.\\"\\"\\"\\n    known_paths = get_known_paths()\\n    index = get_index_dict()\\n    for path in known_paths:\\n        completed_process = subprocess.run(\\n            [\\"find\\", path, \\"-iname\\", f\\"{PREFIX}*\\", \\"-not\\", \\"-path\\", \\"*/\\\\.git/*\\"],\\n            capture_output=True,\\n        )\\n        databases_found = completed_process.stdout.decode(\\"utf-8\\").splitlines()\\n        for database in databases_found:\\n            name = os.path.basename(database)\\n            uid = name.split(\\"-\\")[1]\\n            index[uid] = os.path.dirname(database)\\n    _write_index_dict(index)\\n","lines":[173,187]},"props":{"isClassMethod":false}}},"submodules":{}},"manager":{"name":"bamboost.manager","docstring":"None","classes":{"Manager":{"name":"Manager","docstring":"View of database. ","methods":{"__getitem__":{"docstring":"Returns the simulation in the specified row of the dataframe. ","signature":"(self, key: Union[str, int]) -> bamboost.simulation.Simulation","returns":{"annotation":"<class \'bamboost.simulation.Simulation\'>","description":":class:`~bamboost.reader.Simulation`"},"arguments":{"self":{"default":null,"annotation":null,"description":null},"key":{"default":null,"annotation":"typing.Union[str, int]","description":null}},"source":{"code":"    def __getitem__(self, key: Union[str, int]) -> Simulation:\\n        \\"\\"\\"Returns the simulation in the specified row of the dataframe.\\n\\n        Args:\\n            row (`str`): return the simulation with the specified uid\\n            row (int): return the simulation with index specified by row\\n        Returns:\\n            :class:`~bamboost.reader.Simulation`\\n        \\"\\"\\"\\n        if isinstance(key, str):\\n            return self.sim(key)\\n        else:\\n            return self.sim(self.df.loc[key, \\"id\\"])\\n","lines":[121,133]},"props":{"isClassMethod":false}},"__len__":{"docstring":"None ","signature":"(self) -> int","returns":{"annotation":"<class \'int\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def __len__(self) -> int:\\n        return len(self.all_uids)\\n","lines":[148,149]},"props":{"isClassMethod":false}},"__iter__":{"docstring":"None ","signature":"(self) -> list","returns":{"annotation":"<class \'list\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def __iter__(self) -> list:\\n        for sim in self.sims():\\n            yield sim\\n","lines":[151,153]},"props":{"isClassMethod":false}},"get_view":{"docstring":"View of the database and its parametric space. ","signature":"(self) -> pandas.core.frame.DataFrame","returns":{"annotation":"<class \'pandas.core.frame.DataFrame\'>","description":":class:`pd.DataFrame`"},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def get_view(self) -> pd.DataFrame:\\n        \\"\\"\\"View of the database and its parametric space.\\n\\n        Returns:\\n            :class:`pd.DataFrame`\\n        \\"\\"\\"\\n        all_uids = self.all_uids\\n        data = list()\\n\\n        for uid in all_uids:\\n            h5file_for_uid = os.path.join(self.path, uid, f\\"{uid}.h5\\")\\n            with open_h5file(h5file_for_uid, \\"r\\") as f:\\n                tmp_dict = dict()\\n                if \\"parameters\\" in f.keys():\\n                    tmp_dict.update(f[\\"parameters\\"].attrs)\\n                if \\"additionals\\" in f.keys():\\n                    tmp_dict.update({\\"additionals\\": f[\\"additionals\\"].attrs})\\n                tmp_dict.update(f.attrs)\\n                data.append(tmp_dict)\\n\\n        df = pd.DataFrame.from_records(data)\\n        if df.empty:\\n            return df\\n\\n        # Sort dataframe columns\\n        self._dataframe = df[\\n            [\\"id\\", \\"notes\\", \\"status\\", *df.columns.difference([\\"id\\", \\"notes\\", \\"status\\"])]\\n        ]\\n        return self._dataframe\\n","lines":[210,238]},"props":{"isClassMethod":false}},"sim":{"docstring":"Get an existing simulation with uid. Same as accessing with `db[uid]` directly. ","signature":"(self, uid, return_writer: bool = False) -> bamboost.simulation.Simulation","returns":{"annotation":"<class \'bamboost.simulation.Simulation\'>","description":":class:`~bamboost.simulation.Simulation`"},"arguments":{"self":{"default":null,"annotation":null,"description":null},"uid":{"default":null,"annotation":null,"description":"unique identifier"},"return_writer":{"default":"False","annotation":"<class \'bool\'>","description":"if true, return `SimulationWriter`, otherwise return `Simulation`"}},"source":{"code":"    def sim(self, uid, return_writer: bool = False) -> Simulation:\\n        \\"\\"\\"Get an existing simulation with uid. Same as accessing with `db[uid]` directly.\\n\\n        Args:\\n            uid (`str`): unique identifier\\n            return_writer: if true, return `SimulationWriter`, otherwise\\n                return `Simulation`\\n        Returns:\\n            :class:`~bamboost.simulation.Simulation`\\n        \\"\\"\\"\\n        if uid not in self.all_uids:\\n            raise KeyError(\\"The simulation id is not valid.\\")\\n        if return_writer:\\n            return SimulationWriter(uid, self.path, self.comm)\\n        return Simulation(uid, self.path, self.comm)\\n","lines":[263,277]},"props":{"isClassMethod":false}},"sims":{"docstring":"Get all simulations in a list. Optionally, get all simulations matching the given selection using pandas.","signature":"(\\n    self,\\n    select: pandas.core.series.Series = None,\\n    sort: str = None,\\n    reverse: bool = False,\\n    exclude: set = None,\\n    return_writer: bool = False\\n) -> list","returns":{"annotation":"<class \'list\'>","description":"A list of `:class:~bamboost.simulation.Simulation` objects"},"arguments":{"self":{"default":null,"annotation":null,"description":null},"select":{"default":"None","annotation":"<class \'pandas.core.series.Series\'>","description":"pandas boolean series"},"sort":{"default":"None","annotation":"<class \'str\'>","description":"Optionally sort the list with this keyword"},"reverse":{"default":"False","annotation":"<class \'bool\'>","description":"swap sort direction"},"exclude":{"default":"None","annotation":"<class \'set\'>","description":"sims to exclude"},"return_writer":{"default":"False","annotation":"<class \'bool\'>","description":"if true, return `SimulationWriter`, otherwise return `Simulation`"}},"source":{"code":"    def sims(\\n        self,\\n        select: pd.Series = None,\\n        sort: str = None,\\n        reverse: bool = False,\\n        exclude: set = None,\\n        return_writer: bool = False,\\n    ) -> list:\\n        \\"\\"\\"Get all simulations in a list. Optionally, get all simulations matching the\\n        given selection using pandas.\\n\\n        Args:\\n            select (`pd.Series`): pandas boolean series\\n            sort (`str`): Optionally sort the list with this keyword\\n            reverse (`bool`): swap sort direction\\n            exclude (`list[str]`): sims to exclude\\n            return_writer: if true, return `SimulationWriter`, otherwise\\n                return `Simulation`\\n        Returns:\\n            A list of `:class:~bamboost.simulation.Simulation` objects\\n        \\"\\"\\"\\n        if select is not None:\\n            id_list = self.df[select][\\"id\\"].values\\n        else:\\n            id_list = self.all_uids\\n        if exclude is not None:\\n            exclude = list([exclude]) if isinstance(exclude, str) else exclude\\n            id_list = [id for id in id_list if id not in exclude]\\n\\n        existing_sims = [self.sim(uid, return_writer) for uid in id_list]\\n\\n        if sort is None:\\n            return existing_sims\\n        else:\\n            return sorted(\\n                existing_sims, key=lambda s: s.parameters[sort], reverse=reverse\\n            )\\n","lines":[279,315]},"props":{"isClassMethod":false}},"create_simulation":{"docstring":"Get a writer object for a new simulation. This is written for paralell use as it is likely that this may be used in an executable, creating multiple runs for a parametric space, which may be run in paralell.","signature":"(\\n    self,\\n    uid: str = None,\\n    parameters: dict = None,\\n    skip_duplicate_check: bool = False\\n) -> bamboost.simulation_writer.SimulationWriter","returns":{"annotation":"<class \'bamboost.simulation_writer.SimulationWriter\'>","description":"sim (:class:`~bamboost.simulation.SimulationWriter`)"},"arguments":{"self":{"default":null,"annotation":null,"description":null},"uid":{"default":"None","annotation":"<class \'str\'>","description":"The name/uid for the simulation. If not specified, a random id will be assigned."},"parameters":{"default":"None","annotation":"<class \'dict\'>","description":"Parameter dictionary. If provided, the parameters will be checked against the existing sims for duplication. Otherwise, they may be specified later with :func:`~bamboost.simulation.SimulationWriter.add_parameters`."},"skip_duplicate_check":{"default":"False","annotation":"<class \'bool\'>","description":"if True, the duplicate check is skipped."}},"source":{"code":"    def create_simulation(\\n        self,\\n        uid: str = None,\\n        parameters: dict = None,\\n        skip_duplicate_check: bool = False,\\n    ) -> SimulationWriter:\\n        \\"\\"\\"Get a writer object for a new simulation. This is written for paralell use\\n        as it is likely that this may be used in an executable, creating multiple runs\\n        for a parametric space, which may be run in paralell.\\n\\n        Args:\\n            uid (`str`): The name/uid for the simulation. If not specified, a random id\\n                will be assigned.\\n            parameters (`dict`): Parameter dictionary. If provided, the parameters will be\\n                checked against the existing sims for duplication. Otherwise, they may be\\n                specified later with :func:`~bamboost.simulation.SimulationWriter.add_parameters`.\\n            skip_duplicate_check (`bool`): if True, the duplicate check is skipped.\\n        Returns:\\n            sim (:class:`~bamboost.simulation.SimulationWriter`)\\n        \\"\\"\\"\\n        if parameters and not skip_duplicate_check:\\n            go_on, uid = self._check_duplicate(parameters, uid)\\n            if not go_on:\\n                print(\\"Aborting by user desire...\\")\\n                return None\\n\\n        if self.comm.rank == 0:\\n            if not uid:\\n                uid = uuid.uuid4().hex[:8]  # Assign random unique identifier\\n        uid = self.comm.bcast(uid, root=0)\\n\\n        # Create directory and h5 file\\n        if self.comm.rank == 0:\\n            os.makedirs(os.path.join(self.path, uid), exist_ok=True)\\n            path_to_h5_file = os.path.join(self.path, uid, f\\"{uid}.h5\\")\\n            if os.path.exists(path_to_h5_file):\\n                os.remove(path_to_h5_file)\\n            h5py.File(path_to_h5_file, \\"a\\").close()  # create file\\n\\n        new_sim = SimulationWriter(uid, self.path, self.comm)\\n        new_sim.initialize()  # sets metadata and status\\n        if parameters is None:\\n            parameters = dict()\\n        new_sim.add_parameters(parameters)\\n        return new_sim\\n","lines":[317,361]},"props":{"isClassMethod":false}},"remove":{"docstring":"CAUTION, DELETING DATA. Remove the data of a simulation. ","signature":"(self, uid: str) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"uid":{"default":null,"annotation":"<class \'str\'>","description":"uid"}},"source":{"code":"    def remove(self, uid: str) -> None:\\n        \\"\\"\\"CAUTION, DELETING DATA. Remove the data of a simulation.\\n\\n        Args:\\n            uid (`str`): uid\\n        \\"\\"\\"\\n        shutil.rmtree(os.path.join(self.path, uid))\\n","lines":[363,369]},"props":{"isClassMethod":false}},"global_fields_in_all":{"docstring":"Get a list of all global fields in all simulations. ","signature":"(self) -> list","returns":{"annotation":"<class \'list\'>","description":"List of global fields"},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def global_fields_in_all(self) -> list:\\n        \\"\\"\\"Get a list of all global fields in all simulations.\\n\\n        Returns:\\n            List of global fields\\n        \\"\\"\\"\\n        fields = set()\\n        for sim in self:\\n            try:\\n                fields.update(sim.globals.columns)\\n            except KeyError:\\n                continue\\n\\n        return fields\\n","lines":[455,468]},"props":{"isClassMethod":false}},"get_parameters":{"docstring":"Get the parameters used in this database. ","signature":"(self) -> dict","returns":{"annotation":"<class \'dict\'>","description":"Dictionary of parameters with it\'s count, range, and type. Sorted by count."},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def get_parameters(self) -> dict:\\n        \\"\\"\\"Get the parameters used in this database.\\n\\n        Returns:\\n            Dictionary of parameters with it\'s count, range, and type. Sorted by count.\\n        \\"\\"\\"\\n        parameters = dict()\\n        for sim in self:\\n            for key, val in sim.parameters.items():\\n                if key not in parameters:\\n                    range = (val, val) if isinstance(val, numbers.Number) else None\\n                    parameters[key] = {\\"range\\": range, \\"count\\": 1, \\"type\\": type(val)}\\n                else:\\n                    if isinstance(val, numbers.Number):\\n                        parameters[key][\\"range\\"] = (\\n                            min(parameters[key][\\"range\\"][0], val),\\n                            max(parameters[key][\\"range\\"][1], val),\\n                        )\\n                    parameters[key][\\"count\\"] += 1\\n                    parameters[key][\\"type\\"] = type(val)\\n        return dict(\\n            sorted(parameters.items(), key=lambda x: x[1][\\"count\\"], reverse=True)\\n        )\\n","lines":[470,492]},"props":{"isClassMethod":false}}},"variables":{"FIX_DF":{"annotation":"","description":null},"fromUID":{"annotation":": bamboost.manager.ManagerFromUID","description":null},"fromName":{"annotation":": bamboost.manager.ManagerFromName","description":null},"path":{"annotation":"","description":null},"comm":{"annotation":"","description":null},"UID":{"annotation":"","description":null},"all_uids":{"annotation":": set","description":null},"df":{"annotation":": pandas.core.frame.DataFrame","description":"View of the database and its parametric space. "},"data_info":{"annotation":": pandas.core.frame.DataFrame","description":"Return view of stored data for all simulations "}},"inherits_from":{},"constructor":{"signature":"(\\n    path: str = None,\\n    comm: mpi4py.MPI.Comm = <mpi4py.MPI.Intracomm object>,\\n    uid: str = None,\\n    create_if_not_exist: bool = True\\n)","arguments":{"self":{"default":null,"annotation":null,"description":null},"path":{"default":"None","annotation":"<class \'str\'>","description":"path to the directory of the database. If doesn\'t exist, a new database will be created."},"comm":{"default":"<mpi4py.MPI.Intracomm object at 0x7f5a10a12130>","annotation":"<class \'mpi4py.MPI.Comm\'>","description":"MPI communicator"},"uid":{"default":"None","annotation":"<class \'str\'>","description":"UID of the database"},"create_if_not_exist":{"default":"True","annotation":"<class \'bool\'>","description":null}},"source":{"code":"    def __init__(\\n        self,\\n        path: str = None,\\n        comm: MPI.Comm = MPI.COMM_WORLD,\\n        uid: str = None,\\n        create_if_not_exist: bool = True,\\n    ):\\n        if uid is not None:\\n            path = index.get_path(uid.upper())\\n        self.path = path\\n        self.comm = comm\\n\\n        # check if path exists\\n        if not os.path.isdir(path):\\n            if not create_if_not_exist:\\n                raise NotADirectoryError(\\"Specified path is not a valid path.\\")\\n            log.info(f\\"Created new database ({path})\\")\\n            self._make_new(path)\\n        self.UID = self._retrieve_uid()\\n        # self._store_uid_in_index()\\n        self._all_uids = self._get_uids()\\n        self._dataframe: pd.DataFrame = None\\n        self._meta_folder = os.path.join(path, \\".database\\")\\n","lines":[97,119]}}},"ManagerFromUID":{"name":"ManagerFromUID","docstring":"Get a database by its UID. This is used for autocompletion in ipython. ","methods":{"__getitem__":{"docstring":"None ","signature":"(self, key) -> bamboost.manager.Manager","returns":{"annotation":"<class \'bamboost.manager.Manager\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"key":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def __getitem__(self, key) -> Manager:\\n        key = key.split()[0]  # take only uid\\n        return Manager(uid=key, create_if_not_exist=False)\\n","lines":[60,62]},"props":{"isClassMethod":false}}},"variables":{"completion_keys":{"annotation":"","description":null}},"inherits_from":{},"constructor":{"signature":"()","arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def __init__(self) -> None:\\n        ids = index.get_index_dict()\\n        self.completion_keys = tuple(\\n            [\\n                f\'{key} - {\\"...\\"+val[-25:] if len(val)>=25 else val}\'\\n                for key, val in ids.items()\\n            ]\\n        )\\n","lines":[48,55]}}},"ManagerFromName":{"name":"ManagerFromName","docstring":"Get a database by its path/name. This is used for autocompletion in ipython. ","methods":{"__getitem__":{"docstring":"None ","signature":"(self, key) -> bamboost.manager.Manager","returns":{"annotation":"<class \'bamboost.manager.Manager\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"key":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def __getitem__(self, key) -> Manager:\\n        return Manager(key, create_if_not_exist=False)\\n","lines":[73,74]},"props":{"isClassMethod":false}}},"variables":{"completion_keys":{"annotation":"","description":null}},"inherits_from":{},"constructor":{"signature":"()","arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def __init__(self) -> None:\\n        self.completion_keys = tuple(index.get_index_dict().values())\\n","lines":[67,68]}}}},"functions":{},"submodules":{}},"simulation":{"name":"bamboost.simulation","docstring":"None","classes":{"Simulation":{"name":"Simulation","docstring":"A single dataset/simulation. Used to write to it, read from it or append. ","methods":{"fromUID":{"docstring":"Return the `Simulation` with given UID. ","signature":"(cls, full_uid: str) -> bamboost.simulation.Simulation","returns":{"annotation":"<class \'bamboost.simulation.Simulation\'>","description":null},"arguments":{"cls":{"default":null,"annotation":null,"description":null},"full_uid":{"default":null,"annotation":"<class \'str\'>","description":"the full id (Database uid : simulation uid)"}},"source":{"code":"    @classmethod\\n    def fromUID(cls, full_uid: str) -> Simulation:\\n        \\"\\"\\"Return the `Simulation` with given UID.\\n\\n        Args:\\n            full_uid: the full id (Database uid : simulation uid)\\n        \\"\\"\\"\\n        db_uid, sim_uid = full_uid.split(\\":\\")\\n        db_path = index.get_path(db_uid)\\n        return cls(sim_uid, db_path)\\n","lines":[112,121]},"props":{"isClassMethod":true}},"__getitem__":{"docstring":"Direct access to HDF5 file. ","signature":"(self, key) -> bamboost.common.hdf_pointer.BasePointer","returns":{"annotation":"<class \'bamboost.common.hdf_pointer.BasePointer\'>","description":":class:`~bamboost.common.file_handler.BasePointer`"},"arguments":{"self":{"default":null,"annotation":null,"description":null},"key":{"default":null,"annotation":null,"description":null}},"source":{"code":"    @with_file_open()\\n    def __getitem__(self, key) -> hdf_pointer.BasePointer:\\n        \\"\\"\\"Direct access to HDF5 file.\\n\\n        Returns:\\n            :class:`~bamboost.common.file_handler.BasePointer`\\n        \\"\\"\\"\\n        return hdf_pointer.BasePointer.new_pointer(self._file, key)\\n","lines":[123,130]},"props":{"isClassMethod":false}},"show_files":{"docstring":"Show the file tree of the simulation directory. ","signature":"(\\n    self,\\n    level=-1,\\n    limit_to_directories=False,\\n    length_limit=1000,\\n    printit=True\\n) -> str","returns":{"annotation":"<class \'str\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"level":{"default":"-1","annotation":null,"description":"how deep to print the tree"},"limit_to_directories":{"default":"False","annotation":null,"description":"only print directories"},"length_limit":{"default":"1000","annotation":null,"description":"cutoff"},"printit":{"default":"True","annotation":null,"description":null}},"source":{"code":"    def show_files(\\n        self, level=-1, limit_to_directories=False, length_limit=1000, printit=True\\n    ) -> str:\\n        \\"\\"\\"Show the file tree of the simulation directory.\\n\\n        Args:\\n            level: how deep to print the tree\\n            limit_to_directories: only print directories\\n            length_limit: cutoff\\n        \\"\\"\\"\\n        tree_string = utilities.tree(\\n            self.path, level, limit_to_directories, length_limit\\n        )\\n        if printit:\\n            print(tree_string)\\n        else:\\n            return tree_string\\n","lines":[210,226]},"props":{"isClassMethod":false}},"open_in_file_explorer":{"docstring":"Open the simulation directory. Uses `xdg-open` on linux systems. ","signature":"(self) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def open_in_file_explorer(self) -> None:\\n        \\"\\"\\"Open the simulation directory. Uses `xdg-open` on linux systems.\\"\\"\\"\\n        if os.name == \\"nt\\":  # should work on Windows\\n            os.startfile(self.path)\\n        else:\\n            subprocess.run([\\"xdg-open\\", self.path])\\n","lines":[228,233]},"props":{"isClassMethod":false}},"get_full_uid":{"docstring":"Returns the full uid of the simulation (including the one of the database) ","signature":"(self) -> str","returns":{"annotation":"<class \'str\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def get_full_uid(self) -> str:\\n        \\"\\"\\"Returns the full uid of the simulation (including the one of the database)\\"\\"\\"\\n        database_uid = index.get_uid_from_path(self.path_database)\\n        return f\\"{database_uid}:{self.uid}\\"\\n","lines":[235,238]},"props":{"isClassMethod":false}},"change_status":{"docstring":"Change status of simulation. ","signature":"(self, status: str) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"status":{"default":null,"annotation":"<class \'str\'>","description":"new status"}},"source":{"code":"    @with_file_open(\\"a\\")\\n    def change_status(self, status: str) -> None:\\n        \\"\\"\\"Change status of simulation.\\n\\n        Args:\\n            status (str): new status\\n        \\"\\"\\"\\n        if self._prank == 0:\\n            self._file.attrs[\\"status\\"] = status\\n","lines":[240,248]},"props":{"isClassMethod":false}},"update_metadata":{"docstring":"Update the metadata attributes. ","signature":"(self, update_dict: dict) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"update_dict":{"default":null,"annotation":"<class \'dict\'>","description":"dictionary to push"}},"source":{"code":"    def update_metadata(self, update_dict: dict) -> None:\\n        \\"\\"\\"Update the metadata attributes.\\n\\n        Args:\\n            update_dict: dictionary to push\\n        \\"\\"\\"\\n        with self._file(\\"a\\") as file:\\n            file.attrs.update(update_dict)\\n","lines":[250,257]},"props":{"isClassMethod":false}},"update_parameters":{"docstring":"Update the parameters dictionary. ","signature":"(self, update_dict: dict) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"update_dict":{"default":null,"annotation":"<class \'dict\'>","description":"dictionary to push"}},"source":{"code":"    def update_parameters(self, update_dict: dict) -> None:\\n        \\"\\"\\"Update the parameters dictionary.\\n\\n        Args:\\n            update_dict: dictionary to push\\n        \\"\\"\\"\\n        if self._prank == 0:\\n            with self._file(\\"a\\") as file:\\n                file[\\"parameters\\"].attrs.update(update_dict)\\n","lines":[259,267]},"props":{"isClassMethod":false}},"create_xdmf_file":{"docstring":"Create the xdmf file to read in paraview. ","signature":"(self, fields: list = None, nb_steps: int = None) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"fields":{"default":"None","annotation":"<class \'list\'>","description":"fields for which to write timeseries information, if not specified, all fields in data are written."},"nb_steps":{"default":"None","annotation":"<class \'int\'>","description":"number of steps the simulation has"}},"source":{"code":"    def create_xdmf_file(self, fields: list = None, nb_steps: int = None) -> None:\\n        \\"\\"\\"Create the xdmf file to read in paraview.\\n\\n        Args:\\n            fields (list[str]): fields for which to write timeseries information,\\n                if not specified, all fields in data are written.\\n            nb_steps (int): number of steps the simulation has\\n        \\"\\"\\"\\n\\n        if self._comm.rank == 0:\\n            with self._file(\\"r\\") as f:\\n                if not fields:\\n                    fields = list(f[\\"data\\"].keys())\\n\\n                if not nb_steps:\\n                    grp_name = list(f[\\"data\\"].keys())[0]\\n                    nb_steps = list(f[f\\"data/{grp_name}\\"].keys())\\n                    nb_steps = max([int(step) for step in nb_steps])\\n\\n            xdmf_writer = XDMFWriter(self.xdmffile, self.h5file)\\n            xdmf_writer.write_points_cells(\\n                f\\"{self._mesh_location}/{self._default_mesh}/geometry\\",\\n                f\\"{self._mesh_location}/{self._default_mesh}/topology\\",\\n            )\\n\\n            xdmf_writer.add_timeseries(nb_steps + 1, fields)\\n            xdmf_writer.write_file()\\n","lines":[269,295]},"props":{"isClassMethod":false}},"create_batch_script":{"docstring":"Create a batch job and put it into the folder. ","signature":"(\\n    self,\\n    commands: list = None,\\n    nnodes=1,\\n    ntasks=4,\\n    ncpus=1,\\n    time=\'04:00:00\',\\n    mem_per_cpu=2048,\\n    tmp=8000,\\n    euler=True\\n) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"commands":{"default":"None","annotation":"<class \'list\'>","description":"A list of strings being the user defined commands to run"},"nnodes":{"default":"1","annotation":null,"description":"nb of nodes (default=1)"},"ntasks":{"default":"4","annotation":null,"description":"nb of tasks (default=4)"},"ncpus":{"default":"1","annotation":null,"description":"nb of cpus per task (default=1)"},"time":{"default":"04:00:00","annotation":null,"description":"requested time (default=4 hours)"},"mem_per_cpu":{"default":"2048","annotation":null,"description":"memory (default=2048)"},"tmp":{"default":"8000","annotation":null,"description":"temporary storage, set None to exclude option (default=8000)"},"euler":{"default":"True","annotation":null,"description":"If false, a local bash script will be written"}},"source":{"code":"    def create_batch_script(\\n        self,\\n        commands: list = None,\\n        nnodes=1,\\n        ntasks=4,\\n        ncpus=1,\\n        time=\\"04:00:00\\",\\n        mem_per_cpu=2048,\\n        tmp=8000,\\n        euler=True,\\n    ) -> None:\\n        \\"\\"\\"Create a batch job and put it into the folder.\\n\\n        Args:\\n            commands: A list of strings being the user defined commands to run\\n            nnodes: nb of nodes (default=1)\\n            ntasks: nb of tasks (default=4)\\n            ncpus: nb of cpus per task (default=1)\\n            time: requested time (default=4 hours)\\n            mem_per_cpu: memory (default=2048)\\n            tmp: temporary storage, set None to exclude option (default=8000)\\n            euler: If false, a local bash script will be written\\n        \\"\\"\\"\\n        job = Job()\\n        if not commands:\\n            if hasattr(self, \\"executable\\"):\\n                if \\".py\\" in self.executable:\\n                    command = (\\n                        f\\"{{MPI}} python3 {os.path.join(self.path, self.executable)} \\"\\n                        f\\"--path {self.path_database} --uid {self.uid}\\"\\n                    )\\n                    commands = [command]\\n            else:\\n                raise AttributeError(\\n                    \\"\\"\\"Either you must specify an executable or have it \\n                                     copied before with `copy_executable`!\\"\\"\\"\\n                )\\n\\n        if euler:\\n            job.create_sbatch_script(\\n                commands,\\n                path=os.path.abspath(self.path_database),\\n                uid=self.uid,\\n                nnodes=nnodes,\\n                ntasks=ntasks,\\n                ncpus=ncpus,\\n                time=time,\\n                mem_per_cpu=mem_per_cpu,\\n                tmp=tmp,\\n            )\\n        else:\\n            job.create_bash_script_local(\\n                commands,\\n                path=os.path.abspath(self.path_database),\\n                uid=self.uid,\\n                ntasks=ntasks,\\n            )\\n        with self._file(\\"a\\") as file:\\n            file.attrs.update({\\"submitted\\": False})\\n","lines":[297,355]},"props":{"isClassMethod":false}},"submit":{"docstring":"Submit the job for this simulation. ","signature":"(self) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def submit(self) -> None:\\n        \\"\\"\\"Submit the job for this simulation.\\"\\"\\"\\n        batch_script = os.path.abspath(os.path.join(self.path, f\\"sbatch_{self.uid}.sh\\"))\\n        subprocess.Popen([\\"sbatch\\", f\\"{batch_script}\\"])\\n        print(f\\"Simulation {self.uid} submitted!\\")\\n\\n        with self._file(\\"a\\") as file:\\n            file.attrs.update({\\"submitted\\": True})\\n","lines":[357,364]},"props":{"isClassMethod":false}},"change_note":{"docstring":"None ","signature":"(self, note) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"note":{"default":null,"annotation":null,"description":null}},"source":{"code":"    @with_file_open(\\"a\\")\\n    def change_note(self, note) -> None:\\n        self._file.attrs[\\"notes\\"] = note\\n","lines":[366,368]},"props":{"isClassMethod":false}},"open":{"docstring":"Use this as a context manager in a `with` statement. Purpose: keeping the file open to directly access/edit something in the HDF5 file of this simulation.","signature":"(\\n    self,\\n    mode: str = \'r\',\\n    driver=None,\\n    comm=None\\n) -> bamboost.common.file_handler.FileHandler","returns":{"annotation":"<class \'bamboost.common.file_handler.FileHandler\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"mode":{"default":"r","annotation":"<class \'str\'>","description":"file mode (see h5py docs)"},"driver":{"default":"None","annotation":null,"description":"file driver (see h5py docs)"},"comm":{"default":"None","annotation":null,"description":"mpi communicator"}},"source":{"code":"    def open(self, mode: str = \\"r\\", driver=None, comm=None) -> FileHandler:\\n        \\"\\"\\"Use this as a context manager in a `with` statement.\\n        Purpose: keeping the file open to directly access/edit something in the\\n        HDF5 file of this simulation.\\n\\n        Args:\\n            mode (`str`): file mode (see h5py docs)\\n            driver (`str`): file driver (see h5py docs)\\n            comm (`str`): mpi communicator\\n        \\"\\"\\"\\n        return self._file(mode, driver, comm)\\n","lines":[373,383]},"props":{"isClassMethod":false}},"get_mesh":{"docstring":"Return coordinates and connectivity. Currently returns numpy arrays. ","signature":"(self, mesh_name: str = None) -> Tuple[numpy.ndarray, numpy.ndarray]","returns":{"annotation":"typing.Tuple[numpy.ndarray, numpy.ndarray]","description":"Tuple of np.arrays (coordinates, connectivity)"},"arguments":{"self":{"default":null,"annotation":null,"description":null},"mesh_name":{"default":"None","annotation":"<class \'str\'>","description":"optional, name of mesh to read (default = mesh)"}},"source":{"code":"    @with_file_open(\\"r\\")\\n    def get_mesh(self, mesh_name: str = None) -> Tuple[np.ndarray, np.ndarray]:\\n        \\"\\"\\"Return coordinates and connectivity. Currently returns numpy arrays.\\n\\n        Args:\\n            mesh_name (`str`): optional, name of mesh to read (default = mesh)\\n        Returns:\\n            Tuple of np.arrays (coordinates, connectivity)\\n        \\"\\"\\"\\n        if mesh_name is None:\\n            mesh_name = self._default_mesh\\n\\n        mesh = self.meshes[mesh_name]\\n        return mesh.coordinates, mesh.connectivity\\n","lines":[394,407]},"props":{"isClassMethod":false}},"get_data_interpolator":{"docstring":"Get Linear interpolator for data field at step. Uses the linked mesh. ","signature":"(self, field: str, step: int)","returns":{"annotation":"<class \'inspect._empty\'>","description":":class:`scipy.interpolate.LinearNDInterpolator`"},"arguments":{"self":{"default":null,"annotation":null,"description":null},"field":{"default":null,"annotation":"<class \'str\'>","description":null},"step":{"default":null,"annotation":"<class \'int\'>","description":"step"}},"source":{"code":"    def get_data_interpolator(self, field: str, step: int):\\n        \\"\\"\\"Get Linear interpolator for data field at step. Uses the linked mesh.\\n\\n        Args:\\n            name (`str`): name of the data field\\n            step (`int`): step\\n        Returns:\\n            :class:`scipy.interpolate.LinearNDInterpolator`\\n        \\"\\"\\"\\n        from scipy.interpolate import LinearNDInterpolator\\n\\n        return LinearNDInterpolator(\\n            self.data[field].mesh.coordinates, self.data[field].at_step(step)\\n        )\\n","lines":[457,470]},"props":{"isClassMethod":false}},"show_h5tree":{"docstring":"Print the tree inside the h5 file. ","signature":"(self) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    @with_file_open()\\n    def show_h5tree(self) -> None:\\n        \\"\\"\\"Print the tree inside the h5 file.\\"\\"\\"\\n        # print(\'\\\\U00002B57 \' + os.path.basename(self.h5file))\\n        print(\\"\\\\U0001F43C \\" + os.path.basename(self.h5file))\\n        utilities.h5_tree(self._file.file_object)\\n","lines":[472,477]},"props":{"isClassMethod":false}}},"variables":{"uid":{"annotation":": str","description":null},"path_database":{"annotation":": str","description":null},"path":{"annotation":": str","description":null},"h5file":{"annotation":": str","description":null},"xdmffile":{"annotation":": str","description":null},"meshes":{"annotation":": bamboost.accessors.meshes.MeshGroup","description":null},"data":{"annotation":": bamboost.accessors.fielddata.DataGroup","description":null},"userdata":{"annotation":": bamboost.common.hdf_pointer.MutableGroup","description":null},"links":{"annotation":": bamboost.simulation.Links","description":null},"parameters":{"annotation":": dict","description":null},"metadata":{"annotation":": dict","description":null},"mesh":{"annotation":": Tuple[numpy.ndarray, numpy.ndarray]","description":"Return coordinates and connectivity of default mesh. "},"globals":{"annotation":": pandas.core.frame.DataFrame","description":"Return global data. "},"data_info":{"annotation":": \'pd.Dataframe\'","description":"View the data stored. "},"git":{"annotation":": dict","description":"Get Git information. "}},"inherits_from":{},"constructor":{"signature":"(\\n    uid: str,\\n    path: str,\\n    comm: mpi4py.MPI.Comm = <mpi4py.MPI.Intracomm object>\\n)","arguments":{"self":{"default":null,"annotation":null,"description":null},"uid":{"default":null,"annotation":"<class \'str\'>","description":"unique identifier"},"path":{"default":null,"annotation":"<class \'str\'>","description":"path to parent/database folder"},"comm":{"default":"<mpi4py.MPI.Intracomm object at 0x7f5a10a12130>","annotation":"<class \'mpi4py.MPI.Comm\'>","description":"MPI communicator (default=MPI.COMM_WORLD)"}},"source":{"code":"    def __init__(self, uid: str, path: str, comm: MPI.Comm = MPI.COMM_WORLD):\\n        self.uid: str = uid\\n        self.path_database: str = os.path.abspath(path)\\n        self.path: str = os.path.abspath(os.path.join(path, uid))\\n        self.h5file: str = os.path.join(self.path, f\\"{self.uid}.h5\\")\\n        self.xdmffile: str = os.path.join(self.path, f\\"{self.uid}.xdmf\\")\\n        os.makedirs(self.path, exist_ok=True)\\n\\n        # MPI information\\n        self._comm = comm\\n        self._psize = self._comm.size\\n        self._prank = self._comm.rank\\n        self._ranks = np.array([i for i in range(self._psize)])\\n\\n        self._file = FileHandler(self.h5file)\\n\\n        # Initialize groups to meshes, data and userdata. Create groups.\\n        self.meshes: MeshGroup = MeshGroup(self._file)\\n        self.data: DataGroup = DataGroup(self._file, self.meshes)\\n        self.userdata: hdf_pointer.MutableGroup = hdf_pointer.MutableGroup(self._file, \\"/userdata\\")\\n        self.links: Links = Links(self._file)\\n","lines":[90,110]}}},"Links":{"name":"Links","docstring":"Link group. Used to create and access links. I don\'t know how to distribute this to its own file in the accessors directory, due to circular imports.","methods":{"__getitem__":{"docstring":"Returns the linked simulation object. ","signature":"(self, key) -> Any","returns":{"annotation":"typing.Any","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"key":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def __getitem__(self, key) -> Any:\\n        \\"\\"\\"Returns the linked simulation object.\\"\\"\\"\\n        return Simulation.fromUID(self.all_links()[key])\\n","lines":[48,50]},"props":{"isClassMethod":false}},"__setitem__":{"docstring":"Creates the link. ","signature":"(self, key, newvalue)","returns":{"annotation":"<class \'inspect._empty\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"key":{"default":null,"annotation":null,"description":null},"newvalue":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def __setitem__(self, key, newvalue):\\n        \\"\\"\\"Creates the link.\\"\\"\\"\\n        return self.update_attrs({key: newvalue})\\n","lines":[52,54]},"props":{"isClassMethod":false}},"all_links":{"docstring":"None ","signature":"(self) -> dict","returns":{"annotation":"<class \'dict\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    @with_file_open(\\"r\\")\\n    def all_links(self) -> dict:\\n        return dict(self.obj.attrs)\\n","lines":[73,75]},"props":{"isClassMethod":false}}},"variables":{},"inherits_from":{"bamboost.common.hdf_pointer":[["function","new_pointer"],["variable","path_to_data"],["variable","obj"],["variable","attrs"]]},"constructor":{"signature":"(file_handler: bamboost.common.file_handler.FileHandler)","arguments":{"self":{"default":null,"annotation":null,"description":null},"file_handler":{"default":null,"annotation":"<class \'bamboost.common.file_handler.FileHandler\'>","description":null}},"source":{"code":"    def __init__(self, file_handler: FileHandler) -> None:\\n        super().__init__(file_handler, path_to_data=\\"links\\")\\n","lines":[42,43]}}}},"functions":{},"submodules":{}},"simulation_writer":{"name":"bamboost.simulation_writer","docstring":"None","classes":{"SimulationWriter":{"name":"SimulationWriter","docstring":"The SimulationWriter is the writer object for a single simulation. It inherits all reading methods from :class:`Simulation`.","methods":{"initialize":{"docstring":"Create a new file for this simlation. This deletes an existing h5 file of the simulation and creates an empty new one","signature":"(self) -> bamboost.simulation_writer.SimulationWriter","returns":{"annotation":"<class \'bamboost.simulation_writer.SimulationWriter\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def initialize(self) -> SimulationWriter:\\n        \\"\\"\\"Create a new file for this simlation.\\n        This deletes an existing h5 file of the simulation and creates an empty new one\\n        \\"\\"\\"\\n        self.step = 0\\n        self.add_metadata()\\n        self.change_status(\\"Initiated\\")\\n\\n        return self\\n","lines":[54,62]},"props":{"isClassMethod":false}},"add_metadata":{"docstring":"Add metadata to h5 file. ","signature":"(self) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def add_metadata(self) -> None:\\n        \\"\\"\\"Add metadata to h5 file.\\"\\"\\"\\n        nb_proc = self._comm.Get_size()\\n        if self._prank == 0:\\n            with self._file(\\"a\\"):\\n                self._file.attrs[\\"time_stamp\\"] = str(\\n                    datetime.datetime.now().replace(microsecond=0)\\n                )\\n                self._file.attrs[\\"id\\"] = self.uid\\n                self._file.attrs[\\"processors\\"] = nb_proc\\n                self._file.attrs[\\"notes\\"] = self._file.attrs.get(\\"notes\\", \\"\\")\\n","lines":[64,74]},"props":{"isClassMethod":false}},"add_parameters":{"docstring":"Add parameters to simulation. ","signature":"(self, parameters: dict) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"parameters":{"default":null,"annotation":"<class \'dict\'>","description":"Dictionary with parameters."}},"source":{"code":"    def add_parameters(self, parameters: dict) -> None:\\n        \\"\\"\\"Add parameters to simulation.\\n\\n        Args:\\n            parameters: Dictionary with parameters.\\n        \\"\\"\\"\\n        if self._prank == 0:\\n            with self._file(\\"a\\"):\\n                # flatten parameters\\n                parameters = flatten_dict(parameters)\\n\\n                if \\"parameters\\" in self._file.keys():\\n                    del self._file[\\"parameters\\"]\\n                grp = self._file.create_group(\\"/parameters\\")\\n                for key, val in parameters.items():\\n                    if isinstance(val, np.ndarray):\\n                        grp.create_dataset(key, data=val)\\n                    elif val is not None:\\n                        grp.attrs[key] = val\\n                    else:\\n                        pass\\n","lines":[76,96]},"props":{"isClassMethod":false}},"add_mesh":{"docstring":"Add the mesh to file. Currently only 2d meshes. ","signature":"(\\n    self,\\n    coordinates: numpy.ndarray,\\n    connectivity: numpy.ndarray,\\n    mesh_name: str = None\\n) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"coordinates":{"default":null,"annotation":"<class \'numpy.ndarray\'>","description":"Coordinates as array (nb_nodes, dim)"},"connectivity":{"default":null,"annotation":"<class \'numpy.ndarray\'>","description":"Connectivity matrix (nb_cells, nb nodes per cell)"},"mesh_name":{"default":"None","annotation":"<class \'str\'>","description":"name for mesh (default = `mesh`)"}},"source":{"code":"    def add_mesh(\\n        self, coordinates: np.ndarray, connectivity: np.ndarray, mesh_name: str = None\\n    ) -> None:\\n        \\"\\"\\"Add the mesh to file. Currently only 2d meshes.\\n\\n        Args:\\n            coordinates: Coordinates as array (nb_nodes, dim)\\n            connectivity: Connectivity matrix (nb_cells, nb nodes per cell)\\n            mesh_name: name for mesh (default = `mesh`)\\n        \\"\\"\\"\\n        if mesh_name is None:\\n            mesh_name = self._default_mesh\\n        # self._mesh_location = \'Mesh/0/mesh/\'\\n        mesh_location = f\\"{self._mesh_location}/{mesh_name}/\\"\\n\\n        nb_nodes_local = coordinates.shape[0]\\n        nb_cells_local = connectivity.shape[0]\\n\\n        # gather total mesh\\n        nb_nodes_p = np.array(self._comm.allgather(nb_nodes_local))\\n        nb_cells_p = np.array(self._comm.allgather(nb_cells_local))\\n        nb_nodes, nb_cells = np.sum(nb_nodes_p), np.sum(nb_cells_p)\\n\\n        # shape of datasets\\n        coord_shape = (\\n            (nb_nodes, coordinates.shape[1]) if coordinates.ndim > 1 else (nb_nodes,)\\n        )\\n        conn_shape = (\\n            (nb_cells, connectivity.shape[1]) if connectivity.ndim > 1 else (nb_cells,)\\n        )\\n\\n        # global indices nodes\\n        idx_start = np.sum(nb_nodes_p[self._ranks < self._prank])\\n        idx_end = idx_start + nb_nodes_local\\n\\n        # global indices cells\\n        idx_start_cells = np.sum(nb_cells_p[self._ranks < self._prank])\\n        idx_end_cells = idx_start_cells + nb_cells_local\\n        connectivity = connectivity + idx_start\\n\\n        with self._file(\\"a\\", driver=\\"mpio\\", comm=self._comm) as f:\\n            if mesh_location in self._file.file_object:\\n                del self._file.file_object[mesh_location]\\n            grp = f.require_group(mesh_location)\\n            coord = grp.require_dataset(\\"geometry\\", shape=coord_shape, dtype=\\"f\\")\\n            conn = grp.require_dataset(\\"topology\\", shape=conn_shape, dtype=\\"i\\")\\n\\n            coord[idx_start:idx_end] = coordinates\\n            conn[idx_start_cells:idx_end_cells] = connectivity\\n\\n            coord.flush()\\n            conn.flush()\\n","lines":[98,149]},"props":{"isClassMethod":false}},"add_field":{"docstring":"Add a dataset to the file. The data is stored at `data/`. ","signature":"(\\n    self,\\n    name: str,\\n    vector: <built-in function array>,\\n    time: float = None,\\n    mesh: str = None\\n) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"name":{"default":null,"annotation":"<class \'str\'>","description":"Name for the dataset"},"vector":{"default":null,"annotation":"<built-in function array>","description":"Dataset"},"time":{"default":"None","annotation":"<class \'float\'>","description":"Optional. time"},"mesh":{"default":"None","annotation":"<class \'str\'>","description":"Optional. Linked mesh for this data"}},"source":{"code":"    def add_field(\\n        self, name: str, vector: np.array, time: float = None, mesh: str = None\\n    ) -> None:\\n        \\"\\"\\"Add a dataset to the file. The data is stored at `data/`.\\n\\n        Args:\\n            name: Name for the dataset\\n            vector: Dataset\\n            time: Optional. time\\n            mesh: Optional. Linked mesh for this data\\n        \\"\\"\\"\\n        if mesh is None:\\n            mesh = self._default_mesh\\n\\n        # Get dimension of vector\\n        if vector.ndim <= 1:\\n            vector = vector.reshape((-1, 1))\\n        dim = vector.shape[1]\\n\\n        if time is None:\\n            time = self.step\\n\\n        length_local = vector.shape[0]\\n        length_p = np.array(self._comm.allgather(length_local))\\n        length = np.sum(length_p)\\n\\n        # global indices\\n        idx_start = np.sum(length_p[self._ranks < self._prank])\\n        idx_end = idx_start + length_local\\n\\n        # open file\\n        with self._file(\\"a\\", driver=\\"mpio\\", comm=self._comm) as f:\\n            data = f.require_group(\\n                \\"data\\"\\n            )  # Require group data to store all point data in\\n            grp = data.require_group(name)\\n            vec = grp.require_dataset(str(self.step), shape=(length, dim), dtype=\\"f\\")\\n            vec[idx_start:idx_end, :] = vector\\n\\n            vec.attrs[\\"t\\"] = time  # add time as attribute to dataset\\n            vec.attrs[\\"mesh\\"] = mesh  # add link to mesh as attribute\\n            vec.flush()\\n","lines":[151,192]},"props":{"isClassMethod":false}},"add_global_field":{"docstring":"Add a gobal field. These are stored at `gloals/` as an array in a single dataset.","signature":"(self, name: str, value: float) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"name":{"default":null,"annotation":"<class \'str\'>","description":"Name for the data"},"value":{"default":null,"annotation":"<class \'float\'>","description":"Data"}},"source":{"code":"    def add_global_field(self, name: str, value: float) -> None:\\n        \\"\\"\\"Add a gobal field. These are stored at `gloals/` as an array in a\\n        single dataset.\\n\\n        Args:\\n            name: Name for the data\\n            value: Data\\n        \\"\\"\\"\\n        if self._prank == 0:\\n            with self._file(\\"a\\") as f:\\n                grp = f.require_group(\\"globals\\")\\n                if name not in grp.keys():\\n                    vec = grp.create_dataset(\\n                        name, shape=(1,), dtype=\\"f\\", chunks=True, maxshape=(None,)\\n                    )\\n                    vec[0] = value\\n                else:\\n                    vec = grp[name]\\n                    vec.resize((self.step + 1,))\\n                    vec[-1] = value\\n                vec.flush()\\n","lines":[194,214]},"props":{"isClassMethod":false}},"add_additional":{"docstring":"Add an additional file stored elsewhere or in database directory. ","signature":"(self, name: str, file: str) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"name":{"default":null,"annotation":"<class \'str\'>","description":"Name of data"},"file":{"default":null,"annotation":"<class \'str\'>","description":"filename of file"}},"source":{"code":"    def add_additional(self, name: str, file: str) -> None:\\n        \\"\\"\\"Add an additional file stored elsewhere or in database directory.\\n\\n        Args:\\n            name: Name of data\\n            file: filename of file\\n        \\"\\"\\"\\n        if self._prank == 0:\\n            with self._file(\\"a\\") as f:\\n                grp = f.require_group(\\"additionals\\")\\n                grp.attrs.update({name: file})\\n","lines":[216,226]},"props":{"isClassMethod":false}},"finish_step":{"docstring":"Finish step. Adds 1 to the step counter. ","signature":"(self) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def finish_step(self) -> None:\\n        \\"\\"\\"Finish step. Adds 1 to the step counter.\\"\\"\\"\\n        self.step += 1\\n","lines":[228,230]},"props":{"isClassMethod":false}},"finish_sim":{"docstring":"None ","signature":"(self, status: str = \'Finished\') -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"status":{"default":"Finished","annotation":"<class \'str\'>","description":null}},"source":{"code":"    def finish_sim(self, status: str = \\"Finished\\") -> None:\\n        if self._prank == 0:\\n            self.change_status(status)\\n","lines":[232,234]},"props":{"isClassMethod":false}},"register_git_attributes":{"docstring":"Register git information for given repo. ","signature":"(self, repo_path: str = \'./\') -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"repo_path":{"default":"./","annotation":"<class \'str\'>","description":"path to git repository"}},"source":{"code":"    def register_git_attributes(self, repo_path: str = \\"./\\") -> None:\\n        \\"\\"\\"Register git information for given repo.\\n\\n        Args:\\n            repo_path (`str`): path to git repository\\n        \\"\\"\\"\\n        if self._prank == 0:\\n            repo_path = os.path.abspath(repo_path)\\n            # store current working directory\\n            cwd = os.getcwd()\\n\\n            # switch directory to git repo\\n            os.chdir(repo_path)\\n            git_string = GitStateGetter().create_git_string()\\n\\n            # switch working directory back\\n            os.chdir(cwd)\\n\\n            with self._file(\\"a\\") as f:\\n                grp = f.require_group(\\"git\\")\\n                repo_name = os.path.split(repo_path)[1]\\n                print(f\\"Adding repo {repo_name}\\")\\n                if repo_name in grp.keys():\\n                    del grp[repo_name]\\n                grp.create_dataset(repo_name, data=git_string)\\n","lines":[236,260]},"props":{"isClassMethod":false}},"copy_executable":{"docstring":"WILL BE REMOVED. USE COPY_FILE. Copy an executable to directory for reproducability.","signature":"(self, script_path: str) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"script_path":{"default":null,"annotation":"<class \'str\'>","description":"path to script"}},"source":{"code":"    def copy_executable(self, script_path: str) -> None:\\n        \\"\\"\\"WILL BE REMOVED. USE COPY_FILE.\\n        Copy an executable to directory for reproducability.\\n\\n        Args:\\n            script_path: path to script\\n        \\"\\"\\"\\n        shutil.copy(script_path, self.path)\\n        self.executable = os.path.split(script_path)[1]\\n","lines":[262,270]},"props":{"isClassMethod":false}},"copy_file":{"docstring":"Copy a file to the datafolder. ","signature":"(self, source: Union[str, list], destination: str = \'\') -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"source":{"default":null,"annotation":"typing.Union[str, list]","description":"path to file, or list of files"},"destination":{"default":"","annotation":"<class \'str\'>","description":"destination (will create intermediatory directories)"}},"source":{"code":"    def copy_file(self, source: Union[str, list], destination: str = \\"\\") -> None:\\n        \\"\\"\\"Copy a file to the datafolder.\\n\\n        Args:\\n            source: path to file, or list of files\\n            destination: destination (will create intermediatory directories)\\n        \\"\\"\\"\\n        if isinstance(source, list):\\n            for item in source:\\n                self.copy_file(item, destination)\\n            return\\n\\n        destination = os.path.join(self.path, destination)\\n\\n        if os.path.isdir(source):\\n            shutil.copytree(\\n                source,\\n                os.path.join(destination, os.path.basename(source)),\\n                dirs_exist_ok=True,\\n            )\\n        elif os.path.isfile(source):\\n            os.makedirs(destination, exist_ok=True)\\n            shutil.copy(source, destination)\\n        else:\\n            raise FileNotFoundError\\n","lines":[272,296]},"props":{"isClassMethod":false}}},"variables":{"step":{"annotation":": int","description":null}},"inherits_from":{"bamboost.simulation":[["variable","uid"],["variable","path_database"],["variable","path"],["variable","h5file"],["variable","xdmffile"],["variable","meshes"],["variable","data"],["variable","userdata"],["variable","links"],["function","fromUID"],["function","__getitem__"],["variable","parameters"],["variable","metadata"],["function","show_files"],["function","open_in_file_explorer"],["function","get_full_uid"],["function","change_status"],["function","update_metadata"],["function","update_parameters"],["function","create_xdmf_file"],["function","create_batch_script"],["function","submit"],["function","change_note"],["function","open"],["variable","mesh"],["function","get_mesh"],["variable","globals"],["variable","data_info"],["variable","git"],["function","get_data_interpolator"],["function","show_h5tree"]]},"constructor":{"signature":"(\\n    uid: str,\\n    path: str,\\n    comm: mpi4py.MPI.Comm = <mpi4py.MPI.Intracomm object>\\n)","arguments":{"self":{"default":null,"annotation":null,"description":null},"uid":{"default":null,"annotation":"<class \'str\'>","description":"The identifier of the simulation"},"path":{"default":null,"annotation":"<class \'str\'>","description":"The (parent) database path"},"comm":{"default":"<mpi4py.MPI.Intracomm object at 0x7f5a10a12130>","annotation":"<class \'mpi4py.MPI.Comm\'>","description":"An MPI communicator (Default: `MPI.COMM_WORLD`)"}},"source":{"code":"    def __init__(self, uid: str, path: str, comm: MPI.Comm = MPI.COMM_WORLD):\\n        super().__init__(uid, path, comm)\\n        self.step: int = 0\\n","lines":[40,42]}}}},"functions":{},"submodules":{}},"xdmf":{"name":"bamboost.xdmf","docstring":"None","classes":{"XDMFWriter":{"name":"XDMFWriter","docstring":"Write xdmf file for a subset of the stored data in the H5 file. ","methods":{"write_file":{"docstring":"None ","signature":"(self)","returns":{"annotation":"<class \'inspect._empty\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null}},"source":{"code":"    def write_file(self):\\n        tree = ET.ElementTree(self.xdmf_file)\\n        tree.write(self.filename)\\n","lines":[47,49]},"props":{"isClassMethod":false}},"write_points_cells":{"docstring":"Write the mesh to the xdmf file. ","signature":"(self, points_location: str, cells_location: str)","returns":{"annotation":"<class \'inspect._empty\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"points_location":{"default":null,"annotation":"<class \'str\'>","description":null},"cells_location":{"default":null,"annotation":"<class \'str\'>","description":null}},"source":{"code":"    def write_points_cells(self, points_location: str, cells_location: str):\\n        \\"\\"\\"Write the mesh to the xdmf file.\\n\\n        Args:\\n            points (str): String to geometry/nodes in h5 file\\n            cells (str): String to topology/cells in h5 file\\n        \\"\\"\\"\\n        grid = ET.SubElement(\\n            self.domain, \\"Grid\\", Name=self.mesh_name, GridType=\\"Uniform\\"\\n        )\\n        self._points(grid, points_location)\\n        self._cells(grid, cells_location)\\n","lines":[51,62]},"props":{"isClassMethod":false}},"add_timeseries":{"docstring":"None ","signature":"(self, steps: int, fields: list)","returns":{"annotation":"<class \'inspect._empty\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"steps":{"default":null,"annotation":"<class \'int\'>","description":null},"fields":{"default":null,"annotation":"<class \'list\'>","description":null}},"source":{"code":"    def add_timeseries(self, steps: int, fields: list):\\n        collection = ET.SubElement(\\n            self.domain,\\n            \\"Grid\\",\\n            Name=\\"TimeSeries\\",\\n            GridType=\\"Collection\\",\\n            CollectionType=\\"Temporal\\",\\n        )\\n\\n        for i in range(steps):\\n            self.write_step(collection, fields, i)\\n","lines":[105,115]},"props":{"isClassMethod":false}},"write_step":{"docstring":"Write the data array for time t. ","signature":"(\\n    self,\\n    collection: xml.etree.ElementTree.Element,\\n    fields: list,\\n    step: int\\n)","returns":{"annotation":"<class \'inspect._empty\'>","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"collection":{"default":null,"annotation":"<class \'xml.etree.ElementTree.Element\'>","description":null},"fields":{"default":null,"annotation":"<class \'list\'>","description":null},"step":{"default":null,"annotation":"<class \'int\'>","description":null}},"source":{"code":"    def write_step(self, collection: ET.Element, fields: list, step: int):\\n        \\"\\"\\"Write the data array for time t.\\n\\n        Args:\\n            t (float): time\\n            data_location (str): String to data in h5 file\\n            name (str): Name for the field in the Xdmf file\\n        \\"\\"\\"\\n        with h5py.File(self.h5file, \\"r\\") as f:\\n            grid = ET.SubElement(collection, \\"Grid\\")\\n            ptr = f\'xpointer(//Grid[@Name=\\"{self.mesh_name}\\"]/*[self::Topology or self::Geometry])\'\\n\\n            ET.SubElement(\\n                grid, \\"{http://www.w3.org/2003/XInclude}include\\", xpointer=ptr\\n            )\\n\\n            t = f[f\\"data/{fields[0]}/{step}\\"].attrs.get(\\"t\\", step)\\n            ET.SubElement(grid, \\"Time\\", Value=str(t))\\n\\n            for name in fields:\\n                self.write_attribute(grid, name, name, step)\\n","lines":[117,137]},"props":{"isClassMethod":false}},"write_attribute":{"docstring":"Write an attribute/field. ","signature":"(\\n    self,\\n    grid: xml.etree.ElementTree.Element,\\n    field_name: str,\\n    name: str,\\n    step: int\\n) -> None","returns":{"annotation":"None","description":null},"arguments":{"self":{"default":null,"annotation":null,"description":null},"grid":{"default":null,"annotation":"<class \'xml.etree.ElementTree.Element\'>","description":null},"field_name":{"default":null,"annotation":"<class \'str\'>","description":null},"name":{"default":null,"annotation":"<class \'str\'>","description":null},"step":{"default":null,"annotation":"<class \'int\'>","description":null}},"source":{"code":"    def write_attribute(\\n        self, grid: ET.Element, field_name: str, name: str, step: int\\n    ) -> None:\\n        \\"\\"\\"Write an attribute/field.\\"\\"\\"\\n        with h5py.File(self.h5file, \\"r\\") as f:\\n            data = f[f\\"data/{field_name}/{step}\\"]\\n            try:\\n                shape = data.shape[1]\\n            except IndexError:\\n                shape = 1\\n            att_type = {1: \\"Scalar\\", 2: \\"Vector\\", 3: \\"Tensor\\"}.get(shape, \\"Scalar\\")\\n\\n            att = ET.SubElement(\\n                grid,\\n                \\"Attribute\\",\\n                Name=name,\\n                AttributeType=att_type,\\n                Center=\\"Node\\",\\n            )\\n\\n            dt, prec = numpy_to_xdmf_dtype[data.dtype.name]\\n            try:\\n                dim = \\"{} {}\\".format(*data.shape)\\n            except IndexError:\\n                dim = \\"{}\\".format(data.shape[0])\\n\\n            data_item = ET.SubElement(\\n                att,\\n                \\"DataItem\\",\\n                DataType=dt,\\n                Dimensions=dim,\\n                Format=\\"HDF\\",\\n                Precision=prec,\\n            )\\n            h5file_name = os.path.split(self.h5file)[1]\\n            data_item.text = f\\"{h5file_name}:/data/{field_name}/{step}\\"\\n","lines":[139,174]},"props":{"isClassMethod":false}}},"variables":{"filename":{"annotation":"","description":null},"h5file":{"annotation":"","description":null},"xdmf_file":{"annotation":"","description":null},"domain":{"annotation":"","description":null},"mesh_name":{"annotation":"","description":null}},"inherits_from":{},"constructor":{"signature":"(filename: str, h5file: str)","arguments":{"self":{"default":null,"annotation":null,"description":null},"filename":{"default":null,"annotation":"<class \'str\'>","description":"xdmf file path"},"h5file":{"default":null,"annotation":"<class \'str\'>","description":"h5 file path"}},"source":{"code":"    def __init__(self, filename: str, h5file: str):\\n        self.filename = filename\\n        self.h5file = h5file\\n        self.xdmf_file = ET.Element(\\"Xdmf\\", Version=\\"3.0\\")\\n        self.domain = ET.SubElement(self.xdmf_file, \\"Domain\\")\\n        ET.register_namespace(\\"xi\\", \\"https://www.w3.org/2001/XInclude/\\")\\n        self.mesh_name = \\"mesh\\"\\n","lines":[39,45]}}}},"functions":{},"submodules":{}}}}')}}]);